# -*- coding: utf-8 -*-
"""
Enhanced Black-Litterman Portfolio Optimization Dashboard â€” ITAA Master ì „ìš©
v2025-11-20-ss3 (ë¦¬ìŠ¤í¬ ì‹œë®¬ë ˆì´ì…˜ & P&L ë¶„í¬ ê¸°ëŠ¥ ì¶”ê°€)

ì£¼ìš” ê°œì„ ì‚¬í•­:
1. ì¼ë³„ ì„±ê³¼ íƒ­ì—ì„œ ë¦¬ìŠ¤í¬ ì œì•½ ë°©ë²• ë³€ê²½ ì‹œ ì„±ê³¼ì§€í‘œ ì¬ê³„ì‚°
2. í¬ì§€ì…˜ í¬ê¸° ë³€í™” í…Œì´ë¸” ì¶”ê°€
3. ì›ë³¸ vs ì œì•½ ì ìš© ë¹„êµ ì°¨íŠ¸

ss3 ë²„ì „ ì¶”ê°€ ê¸°ëŠ¥ (Actual Portfolio íƒ­):
1. í¬ì§€ì…˜ í¬ê¸° ì¡°ì • â†’ ë¦¬ìŠ¤í¬ ë³€í™” ì‹œë®¬ë ˆì´ì…˜
2. ëª©í‘œ ë¦¬ìŠ¤í¬ ë³€í™” â†’ í¬ì§€ì…˜ í¬ê¸° ì—­ì‚°
3. -3Ïƒ ~ +3Ïƒ ì‹œë‚˜ë¦¬ì˜¤ë³„ P&L ë¶„í¬ ê·¸ë˜í”„ (í˜„ì¬/ì¡°ì • í¬ì§€ì…˜ ë¹„êµ)
"""

import os
import re
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Union

import numpy as np
import pandas as pd
import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from scipy.stats import rankdata, norm
from scipy.optimize import minimize, nnls
import warnings

import numpy as np
import pandas as pd

from typing import Dict, List, Tuple, Optional, Union, Any

warnings.filterwarnings('ignore')


# === PATCH C helpers (module-scope; avoid UnboundLocalError) ===
import numpy as _np
import pandas as _pd

def _pc_ensure_decimal_returns(df: _pd.DataFrame) -> _pd.DataFrame:
    x = df.replace([_np.inf, -_np.inf], _np.nan).astype(float)
    med = x.abs().stack(dropna=True).median()
    # ìˆ˜ìµë¥ ì´ %ìŠ¤ì¼€ì¼(â‰ˆ1=1%)ì´ë©´ ì†Œìˆ˜ë¡œ ë³€í™˜
    return x / 100.0 if (med is not None and _np.isfinite(med) and med > 0.2) else x

def _pc_build_recent_cov_constant_corr(ret_df: _pd.DataFrame,
                                       window: int = 63, rho: float = 0.25) -> _pd.DataFrame:
    X = ret_df.tail(window)
    std = X.std(ddof=1).fillna(0.0)
    S = _np.outer(std, std) * float(rho)
    _np.fill_diagonal(S, std.values ** 2)
    return _pd.DataFrame(S, index=ret_df.columns, columns=ret_df.columns)

def _pc_te_bp_from_cov(w, cov_df: _pd.DataFrame, ann_factor: int = 252) -> float:
    w = _np.asarray(_pd.Series(w).values, float).reshape(-1)
    var = float(w @ cov_df.values @ w)
    sigma_ann = (var ** 0.5) * (ann_factor ** 0.5)
    return sigma_ann * 1e4  # â†’ basis points


# =============================================================================
# Streamlit ì„¤ì •
# =============================================================================
st.set_page_config(
    page_title="ITAA Black-Litterman Portfolio Tracker",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.markdown(
    """
    <style>
    .main { padding: 0rem 1rem; }
    .stButton>button { width: 100%; }
    .metric-container { background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin: 5px 0; }
    .timeline-event { background-color: #e8f4f8; padding: 10px; border-left: 3px solid #1f77b4; margin: 10px 0; border-radius: 5px; }
    .rebalance-log { background-color: #f8f8f8; padding: 8px; border-left: 3px solid #ff7f0e; margin: 5px 0; border-radius: 3px; }
    .rank-change { padding: 5px 10px; border-radius: 3px; font-weight: bold; }
    .new-pair { background-color: #e7f3ff; padding: 10px; border-radius: 5px; margin: 10px 0; }
    .risk-indicator { background-color: #fff3cd; padding: 10px; border-left: 3px solid #ffc107; margin: 10px 0; border-radius: 5px; }
    .scenario-box { background-color: #f0f8ff; padding: 15px; border-radius: 8px; margin: 10px 0; border: 2px solid #4682b4; }
    .constraint-box { background-color: #e8f5e9; padding: 15px; border-radius: 8px; margin: 10px 0; border: 2px solid #4caf50; }
    </style>
    """,
    unsafe_allow_html=True,
)


# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================
def _to_float(x):
    """ì•ˆì „í•œ float ë³€í™˜"""
    if x is None:
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    if isinstance(x, str):
        s = x.strip().replace(",", "")
        if s == "":
            return np.nan
        if s.endswith("%"):
            try:
                return float(s[:-1]) / 100.0
            except Exception:
                return np.nan
        try:
            return float(s)
        except Exception:
            return np.nan
    return np.nan


def normalize_score(scores, min_val=0, max_val=1):
    """ì ìˆ˜ ì •ê·œí™”"""
    scores = np.array(scores, dtype=float)
    if scores.size == 0:
        return scores
    score_min = np.nanmin(scores)
    score_max = np.nanmax(scores)
    if not np.isfinite(score_min) or not np.isfinite(score_max):
        return np.zeros_like(scores)
    if score_max == score_min:
        return np.full_like(scores, (min_val + max_val) / 2.0)
    normalized = (scores - score_min) / (score_max - score_min)
    return normalized * (max_val - min_val) + min_val


def _norm(s: str) -> str:
    """ë¬¸ìì—´ ì •ê·œí™”"""
    return str(s).strip().casefold()


def _safe_dt(x):
    """ì•ˆì „í•œ datetime ë³€í™˜"""
    try:
        return pd.to_datetime(x, errors="coerce")
    except Exception:
        return pd.NaT


def is_cash_asset(asset_name: str) -> bool:
    """í˜„ê¸ˆ ìì‚° ì—¬ë¶€ í™•ì¸"""
    if asset_name is None:
        return False
    asset_lower = str(asset_name).lower().strip()
    return asset_lower in ['cash', 'í˜„ê¸ˆ', 'usd cash', 'krw cash']


def normalize_str(x: Union[str, float, int]) -> str:
    """ë¬¸ìì—´ ì •ê·œí™” (ê³ ê¸‰)"""
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return ""
    s = str(x)
    s = re.sub(r"[\u200B-\u200D\uFEFF]", "", s)
    s = s.strip()
    s = re.sub(r"\s+", " ", s)
    return s.casefold()

# ë¦¬ìŠ¤í¬ ì œì•½ í‘œì‹œìš© ê³µí†µ ë§µ (ì „ì—­)
CONSTRAINT_DISPLAY_MAP = {
    "3Y_MDD": "3ë…„ MDD",
    "-3STD": "-3 í‘œì¤€í¸ì°¨ (3M)",
    "-2STD": "-2 í‘œì¤€í¸ì°¨ (3M)",
    "-1STD": "-1 í‘œì¤€í¸ì°¨ (3M)",
}

# =============================================================================
# í°íŠ¸ í¬ê¸° ì„¤ì • í•¨ìˆ˜ (1ë‹¨ê³„ ì¦ê°€)
# =============================================================================
def apply_chart_font_settings(fig, title_size=20, axis_title_size=18, tick_size=16, legend_size=16):
    """ì°¨íŠ¸ì— í†µì¼ëœ í°íŠ¸ í¬ê¸° ì ìš© (1ë‹¨ê³„ ì¦ê°€)"""
    fig.update_layout(
        title_font_size=title_size,
        font=dict(size=tick_size),
        legend=dict(font=dict(size=legend_size))
    )
    fig.update_xaxes(title_font_size=axis_title_size, tickfont_size=tick_size)
    fig.update_yaxes(title_font_size=axis_title_size, tickfont_size=tick_size)
    return fig


# =============================================================================
# ì—°ìœ¨í™” ê³„ì‚° í•¨ìˆ˜
# =============================================================================
def calculate_annualized_metrics(returns_series: pd.Series, trading_days_per_year: int = 252) -> Dict[str, float]:
    """
    ìˆ˜ìµë¥  ì‹œê³„ì—´ë¡œë¶€í„° ì—°ìœ¨í™” ìˆ˜ìµë¥  ë° ë³€ë™ì„± ê³„ì‚°

    Args:
        returns_series: ì¼ë³„ ìˆ˜ìµë¥  ì‹œê³„ì—´ (ì†Œìˆ˜ í˜•íƒœ)
        trading_days_per_year: ì—°ê°„ ê±°ë˜ì¼ ìˆ˜

    Returns:
        dict: {
            'cumulative_return': ëˆ„ì  ìˆ˜ìµë¥  (ì†Œìˆ˜),
            'annualized_return': ì—°ìœ¨í™” ìˆ˜ìµë¥  (ì†Œìˆ˜),
            'annualized_volatility': ì—°ìœ¨í™” ë³€ë™ì„± (ì†Œìˆ˜),
            'n_days': ì‹¤ì œ ê±°ë˜ì¼ ìˆ˜
        }
    """
    if returns_series.empty or len(returns_series) == 0:
        return {
            'cumulative_return': 0.0,
            'annualized_return': 0.0,
            'annualized_volatility': 0.0,
            'n_days': 0
        }

    # ëˆ„ì  ìˆ˜ìµë¥ 
    cumulative = (1 + returns_series).prod() - 1

    # ê±°ë˜ì¼ ìˆ˜
    n_days = len(returns_series)

    # ì—°ìœ¨í™” ìˆ˜ìµë¥ 
    if n_days > 0:
        annualized_return = (1 + cumulative) ** (trading_days_per_year / n_days) - 1
    else:
        annualized_return = 0.0

    # ì—°ìœ¨í™” ë³€ë™ì„±
    daily_vol = returns_series.std()
    annualized_vol = daily_vol * np.sqrt(trading_days_per_year)

    return {
        'cumulative_return': float(cumulative),
        'annualized_return': float(annualized_return),
        'annualized_volatility': float(annualized_vol),
        'n_days': int(n_days)
    }


# =============================================================================
# ìƒê´€ê´€ê³„/ë¦¬ìŠ¤í¬ ê³„ì‚° í•¨ìˆ˜
# =============================================================================
def calculate_rolling_correlation(returns_df: pd.DataFrame, window: int = 60):
    """Rolling correlation ê³„ì‚° (NaN ì²˜ë¦¬ ê°œì„ )"""
    if returns_df.empty or len(returns_df.columns) < 2:
        return {}

    rolling_corr = {}
    assets = returns_df.columns.tolist()

    for i in range(len(assets)):
        for j in range(i + 1, len(assets)):
            asset1, asset2 = assets[i], assets[j]
            pair_name = f"{asset1} vs {asset2}"

            valid_data = returns_df[[asset1, asset2]].dropna()

            if len(valid_data) < window:
                continue

            corr = returns_df[asset1].rolling(window=window).corr(returns_df[asset2])
            corr = corr.dropna()

            if not corr.empty:
                rolling_corr[pair_name] = corr

    return rolling_corr


def calculate_correlation_stability(returns_df: pd.DataFrame, window: int = 60):
    """Correlation stability ê³„ì‚° (NaN ì²˜ë¦¬ ê°œì„ )"""
    if returns_df.empty or len(returns_df) < window * 2:
        return pd.DataFrame()

    valid_threshold = 0.8
    valid_assets = []
    for col in returns_df.columns:
        valid_ratio = returns_df[col].notna().sum() / len(returns_df)
        if valid_ratio >= valid_threshold:
            valid_assets.append(col)

    if len(valid_assets) < 2:
        return pd.DataFrame()

    returns_clean = returns_df[valid_assets].copy()

    n_windows = len(returns_clean) // window
    correlations = []

    for i in range(n_windows):
        start_idx = i * window
        end_idx = (i + 1) * window
        window_data = returns_clean.iloc[start_idx:end_idx]

        if window_data.notna().sum().min() >= window * 0.7:
            corr_matrix = window_data.corr()
            if not corr_matrix.isnull().all().all():
                correlations.append(corr_matrix)

    if not correlations:
        return pd.DataFrame()

    corr_stack = np.stack([corr.values for corr in correlations], axis=0)
    stability = pd.DataFrame(
        np.nanstd(corr_stack, axis=0),
        index=valid_assets,
        columns=valid_assets
    )

    return stability


def calculate_portfolio_weights(views_df: pd.DataFrame, weights_df: pd.DataFrame) -> np.ndarray:
    """
    Viewsì™€ Benchmarkë¥¼ ê¸°ë°˜ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    TEì™€ Vol ê³„ì‚°ì—ì„œ ë™ì¼í•˜ê²Œ ì‚¬ìš©
    """
    if weights_df.empty:
        return np.array([])

    assets = weights_df["Asset"].astype(str).tolist()
    n_assets = len(assets)

    # 1. Optimal_Weightê°€ ìˆìœ¼ë©´ ê·¸ê²ƒ ì‚¬ìš©
    if "Optimal_Weight" in weights_df.columns:
        opt_weights = pd.to_numeric(weights_df["Optimal_Weight"], errors="coerce").fillna(0.0).values
        return opt_weights

    # 2. Benchmark + View adjustments
    if "Benchmark_Weight" in weights_df.columns:
        bm_weights = pd.to_numeric(weights_df["Benchmark_Weight"], errors="coerce").fillna(0.0).values
        view_adjustments = np.zeros(n_assets)

        if not views_df.empty:
            for _, view in views_df.iterrows():
                long_asset = str(view.get("Long_Asset", ""))
                short_asset = str(view.get("Short_Asset", ""))
                signal = float(view.get("Signal", 0.0))
                conviction = float(view.get("Conviction", 1.0))
                strength = signal * conviction * 0.05

                if long_asset in assets:
                    idx_long = assets.index(long_asset)
                    view_adjustments[idx_long] += strength
                if short_asset in assets:
                    idx_short = assets.index(short_asset)
                    view_adjustments[idx_short] -= strength

        opt_weights = bm_weights + view_adjustments
        opt_weights = np.clip(opt_weights, 0, 1)
        s = opt_weights.sum()
        if s > 0:
            opt_weights = opt_weights / s
        return opt_weights

    return np.array([])


# =============================================================================
# 3M Rolling Return ê³„ì‚°
# =============================================================================
def calculate_pair_3m_rolling_returns(
        returns_by_asset: pd.DataFrame,
        long_asset: str,
        short_asset: str,
        signal: float,  # âœ… Signal ì¶”ê°€
        lookback_years: int = 3,
        rolling_window: int = 63
) -> pd.Series:
    """
    í˜ì–´ì˜ 3ê°œì›” ë¡¤ë§ ë¦¬í„´ ê³„ì‚°
    âœ… Signal ë°©í–¥ì— ë”°ë¼ ìŠ¤í”„ë ˆë“œ ë°©í–¥ ê²°ì •

    Signal > 0: spread = Long - Short
    Signal < 0: spread = Short - Long
    """
    lookback_days = int(252 * lookback_years) + rolling_window
    recent_data = returns_by_asset.iloc[-lookback_days:]

    if long_asset not in recent_data.columns or short_asset not in recent_data.columns:
        return pd.Series(dtype=float)

    # âœ… Signal ë°©í–¥ì— ë”°ë¼ ìŠ¤í”„ë ˆë“œ ê³„ì‚°
    if signal >= 0:
        spread_daily = (recent_data[long_asset] - recent_data[short_asset]).dropna()
    else:
        spread_daily = (recent_data[short_asset] - recent_data[long_asset]).dropna()

    if len(spread_daily) < rolling_window:
        return pd.Series(dtype=float)

    rolling_3m = spread_daily.rolling(window=rolling_window).sum()
    return rolling_3m.dropna()


def calculate_pair_scenarios_3m(pair_3m_returns: pd.Series, position_size: float) -> Dict[str, float]:
    """3ê°œì›” rolling return ê¸°ì¤€ ì‹œë‚˜ë¦¬ì˜¤ë³„ ê¸°ëŒ€ìˆ˜ìµë¥  ê³„ì‚°"""
    if pair_3m_returns.empty or len(pair_3m_returns) < 20:
        return {}

    mean_return = pair_3m_returns.mean()
    std_return = pair_3m_returns.std()

    scenarios = {}
    std_levels = [-3, -2, -1, 1, 2, 3]

    for std_level in std_levels:
        spread_return_3m = mean_return + std_level * std_return
        portfolio_return = position_size * spread_return_3m
        scenarios[f"{std_level}std"] = portfolio_return * 10000  # bp ë‹¨ìœ„

    scenarios['mean_3m_bp'] = mean_return * position_size * 10000
    scenarios['std_3m_bp'] = std_return * position_size * 10000
    scenarios['sharpe_3m'] = mean_return / std_return if std_return > 0 else 0
    scenarios['position_bp'] = position_size * 10000

    # ì—°ìœ¨í™” ê·¼ì‚¬
    scenarios['annualized_return_bp'] = scenarios['mean_3m_bp'] * 4
    scenarios['annualized_std_bp'] = scenarios['std_3m_bp'] * 2

    return scenarios


def calculate_common_positions(
        returns_by_asset: pd.DataFrame,
        views_df: pd.DataFrame,
        constraint_method: str,
        lookback_years: int = 3
) -> pd.DataFrame:
    """
    ëª¨ë“  íƒ­ì—ì„œ ì‚¬ìš©í•  ê³µí†µ í¬ì§€ì…˜ ê³„ì‚°
    âœ… Signal ë°©í–¥ ë°˜ì˜
    """
    if returns_by_asset.empty or views_df.empty:
        return pd.DataFrame()

    pairs = [(str(r['Long_Asset']), str(r['Short_Asset']))
             for _, r in views_df.iterrows()]
    signals = views_df['Signal'].astype(float).values
    pair_ids = views_df.get('Pair_ID', range(len(pairs))).values

    # RiskConstraintCalculator (Signal ì „ë‹¬)
    risk_calc = RiskConstraintCalculator(
        returns_by_asset,
        lookback_years=lookback_years,
        rolling_window_days=63,
        use_exponential_weighting=True,
        ewm_halflife_days=126,
        max_loss_bp_map={1: 0.10, 2: 0.15}
    )

    # âœ… Signalì„ ê°œë³„ì ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ ë°©í–¥ ë°˜ì˜
    constraint_values, cap_arr = risk_calc.calculate_position_caps(
        pairs=pairs,
        signals=signals,
        constraint_method=constraint_method,
        asof_date=None,
        kappa_mode="cash-aware"
    )

    # Cash pair ê°ì§€
    def is_cash_name(name):
        if name is None:
            return False
        s = str(name).upper()
        cash_keywords = ("CASH", "T-BILL", "TBILL", "MMF", "CALL",
                         "KTB 3M", "UST 3M", "MONEY")
        return any(kw in s for kw in cash_keywords)

    is_cash_pair = [is_cash_name(la) or is_cash_name(sa) for la, sa in pairs]
    leg_factors = np.where(is_cash_pair, 1, 2)

    # âœ… Signal ë°©í–¥ ë°˜ì˜í•œ í¬ì§€ì…˜
    # cap_arrëŠ” í•­ìƒ ì–‘ìˆ˜, Signalì˜ ë¶€í˜¸ë¥¼ ê³±í•´ì„œ ë°©í–¥ ê²°ì •
    signed_caps = cap_arr * np.sign(signals)

    position_df = pd.DataFrame({
        'Pair_ID': pair_ids,
        'Pair': [f"{p[0]} vs {p[1]}" for p in pairs],
        'Long_Asset': [p[0] for p in pairs],
        'Short_Asset': [p[1] for p in pairs],
        'Signal': signals,
        'Is_Cash_Pair': is_cash_pair,
        'Leg_Factor': leg_factors,

        'Risk_Unit_3M_%': (constraint_values * 100).round(3),
        'Max_Loss_bp': [risk_calc.get_max_loss_bp(s) for s in signals],

        # âœ… Signal ë°©í–¥ì´ ë°˜ì˜ëœ í¬ì§€ì…˜
        'Per_Leg_Position_bp': (signed_caps * 10000).round(3),
        'Total_Notional_bp': (signed_caps * leg_factors * 10000).round(3),

        'Constraint_Method': constraint_method
    })

    return position_df



# =============================================================================
# ë¦¬ìŠ¤í¬ ì œì•½ ê³„ì‚° í´ë˜ìŠ¤ (ìˆ˜ì •ë¨)
# =============================================================================
import numpy as np
import pandas as pd
from typing import List, Tuple, Optional, Dict


# =============================================================================
# í—¬í¼ í•¨ìˆ˜: Signal ê¸°ë°˜ ì†ì‹¤ í—ˆìš©ì¹˜ ê³„ì‚°
# =============================================================================
def _compute_loss_caps_bp_from_views(views_df: pd.DataFrame) -> np.ndarray:
    """
    Signal ê°•ë„(|S|)ë³„ ì†ì‹¤ í—ˆìš©ì¹˜(bp) ë²¡í„° ìƒì„±.

    Rules:
    - |S| â‰¥ 2.0 â†’ 0.15bp
    - |S| â‰¥ 1.0 â†’ 0.10bp
    - ê·¸ ì™¸ â†’ 0.10 + 0.05 * |S| bp

    Args:
        views_df: Views DataFrame with 'Signal' column

    Returns:
        np.ndarray: ê° viewì— ëŒ€í•œ ìµœëŒ€ ì†ì‹¤ í—ˆìš©ì¹˜ (bp)
    """
    s = pd.to_numeric(views_df.get("Signal", 0), errors="coerce").fillna(0.0).abs().values
    return np.where(s >= 2.0, 0.15,
                    np.where(s >= 1.0, 0.10, 0.10 + 0.05 * s))

class RiskConstraintCalculator:
    """
    ë¦¬ìŠ¤í¬ ì œì•½ ê³„ì‚°ê¸° - 3ê°œì›” ë¡¤ë§ ë¦¬í„´ ê¸°ë°˜
    """

    def __init__(
        self,
        returns_by_asset: pd.DataFrame,
        lookback_years: int = 3,
        rolling_window_days: int = 63,
        z_default: float = 3.0,
        max_loss_bp_map: Optional[Dict[int, float]] = None,
        cash_keywords: Optional[List[str]] = None,
        min_sigma: float = 1e-6,
        use_exponential_weighting: bool = True,
        ewm_halflife_days: int = 126,
    ):
        """
        Parameters
        ----------
        returns_by_asset : pd.DataFrame
            ì¼ë³„ ìˆ˜ìµë¥ (ì†Œìˆ˜) í…Œì´ë¸”. index=DatetimeIndex, columns=ìì‚°ëª…
        lookback_years : int
            ë¡¤ë§ ë¦¬í„´ ê³„ì‚°ì— ì‚¬ìš©í•  ê³¼ê±° ê¸°ê°„ (ë…„)
        rolling_window_days : int
            ë¡¤ë§ ìœˆë„ìš° í¬ê¸° (ì˜ì—…ì¼, ê¸°ë³¸ê°’: 63 = ì•½ 3ê°œì›”)
        z_default : float
            constraint_method íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ Zë°°ìˆ˜
        max_loss_bp_map : dict
            ì‹ í˜¸ ê°•ë„ â†’ í—ˆìš© ìµœëŒ€ ì†ì‹¤(bp) ë§¤í•‘
            ì˜ˆ) {1: 10, 2: 15}  â† 10bp, 15bp (ì†Œìˆ˜ ì•„ë‹˜!)
        cash_keywords : list[str]
            ìºì‹œ ìì‚° ì‹ë³„ í‚¤ì›Œë“œ
        min_sigma : float
            ìˆ˜ì¹˜ ì•ˆì •í™”ë¥¼ ìœ„í•œ Ïƒ í•˜í•œ
        use_exponential_weighting : bool
            Trueë©´ EWM std ì‚¬ìš© (ìµœê·¼ ê°•ì¡°)
        ewm_halflife_days : int
            EWM ì‚¬ìš© ì‹œ halflife (ì˜ì—…ì¼)
        """
        self.rets = returns_by_asset.sort_index()
        self.lookback_years = lookback_years
        self.rolling_window_days = int(rolling_window_days)
        self.z_default = float(z_default)
        self.min_sigma = float(min_sigma)
        self.use_ewm = use_exponential_weighting
        self.ewm_halflife = int(ewm_halflife_days)

        # bp ë‹¨ìœ„! (ì†Œìˆ˜ ì•„ë‹˜)
        self.max_loss_bp_map = max_loss_bp_map or {1: 0.1, 2: 0.15}

        self.cash_keywords = [k.strip().lower() for k in (cash_keywords or [
            "cash", "money", "mm", "t-bill", "tbill", "bill", "bills",
            "ktb 3m", "ust 3m", "mmf", "call"
        ])]

        assert isinstance(self.rets.index, pd.DatetimeIndex), \
            "returns_by_asset.indexëŠ” DatetimeIndexì—¬ì•¼ í•©ë‹ˆë‹¤."

    def get_max_loss_bp(self, signal_value: float) -> float:
        """
        |Signal|ì— ë”°ë¥¸ í—ˆìš© ìµœëŒ€ ì†ì‹¤(bp)ì„ ë°˜í™˜
        """
        a = int(abs(round(float(signal_value))))
        if a in self.max_loss_bp_map:
            return float(self.max_loss_bp_map[a])
        if 1 in self.max_loss_bp_map:
            return float(self.max_loss_bp_map[1])
        k = sorted(self.max_loss_bp_map.keys())[0]
        return float(self.max_loss_bp_map[k])

    def calculate_position_caps(
            self,
            pairs: List[Tuple[str, str]],
            signals: List[float],
            constraint_method: str,
            asof_date: Optional[pd.Timestamp] = None,
            kappa_mode: str = "symmetric",
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        ê° í˜ì–´ì— ëŒ€í•´ (risk_unit, cap) ê³„ì‚° (Signal ë°©í–¥ ë°˜ì˜)
        """
        z = abs(self._parse_z(constraint_method))

        lookback_days = int(252 * self.lookback_years) + self.rolling_window_days
        end_idx = self._resolve_asof_index(asof_date)
        start_idx = max(0, end_idx - lookback_days + 1)
        window = self.rets.iloc[start_idx:end_idx + 1]

        risk_units = []
        caps = []

        for (la, sa), sig in zip(pairs, signals):
            la = str(la)
            sa = str(sa)

            # âœ… Signal ë°©í–¥ì— ë”°ë¼ ìŠ¤í”„ë ˆë“œ ë°©í–¥ ê²°ì •
            if kappa_mode == "cash-aware" and self._is_cash_pair(la, sa):
                mu_3m, sigma_3m = self._single_leg_stats_3m_rolling(window, la, sa, sig)
                leg_factor = 1
            else:
                mu_3m, sigma_3m = self._pair_spread_stats_3m_rolling(window, la, sa, sig)
                leg_factor = 2

            # -zÏƒ ì‹œë‚˜ë¦¬ì˜¤
            scenario_loss = abs(mu_3m - z * sigma_3m)
            risk_unit = max(self.min_sigma, scenario_loss)

            # í—ˆìš© ì†ì‹¤ (bp â†’ ì†Œìˆ˜)
            max_loss_decimal = self.get_max_loss_bp(sig) / 10_000.0

            # Per-leg cap (í•­ìƒ ì–‘ìˆ˜)
            cap = max_loss_decimal / (risk_unit * leg_factor) if risk_unit > 0 else np.inf

            risk_units.append(float(risk_unit))
            caps.append(float(cap))

        return np.array(risk_units, dtype=float), np.array(caps, dtype=float)

    def _pair_spread_stats_3m_rolling(
            self,
            window: pd.DataFrame,
            la: str,
            sa: str,
            signal: float  # âœ… Signal ì¶”ê°€
    ) -> Tuple[float, float]:
        """
        í˜ì–´ ìŠ¤í”„ë ˆë“œì˜ 3ê°œì›” ë¡¤ë§ ë¦¬í„´ í‰ê· ê³¼ í‘œì¤€í¸ì°¨
        âœ… Signal ë°©í–¥ì— ë”°ë¼ ìŠ¤í”„ë ˆë“œ ë°©í–¥ ê²°ì •

        Signal > 0: spread = Long - Short (ê¸°ì¡´)
        Signal < 0: spread = Short - Long (ë°˜ì „)
        """
        if la not in window.columns and sa not in window.columns:
            return 0.0, 0.0

        a = window[la] if la in window.columns else pd.Series(0.0, index=window.index)
        b = window[sa] if sa in window.columns else pd.Series(0.0, index=window.index)

        # âœ… Signal ë°©í–¥ì— ë”°ë¼ ìŠ¤í”„ë ˆë“œ ê³„ì‚°
        if signal >= 0:
            spread_daily = (a - b).dropna()  # Long - Short
        else:
            spread_daily = (b - a).dropna()  # Short - Long (ë°˜ì „)

        min_required = self.rolling_window_days + 20
        if len(spread_daily) < min_required:
            return 0.0, 0.0

        # 3ê°œì›” ë¡¤ë§ ë¦¬í„´
        rolling_3m = spread_daily.rolling(window=self.rolling_window_days).sum()
        rolling_3m_clean = rolling_3m.dropna()

        if len(rolling_3m_clean) < 2:
            return 0.0, 0.0

        # EWM í†µê³„
        if self.use_ewm:
            ewm_mean = rolling_3m_clean.ewm(halflife=self.ewm_halflife).mean()
            ewm_std = rolling_3m_clean.ewm(halflife=self.ewm_halflife).std()
            mu = float(ewm_mean.iloc[-1]) if len(ewm_mean) > 0 else 0.0
            sigma = float(ewm_std.iloc[-1]) if len(ewm_std) > 0 else 0.0
        else:
            mu = float(rolling_3m_clean.mean())
            sigma = float(rolling_3m_clean.std(ddof=1))

        return mu, sigma


    def _single_leg_stats_3m_rolling(
            self,
            window: pd.DataFrame,
            la: str,
            sa: str,
            signal: float  # âœ… Signal ì¶”ê°€
    ) -> Tuple[float, float]:
        """
        Cash pairìš©: ë¹„ìºì‹œ legì˜ 3ê°œì›” ë¡¤ë§ ë¦¬í„´
        âœ… Signal ë°©í–¥ì— ë”°ë¼ ìˆ˜ìµë¥  ë°©í–¥ ê²°ì •
        """
        la_is_cash = self._is_cash_name(la)
        sa_is_cash = self._is_cash_name(sa)

        min_required = self.rolling_window_days + 20

        # ë¹„ìºì‹œ ìì‚° ì„ íƒ
        target_asset = None
        if la in window.columns and not la_is_cash:
            target_asset = la
        elif sa in window.columns and not sa_is_cash:
            target_asset = sa

        if target_asset is None:
            return 0.0, 0.0

        series = window[target_asset].dropna()

        if len(series) < min_required:
            return 0.0, 0.0

        # âœ… Signal < 0ì´ë©´ ìˆ˜ìµë¥  ë°˜ì „
        if signal < 0:
            series = -series

        rolling_3m = series.rolling(window=self.rolling_window_days).sum()
        rolling_3m_clean = rolling_3m.dropna()

        if len(rolling_3m_clean) < 2:
            return 0.0, 0.0

        if self.use_ewm:
            ewm_mean = rolling_3m_clean.ewm(halflife=self.ewm_halflife).mean()
            ewm_std = rolling_3m_clean.ewm(halflife=self.ewm_halflife).std()
            mu = float(ewm_mean.iloc[-1]) if len(ewm_mean) > 0 else 0.0
            sigma = float(ewm_std.iloc[-1]) if len(ewm_std) > 0 else 0.0
        else:
            mu = float(rolling_3m_clean.mean())
            sigma = float(rolling_3m_clean.std(ddof=1))

        return mu, sigma


    def _resolve_asof_index(self, asof_date: Optional[pd.Timestamp]) -> int:
        """asof_date ì¸ë±ìŠ¤ ìœ„ì¹˜ ë°˜í™˜"""
        if asof_date is None:
            return len(self.rets.index) - 1

        if asof_date in self.rets.index:
            return self.rets.index.get_loc(asof_date)

        pos = self.rets.index.searchsorted(asof_date, side="right") - 1
        if pos < 0:
            return 0
        return int(pos)

    def _parse_z(self, constraint_method: str) -> float:
        """
        ë¬¸ìì—´ì—ì„œ Zë°°ìˆ˜ íŒŒì‹±
        """
        if constraint_method is None:
            return self.z_default

        s = str(constraint_method).lower().strip()

        # ìˆ«ìë§Œ
        try:
            return abs(float(s))
        except ValueError:
            pass

        # 'z=3'
        if "z" in s:
            try:
                return abs(float(s.split("=")[-1]))
            except Exception:
                pass

        # '-3std', '2std'
        for tok in ["std", "Ïƒ", "sigma"]:
            if tok in s:
                try:
                    num_str = s.replace(tok, "").replace("-", "").strip()
                    return abs(float(num_str))
                except Exception:
                    continue

        return self.z_default

    def _is_cash_name(self, name: str) -> bool:
        n = name.lower()
        return any(k in n for k in self.cash_keywords)

    def _is_cash_pair(self, la: str, sa: str) -> bool:
        return self._is_cash_name(la) or self._is_cash_name(sa)

    def explain_window(self, asof_date: Optional[pd.Timestamp] = None) -> Dict[str, object]:
        """ìœˆë„ìš° ì„¤ëª…"""
        lookback_days = int(252 * self.lookback_years) + self.rolling_window_days
        end_idx = self._resolve_asof_index(asof_date)
        start_idx = max(0, end_idx - lookback_days + 1)
        idx = self.rets.index
        return {
            "lookback_years": self.lookback_years,
            "rolling_window_days": self.rolling_window_days,
            "use_exponential_weighting": self.use_ewm,
            "ewm_halflife_days": self.ewm_halflife if self.use_ewm else None,
            "start_date": idx[start_idx] if len(idx) else None,
            "end_date": idx[end_idx] if len(idx) else None,
            "z_default": self.z_default,
        }


# =============================================================================
# ë¦¬ìŠ¤í¬ ì œì•½ ì ìš© ì¼ë³„ ìˆ˜ìµë¥  ì¬ê³„ì‚° (cap=ì‚¬ì´ì¦ˆ ì§ê²° + í˜¸í™˜ ì»¬ëŸ¼ í¬í•¨)
# =============================================================================
def calculate_daily_returns_with_constraint(
        returns_by_asset: pd.DataFrame,
        views_timeline: pd.DataFrame,
        w_bmk_daily: pd.DataFrame,
        w_opt_daily: pd.DataFrame,
        start_date: pd.Timestamp,
        end_date: pd.Timestamp,
        constraint_method: str,
        lookback_years: int = 3,
        kappa_mode: str = "cash-aware",
        sizing_mode: str = "full_cap", # "cash-aware" | "symmetric"
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    ë¦¬ìŠ¤í¬ ì œì•½ì„ ì ìš©í•˜ì—¬ ì¼ë³„ ìˆ˜ìµë¥  ì¬ê³„ì‚° (íŒ¨ì¹˜ ë²„ì „)
    - ì›ë³¸ Optimal êµ¬ì¡° ìœ ì§€í•œ ì±„ pairë³„ per-leg capë§Œ clip ë°©ì‹ìœ¼ë¡œ ì ìš©
    - ìˆ í¬ì§€ì…˜ ìœ ì§€ (ìŒìˆ˜ ì œê±° ì•ˆ í•¨)
    - FX-vs-Cash ë“± 'í•œìª½ë§Œ ìœ„í—˜'ì¸ í˜ì–´ëŠ” kappa_mode="cash-aware"ë¡œ ì²˜ë¦¬

    Parameters
    ----------
    returns_by_asset : ì¼ë³„ ìì‚° ìˆ˜ìµë¥ (ì†Œìˆ˜)
    views_timeline   : í™œì„± pair/Signal/ê¸°ê°„ ì •ë³´
      í•„ìˆ˜ ì»¬ëŸ¼ ì˜ˆì‹œ: ["Long_Asset","Short_Asset","Signal","Start_Date","End_Date","Pair_ID"(ì„ íƒ)]
      ì„ íƒ ì»¬ëŸ¼: ["Is_Cash_Pair"] (ìˆìœ¼ë©´ cash-aware íŒì •ì— ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    w_bmk_daily      : ì¼ë³„ ë²¤ì¹˜ë§ˆí¬ ê°€ì¤‘ì¹˜
    w_opt_daily      : ì¼ë³„ ìµœì  ê°€ì¤‘ì¹˜(ì›ë³¸)
    start_date       : ì‹œì‘ì¼
    end_date         : ì¢…ë£Œì¼
    constraint_method: ë¦¬ìŠ¤í¬ ë‹¨ìœ„ ê³„ì‚° ë°©ë²•(ì˜ˆ: "zscore_vol", "recent_vol" ë“± í´ë˜ìŠ¤ ë‚´ë¶€ êµ¬í˜„ê³¼ ì¼ì¹˜)
    lookback_years   : ë¦¬ìŠ¤í¬ ë‹¨ìœ„ ë¡¤ë§ ìœˆë„ìš° ê¸¸ì´(ë…„)
    kappa_mode       : "cash-aware" ë˜ëŠ” "symmetric"

    Returns
    -------
    daily_returns_df : (Portfolio_Return, Benchmark_Return, Active_Return)
    position_changes_df : í˜ì–´ë³„ ì¼ì/ì‚¬ì´ì¦ˆ/ì†ì‹¤ í—ˆìš©/ì‹¤ì¸¡ ë¦¬ìŠ¤í¬ ë“± ìƒì„¸ ë¡œê·¸
                          â€» KeyError ë°©ì§€ìš© 'Total_Active_bp' í¬í•¨
    """
    if returns_by_asset.empty or views_timeline.empty:
        return pd.DataFrame(), pd.DataFrame()

    # ë‚ ì§œ í•„í„°
    mask = (returns_by_asset.index >= start_date) & (returns_by_asset.index <= end_date)
    dates = returns_by_asset.index[mask]
    if len(dates) == 0:
        return pd.DataFrame(), pd.DataFrame()

    assets_list = returns_by_asset.columns.tolist()
    risk_calc = RiskConstraintCalculator(returns_by_asset, lookback_years=lookback_years)

    portfolio_returns: List[float] = []
    benchmark_returns: List[float] = []
    active_returns: List[float] = []
    used_dates: List[pd.Timestamp] = []
    position_records: List[Dict[str, Any]] = []

    # --- ê°„ë‹¨í•œ í˜„ê¸ˆ/í˜„ê¸ˆì„± ì¶”ì •(í´ë°±) ---
    def _is_cashish(name: str) -> bool:
        if name is None:
            return False
        s = str(name).upper()
        # ë„ˆë¬´ ê³µê²©ì ì´ì§€ ì•Šë„ë¡ 'USDJPY' ê°™ì€ FX ì¢…ëª©ì„ ì˜¤íƒí•˜ì§€ ì•Šê²Œ íŒ¨í„´ ì œí•œ
        cash_tokens = (" CASH", "CASH ", "T-BILL", "TBILL", "MMF", "CALL", "KTB 3M", "UST 3M", "BILLS")
        return any(tok in s for tok in cash_tokens) or s.strip() in {"CASH", "USD CASH", "KRW CASH"}

    for date in dates:
        if date not in returns_by_asset.index:
            continue
        daily_returns = returns_by_asset.loc[date]

        # â”€â”€ ë²¤ì¹˜ë§ˆí¬ ê°€ì¤‘ì¹˜ êµ¬í•˜ê¸°(í•´ë‹¹ì¼ ì—†ìœ¼ë©´ ì§ì „ì¼ ì‚¬ìš©) â”€â”€
        if not w_bmk_daily.empty:
            if date in w_bmk_daily.index:
                w_bmk = w_bmk_daily.loc[date].reindex(assets_list).fillna(0.0)
            else:
                prev_idx = w_bmk_daily.index[w_bmk_daily.index <= date]
                w_bmk = (w_bmk_daily.loc[prev_idx[-1]].reindex(assets_list).fillna(0.0)) if len(prev_idx) else pd.Series(0.0, index=assets_list)
        else:
            w_bmk = pd.Series(0.0, index=assets_list)

        # â”€â”€ ì›ë³¸ Optimal ê°€ì¤‘ì¹˜(í•´ë‹¹ì¼ ì—†ìœ¼ë©´ ì§ì „ì¼) â”€â”€
        if not w_opt_daily.empty:
            if date in w_opt_daily.index:
                w_opt_original = w_opt_daily.loc[date].reindex(assets_list).fillna(0.0)
            else:
                prev_idx = w_opt_daily.index[w_opt_daily.index <= date]
                w_opt_original = (w_opt_daily.loc[prev_idx[-1]].reindex(assets_list).fillna(0.0)) if len(prev_idx) else pd.Series(0.0, index=assets_list)
        else:
            w_opt_original = pd.Series(0.0, index=assets_list)

        # í•© 0 ë˜ëŠ” ìŒìˆ˜ ë°©ì§€ìš© ì •ê·œí™”(ë²¤ì¹˜ë§ˆí¬ë§Œ)
        bmk_sum = w_bmk.sum()
        if bmk_sum > 0:
            w_bmk = w_bmk / bmk_sum

        # ìµœì  ê°€ì¤‘ì¹˜ëŠ” Long/Short í•©ì´ 1ì´ ì•„ë‹ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‘ 
        w_active_original = (w_opt_original - w_bmk).reindex(assets_list).fillna(0.0)

        bmk_return = float((w_bmk * daily_returns).sum())

        # â”€â”€ í•´ë‹¹ì¼ í™œì„± ë·° ì¶”ì¶œ â”€â”€
        active_views = views_timeline.copy()
        if 'Start_Date' in active_views.columns:
            active_views = active_views[active_views['Start_Date'].fillna(pd.Timestamp.min) <= date]
        if 'End_Date' in active_views.columns:
            active_views = active_views[active_views['End_Date'].fillna(pd.Timestamp.max) >= date]
        active_views = active_views[active_views.get('Signal', 0) != 0]

        # ë·°ê°€ ì—†ìœ¼ë©´ ì œì•½ ì—†ì´ ì›ë³¸ìœ¼ë¡œ ê³„ì‚°
        if active_views.empty:
            port_return = float((w_opt_original * daily_returns).sum())
            portfolio_returns.append(port_return)
            benchmark_returns.append(bmk_return)
            active_returns.append(port_return - bmk_return)
            used_dates.append(date)
            continue

        # â”€â”€ Pair/Signal/ID ìˆ˜ì§‘ â”€â”€
        pairs: List[Tuple[str, str]] = [(str(r['Long_Asset']), str(r['Short_Asset'])) for _, r in active_views.iterrows()]
        signals = active_views['Signal'].astype(float).values
        pair_ids = active_views['Pair_ID'].values if 'Pair_ID' in active_views.columns else np.arange(len(pairs))

        # cash-aware íŒì • ì†ŒìŠ¤(ëª…ì‹œ ì»¬ëŸ¼ ìš°ì„ , ì—†ìœ¼ë©´ íœ´ë¦¬ìŠ¤í‹±)
        has_is_cash_pair_col = 'Is_Cash_Pair' in active_views.columns
        is_cash_pair_flags = []
        if has_is_cash_pair_col:
            is_cash_pair_flags = active_views['Is_Cash_Pair'].astype(bool).tolist()
        else:
            # íœ´ë¦¬ìŠ¤í‹±: ìì‚°ëª… í…ìŠ¤íŠ¸ ê¸°ë°˜
            is_cash_pair_flags = [_is_cashish(pa) or _is_cashish(pb) for (pa, pb) in pairs]

        # â”€â”€ incidence í–‰ë ¬ â”€â”€
        B = build_incidence_matrix(assets_list, pairs)   # shape (n_assets, n_pairs)
        if B.size == 0:
            # incidence ìƒì„± ì‹¤íŒ¨ ì‹œ ì›ë³¸ìœ¼ë¡œ
            port_return = float((w_opt_original * daily_returns).sum())
            portfolio_returns.append(port_return)
            benchmark_returns.append(bmk_return)
            active_returns.append(port_return - bmk_return)
            used_dates.append(date)
            continue

        # â”€â”€ ì›ë³¸ active weightsì—ì„œ pair per-leg ì‚¬ì´ì¦ˆ ì—­ì¶”ì • â”€â”€
        #     (B @ x = w_active_original, x_i = per-leg size; long leg +x, short leg -x)
        x_original = reconstruct_pair_sizes(w_active_original.values, B, signals)

        # â”€â”€ ë¦¬ìŠ¤í¬ ë‹¨ìœ„ì™€ per-leg cap ê³„ì‚°(â˜… íŒ¨ì¹˜ í•µì‹¬) â”€â”€
        #    ë‚ ì§œë³„ ë¡¤ë§ ìœˆë„ìš°ë¡œ constraint_values(=risk unit) & cap_arr ë°˜í™˜
        constraint_values, cap_arr = risk_calc.calculate_position_caps(
            pairs=pairs,
            signals=signals,
            constraint_method=constraint_method,
            asof_date=date,
            kappa_mode=kappa_mode,  # "cash-aware"ë©´ cash í˜ì–´ëŠ” leg_factor=1 ê¸°ì¤€ìœ¼ë¡œ cap ì‚°ì¶œ
        )

        # â”€â”€ Cap ì ìš©(clip) â”€â”€
        if sizing_mode == "clip":
            x_constrained = np.sign(x_original) * np.minimum(
                np.abs(x_original), np.asarray(cap_arr, dtype=float)

            )
        else:
            x_constrained = np.sign(signals) * np.asarray(cap_arr, dtype=float)

                # â”€â”€ ì œì•½ ì ìš©ëœ active weights ë³µì› â”€â”€
        w_active_constrained = pd.Series(B @ x_constrained, index=assets_list)

        # â”€â”€ ìµœì¢… í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜(ìˆ í—ˆìš©, í•©=1 ê°•ì œ X) â”€â”€
        w_portfolio = (w_bmk + w_active_constrained).reindex(assets_list).fillna(0.0)

        # â”€â”€ ì¼ë³„ ìˆ˜ìµë¥  â”€â”€
        port_return = float((w_portfolio * daily_returns).sum())
        act_return = port_return - bmk_return

        portfolio_returns.append(port_return)
        benchmark_returns.append(bmk_return)
        active_returns.append(act_return)
        used_dates.append(date)

        # â”€â”€ ë¡œê¹…(ì§„ë‹¨/ì‹œê°í™”ìš©) â”€â”€
        for i, (pid, (la, sa)) in enumerate(zip(pair_ids, pairs)):
            abs_signal = int(abs(round(float(signals[i]))))
            # í—ˆìš©ì†ì‹¤ bp (í´ë˜ìŠ¤ ë‚´ë¶€ ê·œì¹™ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
            max_loss_bp = risk_calc.get_max_loss_bp(signals[i])

            # per-leg í¬ì§€ì…˜(ì†Œìˆ˜)
            per_leg_orig = float(x_original[i])
            per_leg_cap  = float(cap_arr[i])
            per_leg_new  = float(x_constrained[i])

            # cash-awareë©´ í•œìª½ ë ˆê·¸ë§Œ ìœ„í—˜ â†’ ì´ ìµìŠ¤í¬ì € ì§‘ê³„ ì‹œ leg_factor=1
            leg_factor = 1 if (kappa_mode == "cash-aware" and bool(is_cash_pair_flags[i])) else 2

            # ì´ ì•¡í‹°ë¸Œ(ì†Œìˆ˜)ì™€ ë¦¬ìŠ¤í¬/ì†ì‹¤
            total_active_abs = abs(per_leg_new) * leg_factor
            # constraint_values[i] = risk unit (ì˜ˆ: z*Ïƒ) in decimal
            risk_unit = float(constraint_values[i])
            actual_loss = total_active_abs * abs(risk_unit)  # ì†Œìˆ˜ ê¸°ì¤€
            # bp ë³€í™˜
            per_leg_orig_bp = per_leg_orig * 10_000.0
            per_leg_new_bp  = per_leg_new  * 10_000.0
            total_active_bp = total_active_abs * 10_000.0
            actual_loss_bp  = actual_loss * 10_000.0

            position_records.append({
                "Date": date,
                "Pair_ID": pid,
                "Pair": f"{la} vs {sa}",
                "Signal": float(signals[i]),
                "Signal_Abs": abs_signal,
                "Kappa_Mode": kappa_mode,
                "Is_Cash_Pair": bool(is_cash_pair_flags[i]),
                "Leg_Factor": leg_factor,  # 1 (cash-aware) or 2 (symmetric)
                "Risk_Unit": risk_unit,  # ì†Œìˆ˜ (ì˜ˆ: 0.031 = 3.1%)
                "Constraint_Value_%": risk_unit * 100.0,  # % í‘œì‹œìš©
                "Max_Loss_bp": float(max_loss_bp),  # í—ˆìš©ì†ì‹¤(bp)

                # --- per-leg í¬ì§€ì…˜(bp) ê´€ë ¨: ì›ë³¸/ìº¡/í‘œì¤€ ì´ë¦„ ëª¨ë‘ ê¸°ë¡ ---
                "Original_per_leg_bp": per_leg_orig_bp,
                "Capped_per_leg_bp": per_leg_new_bp,
                "Position_per_leg_bp": per_leg_new_bp,  # â† UIê°€ ê¸°ëŒ€í•˜ëŠ” í‘œì¤€ ì´ë¦„ (ì‹¤ì œ ì ìš©ì¹˜)

                # --- ì´ ìµìŠ¤í¬ì €/ì†ì‹¤ (bp) ---
                "Total_Active_bp": total_active_bp,
                "Total_Notional_bp": total_active_bp,  # â† UIì˜ ë‹¤ë¥¸ í‘œì¤€ ì´ë¦„ë„ í•¨ê»˜ ê¸°ë¡
                "Actual_Loss_bp": actual_loss_bp,

                "Capped": bool(abs(per_leg_orig) > per_leg_cap),
                "Benchmark_Sum": float(w_bmk.sum()),
                "Portfolio_Sum": float(w_portfolio.sum()),
                "Active_Sum": float(w_active_constrained.sum()),
            })

    daily_returns_df = pd.DataFrame({
        "Portfolio_Return": portfolio_returns,
        "Benchmark_Return": benchmark_returns,
        "Active_Return": active_returns,
    }, index=pd.Index(used_dates, name="Date")).sort_index()

    position_changes_df = pd.DataFrame(position_records).sort_values(["Date", "Pair_ID"]) if position_records else pd.DataFrame()

    position_changes_df = pd.DataFrame(position_records).sort_values(
        ["Date", "Pair_ID"]) if position_records else pd.DataFrame()

    # === ì»¬ëŸ¼ ë³„ì¹­/ê²°ì¸¡ ë³´ê°• (ê³¼ê±° ìºì‹œ/CSV í˜¸í™˜ ëª©ì ) ===
    if not position_changes_df.empty:
        if "Position_per_leg_bp" not in position_changes_df.columns and "Capped_per_leg_bp" in position_changes_df.columns:
            position_changes_df["Position_per_leg_bp"] = position_changes_df["Capped_per_leg_bp"]

        if "Total_Notional_bp" not in position_changes_df.columns and "Total_Active_bp" in position_changes_df.columns:
            position_changes_df["Total_Notional_bp"] = position_changes_df["Total_Active_bp"]

    return daily_returns_df, position_changes_df

# =============================================================================
# TE/Vol ê³„ì‚° í•¨ìˆ˜ (ë¦¬ìŠ¤í¬ ì œì•½ ë°©ë²• í†µí•©)
# =============================================================================
def calculate_expected_tracking_error_with_constraint(
        views_df: pd.DataFrame,
        weights_df: pd.DataFrame,
        cov_matrix: pd.DataFrame,
        returns_by_asset: pd.DataFrame,
        Wopt_last: pd.Series,
        Wbmk_last: pd.Series,
        constraint_method: str = "3Y_MDD",
        lookback_years: int = 3
) -> Tuple[float, pd.DataFrame]:
    """
    ì„ íƒí•œ ë¦¬ìŠ¤í¬ ì œì•½ ë°©ë²•ì— ë”°ë¥¸ TE ê³„ì‚°

    Args:
        constraint_method: "3Y_MDD", "-3STD", "-2STD", "-1STD"

    Returns:
        (TE, debug_df): TE ê°’ê³¼ ë””ë²„ê¹… ì •ë³´ DataFrame
    """
    if cov_matrix.empty or weights_df.empty or returns_by_asset.empty:
        return 0.0, pd.DataFrame()

    if Wopt_last.empty or Wbmk_last.empty:
        return 0.0, pd.DataFrame()

    try:
        # ìì‚° ë¦¬ìŠ¤íŠ¸
        assets_list = [a for a in Wopt_last.index if a in returns_by_asset.columns]
        if len(assets_list) == 0:
            return 0.0, pd.DataFrame()

        Wact_current = (Wopt_last - Wbmk_last).reindex(assets_list).fillna(0.0)

        # Active views í•„í„°ë§ (Signal != 0)
        active_views = views_df[views_df['Signal'] != 0].copy()

        if active_views.empty:
            # Signalì´ ì—†ìœ¼ë©´ í˜„ì¬ TE ë°˜í™˜
            cov = cov_matrix.reindex(index=assets_list, columns=assets_list).fillna(0.0).values
            w = Wact_current.values
            te_variance = float(w @ cov @ w)
            te = float(np.sqrt(max(0.0, te_variance)))
            return te, pd.DataFrame()

        # Pair ì •ë³´ ì¶”ì¶œ
        pairs = [(str(row['Long_Asset']), str(row['Short_Asset'])) for _, row in active_views.iterrows()]
        signals = active_views['Signal'].astype(float).values
        pair_ids = active_views.get('Pair_ID', range(len(pairs))).values

        # Incidence matrix ìƒì„±
        B = build_incidence_matrix(assets_list, pairs)
        if B.size == 0:
            cov = cov_matrix.reindex(index=assets_list, columns=assets_list).fillna(0.0).values
            w = Wact_current.values
            te_variance = float(w @ cov @ w)
            te = float(np.sqrt(max(0.0, te_variance)))
            return te, pd.DataFrame()

        # ë¦¬ìŠ¤í¬ ì œì•½ ê³„ì‚°
        risk_calc = RiskConstraintCalculator(returns_by_asset, lookback_years=lookback_years)
        constraint_values, cap_arr = risk_calc.calculate_position_caps(pairs, signals, constraint_method)

        # Signal ë°©í–¥ ì ìš©
        x_pair = np.sign(signals) * cap_arr

        # Active weights ì¬êµ¬ì„±
        Wact_new = pd.Series(B @ x_pair, index=assets_list)

        # TE ê³„ì‚°
        cov = cov_matrix.reindex(index=assets_list, columns=assets_list).fillna(0.0).values
        w = Wact_new.values
        te_variance = float(w @ cov @ w)
        te = float(np.sqrt(max(0.0, te_variance)))

        # Signalì— ë”°ë¥¸ ìµœëŒ€ ì†ì‹¤ í—ˆìš©ì¹˜
        max_loss_per_pair = np.zeros(len(pairs))
        for i, signal in enumerate(signals):
            abs_signal = abs(signal)
            if abs_signal >= 2.0:
                max_loss_per_pair[i] = 0.15
            elif abs_signal >= 1.0:
                max_loss_per_pair[i] = 0.10
            else:
                max_loss_per_pair[i] = 0.10 + (abs_signal) * 0.05

        # ë””ë²„ê¹… ì •ë³´ ìƒì„±
        constraint_col_name = {
            "3Y_MDD": "MDD_%",
            "-3STD": "-3STD_%",
            "-2STD": "-2STD_%",
            "-1STD": "-1STD_%"
        }[constraint_method]

        debug_df = pd.DataFrame({
            'Pair_ID': pair_ids,
            'Pair': [f"{p[0]} vs {p[1]}" for p in pairs],
            'Signal': signals,
            constraint_col_name: (constraint_values * 100).round(2),
            'Max_Loss_bp': max_loss_per_pair.round(3),
            'Position_bp': (x_pair * 10000).round(3),
            'Actual_Loss_bp': (np.abs(x_pair) * np.abs(constraint_values) * 10000).round(3)
        })

        return te, debug_df

    except Exception as e:
        st.warning(f"TE ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0, pd.DataFrame()


def calculate_expected_volatility_with_constraint(
        views_df: pd.DataFrame,
        weights_df: pd.DataFrame,
        cov_matrix: pd.DataFrame,
        returns_by_asset: pd.DataFrame,
        Wopt_last: pd.Series,
        Wbmk_last: pd.Series,
        constraint_method: str = "3Y_MDD",
        lookback_years: int = 3
) -> float:
    """
    ì„ íƒí•œ ë¦¬ìŠ¤í¬ ì œì•½ ë°©ë²•ì— ë”°ë¥¸ ë³€ë™ì„± ê³„ì‚°

    ì¤‘ìš”: Benchmarkê°€ 0ì´ë©´ Portfolio Vol = TEì™€ ê°™ì•„ì•¼ í•¨
    """
    if cov_matrix.empty or returns_by_asset.empty:
        return 0.0

    if Wopt_last.empty or Wbmk_last.empty:
        return 0.0

    try:
        assets_list = [a for a in Wopt_last.index if a in returns_by_asset.columns]
        if len(assets_list) == 0:
            return 0.0

        # TE ê³„ì‚°ì—ì„œ Active weightsë¥¼ ê°€ì ¸ì˜´
        te, debug_df = calculate_expected_tracking_error_with_constraint(
            views_df, weights_df, cov_matrix, returns_by_asset,
            Wopt_last, Wbmk_last, constraint_method, lookback_years
        )

        # Benchmark weights í™•ì¸
        Wbmk = Wbmk_last.reindex(assets_list).fillna(0.0)
        bm_sum = Wbmk.sum()

        # Benchmarkê°€ ê±°ì˜ 0ì´ë©´ (100% Cash), Vol = TE
        if abs(bm_sum) < 0.001:
            return te

        # Benchmarkê°€ ìˆëŠ” ê²½ìš° Portfolio Vol ê³„ì‚°
        # Active weights ì¬êµ¬ì„±
        Wact_new = pd.Series(0.0, index=assets_list)
        if not debug_df.empty:
            active_views = views_df[views_df['Signal'] != 0].copy()
            if not active_views.empty:
                pairs = [(str(row['Long_Asset']), str(row['Short_Asset']))
                         for _, row in active_views.iterrows()]
                B = build_incidence_matrix(assets_list, pairs)
                if B.size > 0:
                    x_pair = debug_df['Position_bp'].values / 10000
                    Wact_new = pd.Series(B @ x_pair, index=assets_list)

        # Portfolio = Benchmark + Active
        Wopt_new = Wbmk + Wact_new

        # ìŒìˆ˜ ì œê±° ë° ì •ê·œí™”
        Wopt_new = np.maximum(Wopt_new, 0)
        s = Wopt_new.sum()
        if s > 0:
            Wopt_new = Wopt_new / s
        else:
            return te

        # Portfolio Vol ê³„ì‚°
        cov = cov_matrix.reindex(index=assets_list, columns=assets_list).fillna(0.0).values
        portfolio_variance = float(Wopt_new.values @ cov @ Wopt_new.values)
        portfolio_vol = float(np.sqrt(max(0.0, portfolio_variance)))

        return portfolio_vol

    except Exception as e:
        st.warning(f"Vol ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0


def calculate_expected_volatility(views_df: pd.DataFrame, weights_df: pd.DataFrame, cov_matrix: pd.DataFrame) -> float:
    """í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„± ê³„ì‚° (ì—°ìœ¨, ì†Œìˆ˜) - Fallbackìš©"""
    if cov_matrix.empty or weights_df.empty:
        return 0.0
    try:
        assets = weights_df["Asset"].astype(str).tolist()
        cov = cov_matrix.reindex(index=assets, columns=assets).fillna(0.0).values

        opt_weights = calculate_portfolio_weights(views_df, weights_df)
        if len(opt_weights) == 0:
            return 0.0

        portfolio_variance = float(opt_weights @ cov @ opt_weights)
        portfolio_vol = float(np.sqrt(max(0.0, portfolio_variance)))
        return portfolio_vol
    except Exception as e:
        st.warning(f"Vol ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0


def calculate_expected_tracking_error(views_df: pd.DataFrame, weights_df: pd.DataFrame,
                                      cov_matrix: pd.DataFrame) -> float:
    """TE ê³„ì‚° (Fallbackìš©)"""
    if cov_matrix.empty or weights_df.empty:
        return 0.0

    try:
        assets = weights_df["Asset"].astype(str).tolist()
        n_assets = len(assets)

        # Benchmark weights
        if "Benchmark_Weight" not in weights_df.columns:
            return 0.0

        bm_weights = pd.to_numeric(weights_df["Benchmark_Weight"], errors="coerce").fillna(0.0).values

        # Optimal weights
        opt_weights = calculate_portfolio_weights(views_df, weights_df)
        if len(opt_weights) == 0:
            return 0.0

        # Active weights
        active_weights = opt_weights - bm_weights

        # TE ê³„ì‚°
        cov = cov_matrix.reindex(index=assets, columns=assets).fillna(0.0).values
        te_variance = float(active_weights @ cov @ active_weights)
        te = float(np.sqrt(max(0.0, te_variance)))

        return te
    except Exception as e:
        st.warning(f"TE ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0


def compute_te_from_active_direct(active_weights: np.ndarray, cov_matrix: pd.DataFrame, assets: List[str]) -> float:
    """Active weightë¡œë¶€í„° ì§ì ‘ TE ê³„ì‚°"""
    if cov_matrix.empty or len(active_weights) == 0:
        return 0.0
    try:
        cov = cov_matrix.reindex(index=assets, columns=assets).fillna(0.0).values
        te_variance = float(active_weights @ cov @ active_weights)
        te_annual = float(np.sqrt(max(0.0, te_variance)))
        return te_annual
    except Exception:
        return 0.0


# =============================================================================
# ì‹œì¥ ë°ì´í„° ë¡œë”
# =============================================================================
def load_market_returns_csv(csv_path: str, asset_names: list, excel_path: str = None) -> pd.DataFrame:
    """ì‹œì¥ ìˆ˜ìµë¥  ë°ì´í„° ë¡œë“œ"""
    CASH_ANNUAL_RETURN = 0.025
    TRADING_DAYS = 252

    if not os.path.isfile(csv_path):
        st.warning(f"ì‹œì¥ ë°ì´í„° CSVê°€ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        return pd.DataFrame()

    df = pd.read_csv(csv_path, encoding='utf-8')
    dcol = None
    for c in df.columns:
        if _norm(c) in {"date", "ë‚ ì§œ"}:
            dcol = c
            break

    if dcol is None:
        st.warning("CSVì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    df[dcol] = pd.to_datetime(df[dcol], errors="coerce")
    df = df.dropna(subset=[dcol]).sort_values(dcol).set_index(dcol)

    # Ticker ë§¤í•‘
    ticker_mapping = {}
    if excel_path and os.path.isfile(excel_path):
        try:
            xls = pd.ExcelFile(excel_path, engine="openpyxl")
            if "Asset_Universe" in xls.sheet_names:
                au = pd.read_excel(xls, "Asset_Universe")
                au_cols = {c.lower().replace('_', '').replace(' ', ''): c for c in au.columns}
                col_name = None
                col_ticker = None
                for possible_name in ["assetname", "asset", "name"]:
                    if possible_name in au_cols:
                        col_name = au_cols[possible_name]
                        break
                for possible_ticker in ["bloombergticker", "ticker", "bloomberg", "symbol"]:
                    if possible_ticker in au_cols:
                        col_ticker = au_cols[possible_ticker]
                        break
                if col_name and col_ticker:
                    for _, row in au.iterrows():
                        asset_name = str(row[col_name]).strip()
                        ticker = str(row[col_ticker]).strip()
                        ticker_mapping[asset_name] = ticker
                    st.success(f"âœ… Asset_Universeì—ì„œ {len(ticker_mapping)}ê°œ Bloomberg Ticker ë§¤í•‘ ë¡œë“œ")
        except Exception as e:
            st.error(f"Asset_Universe ë¡œë“œ ì‹¤íŒ¨: {e}")

    ret = pd.DataFrame(index=df.index)
    matched, not_matched, cash_assets = [], [], []

    for asset_name in asset_names:
        if is_cash_asset(asset_name):
            daily_return = CASH_ANNUAL_RETURN / TRADING_DAYS
            ret[asset_name] = daily_return
            cash_assets.append(asset_name)
            matched.append(f"âœ… {asset_name} â† {CASH_ANNUAL_RETURN * 100:.2f}% ì—°ê°„ ìˆ˜ìµë¥  (Cash)")
            continue

        ticker = ticker_mapping.get(asset_name)
        if ticker:
            found = False
            if ticker in df.columns:
                ret[asset_name] = df[ticker]
                matched.append(f"âœ… {asset_name} â† {ticker}")
                found = True
            else:
                for col in df.columns:
                    if col.lower() == ticker.lower():
                        ret[asset_name] = df[col]
                        matched.append(f"âœ… {asset_name} â† {col}")
                        found = True
                        break
                if not found:
                    ticker_base = ticker.replace(" Index", "").replace(" Comdty", "").replace(" Curncy", "")
                    for col in df.columns:
                        col_base = col.replace(" Index", "").replace(" Comdty", "").replace(" Curncy", "")
                        if col_base.lower() == ticker_base.lower():
                            ret[asset_name] = df[col]
                            matched.append(f"âœ… {asset_name} â† {col}")
                            found = True
                            break
            if not found:
                not_matched.append(f"âŒ {asset_name} (Ticker: {ticker})")
        else:
            if asset_name in df.columns:
                ret[asset_name] = df[asset_name]
                matched.append(f"âœ… {asset_name} â† {asset_name} (ì§ì ‘ ë§¤ì¹­)")
            else:
                not_matched.append(f"âŒ {asset_name} (Ticker ì—†ìŒ)")

    if matched:
        with st.expander(f"âœ… ë§¤ì¹­ ì„±ê³µ ({len(matched)}ê°œ)", expanded=False):
            for m in matched:
                st.text(m)
    if not_matched:
        with st.expander(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨ ({len(not_matched)}ê°œ)", expanded=False):
            for nm in not_matched:
                st.text(nm)

    if ret.empty:
        st.error("âš ï¸ ë§¤ì¹­ëœ ìì‚°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return ret

    for col in ret.columns:
        if col not in cash_assets:
            ret[col] = ret[col].ffill().bfill().pct_change()

    ret = ret.dropna()

    if cash_assets:
        st.info(f"ğŸ’µ Cash ìì‚° ({', '.join(cash_assets)}): ì—°ê°„ {CASH_ANNUAL_RETURN * 100:.2f}% ìˆ˜ìµë¥ ë¡œ ì²˜ë¦¬")

    st.success(f"ğŸ“ˆ {len(ret.columns)}ê°œ ìì‚°ì˜ ìˆ˜ìµë¥  ë°ì´í„° ìƒì„± ì™„ë£Œ")
    return ret


# =============================================================================
# Excel Views ë¡œë”
# =============================================================================
def load_views_from_excel(excel_path: str) -> pd.DataFrame:
    """Excelì—ì„œ Views ì •ë³´ ë¡œë“œ"""
    if not os.path.isfile(excel_path):
        return pd.DataFrame()
    try:
        xls = pd.ExcelFile(excel_path, engine="openpyxl")
        vt = pd.read_excel(xls, "Views_Timeline")
        pddef = pd.read_excel(xls, "Pairs_Definition")
        au = pd.read_excel(xls, "Asset_Universe")
    except Exception as e:
        st.warning(f"ì—‘ì…€ ë¡œë”© ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

    au_cols = {c.lower(): c for c in au.columns}
    col_id = au_cols.get("asset_id") or au_cols.get("id")
    col_nm = au_cols.get("asset_name") or au_cols.get("name")
    if col_id is None or col_nm is None:
        st.warning("Asset_Universe ì‹œíŠ¸ì— Asset_ID/Asset_Name í•„ìˆ˜")
        return pd.DataFrame()
    id2name = dict(zip(au[col_id], au[col_nm].astype(str)))

    pd_cols = {c.lower(): c for c in pddef.columns}
    col_pair = pd_cols.get("pair_id") or pd_cols.get("pair")
    col_long = pd_cols.get("long_asset_id") or pd_cols.get("long_id")
    col_short = pd_cols.get("short_asset_id") or pd_cols.get("short_id")
    if col_pair is None or col_long is None or col_short is None:
        st.warning("Pairs_Definition ì‹œíŠ¸ì— Pair_ID/Long_Asset_ID/Short_Asset_ID í•„ìˆ˜")
        return pd.DataFrame()

    mp = pddef[[col_pair, col_long, col_short]].copy()
    mp["Long_Asset"] = mp[col_long].map(id2name).astype(str)
    mp["Short_Asset"] = mp[col_short].map(id2name).astype(str)
    mp = mp.rename(columns={col_pair: "Pair_ID"}).drop(columns=[col_long, col_short])

    vt_cols = {c.lower(): c for c in vt.columns}
    need = ["pair_id", "signal"]
    if not all(k in vt_cols for k in need):
        st.warning("Views_Timeline ì‹œíŠ¸ì— Pair_ID/Signal í•„ìˆ˜")
        return pd.DataFrame()

    v = vt.rename(columns={vt_cols["pair_id"]: "Pair_ID", vt_cols["signal"]: "Signal"}).copy()
    v["Signal"] = pd.to_numeric(v["Signal"], errors="coerce").fillna(0.0)

    if "start_date" in vt_cols:
        v["Start_Date"] = _safe_dt(v[vt_cols["start_date"]])
    else:
        v["Start_Date"] = pd.NaT

    if "end_date" in vt_cols:
        v["End_Date"] = _safe_dt(v[vt_cols["end_date"]])
    else:
        v["End_Date"] = pd.NaT

    if "status" in vt_cols:
        v["Status"] = v[vt_cols["status"]].astype(str)
    else:
        v["Status"] = "Active"

    out = v.merge(mp, on="Pair_ID", how="left", validate="many_to_one")
    out = out.dropna(subset=["Long_Asset", "Short_Asset"]).copy()
    return out[["Pair_ID", "Long_Asset", "Short_Asset", "Signal", "Start_Date", "End_Date", "Status"]]


def load_active_views_from_timeline(timeline_csv: pd.DataFrame, asof: pd.Timestamp) -> pd.DataFrame:
    """íƒ€ì„ë¼ì¸ì—ì„œ í™œì„± ë·° ì¶”ì¶œ"""
    if timeline_csv is None or timeline_csv.empty:
        return pd.DataFrame()

    v = timeline_csv.copy()
    for c in ["Start_Date", "End_Date"]:
        if c in v.columns:
            v[c] = _safe_dt(v[c])
        else:
            v[c] = pd.NaT

    v["Signal"] = pd.to_numeric(v.get("Signal", 0.0), errors="coerce").fillna(0.0)
    mask = (v["Start_Date"].fillna(pd.Timestamp.min) <= asof) & (v["End_Date"].fillna(pd.Timestamp.max) >= asof)
    v = v[mask].copy()

    keep_cols = [c for c in
                 ["Pair_ID", "Long_Asset", "Short_Asset", "Signal", "Start_Date", "End_Date", "Reason", "Status"] if
                 c in v.columns]
    return v[keep_cols]


# =============================================================================
# CSV ë°ì´í„° ë¡œë”
# =============================================================================
@st.cache_data
def load_csv_data(data_dir: str):
    """CSV íŒŒì¼ë“¤ ë¡œë“œ"""
    if not os.path.isdir(data_dir):
        raise FileNotFoundError(f"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_dir}")

    files = os.listdir(data_dir)
    stem_to_file = {}
    for f in files:
        name, ext = os.path.splitext(f)
        if ext.lower() in [".csv", ".xlsx", ".xls"]:
            stem_to_file[name.lower()] = f

    def _find(stem: str):
        cand = stem_to_file.get(stem.lower())
        return None if not cand else os.path.join(data_dir, cand)

    def _read_table(path: str, index_col=None) -> pd.DataFrame:
        _, ext = os.path.splitext(path)
        try:
            if ext.lower() == ".csv":
                df = pd.read_csv(path, index_col=index_col, encoding="utf-8-sig")
            else:
                df = pd.read_excel(path, index_col=index_col, engine="openpyxl")
            return df
        except Exception as e:
            st.warning(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {path} - {e}")
            return pd.DataFrame()

    data = {}
    missing = []

    # í•„ìˆ˜ íŒŒì¼
    required_stems = [
        "portfolio_weights",
        "performance_metrics",
        "expected_returns",
        "asset_rankings",
        "covariance_matrix",
    ]
    for stem in required_stems:
        p = _find(stem)
        if p:
            idx_col = 0 if stem == "covariance_matrix" else None
            df = _read_table(p, index_col=idx_col)
            data[stem] = df
        else:
            missing.append(stem)
            data[stem] = pd.DataFrame()

    # ì„ íƒ íŒŒì¼
    optional_stems = [
        "active_views",
        "attractiveness_scores",
        "daily_returns_series",
        "daily_weights_optimal",
        "daily_weights_benchmark",
        "weights_checkpoints",
        "rebalance_log",
        "rebalance_calendar",
        "weight_history",
        "view_timeline_history",
        "attribution_report",
        "attribution_summary",
        "pair_mdd_report",
        "pair_constraints",
    ]
    for opt_stem in optional_stems:
        p = _find(opt_stem)
        if p:
            if opt_stem in [
                "daily_returns_series", "daily_weights_optimal", "daily_weights_benchmark",
                "weights_checkpoints", "weight_history"
            ]:
                df = _read_table(p, index_col=0)
                if not df.empty:
                    try:
                        df.index = pd.to_datetime(df.index)
                    except Exception:
                        pass
                data[opt_stem] = df
            else:
                data[opt_stem] = _read_table(p, index_col=None)
        else:
            data[opt_stem] = pd.DataFrame()

    # ë‚ ì§œ ë³€í™˜
    if "rebalance_log" in data and not data["rebalance_log"].empty:
        if "Rebalance_Date" in data["rebalance_log"].columns:
            try:
                data["rebalance_log"]["Rebalance_Date"] = pd.to_datetime(data["rebalance_log"]["Rebalance_Date"],
                                                                         errors='coerce')
            except Exception:
                pass

    if "rebalance_calendar" in data and not data["rebalance_calendar"].empty:
        if "Rebalance_Date" in data["rebalance_calendar"].columns:
            try:
                data["rebalance_calendar"]["Rebalance_Date"] = pd.to_datetime(
                    data["rebalance_calendar"]["Rebalance_Date"], errors='coerce')
            except Exception:
                pass

    # ìˆ˜ì¹˜ ë³€í™˜
    if "performance_metrics" in data and not data["performance_metrics"].empty:
        try:
            pm = data["performance_metrics"].copy()
            pm.columns = [str(c).strip() for c in pm.columns]
            if "Value" in pm.columns:
                pm["Value"] = pm["Value"].apply(_to_float)
            data["performance_metrics"] = pm
        except Exception:
            pass

    if "portfolio_weights" in data and not data["portfolio_weights"].empty:
        try:
            pw = data["portfolio_weights"].copy()
            for col in ["Optimal_Weight", "Benchmark_Weight", "Active_Weight"]:
                if col in pw.columns:
                    pw[col] = pw[col].apply(_to_float)
            data["portfolio_weights"] = pw
        except Exception:
            pass

    # ë¡œë“œ ì •ë³´ í‘œì‹œ
    loaded = [k for k in data.keys() if not data[k].empty]
    if loaded:
        st.sidebar.info(
            "ğŸ“‚ ë¡œë“œëœ íŒŒì¼:\n" +
            "\n".join([f"âœ… {k}" for k in loaded[:8]]) +
            (f"\n... ì™¸ {len(loaded) - 8}ê°œ" if len(loaded) > 8 else "")
        )
    if missing:
        st.sidebar.warning("âš ï¸ ëˆ„ë½ëœ í•„ìˆ˜ íŒŒì¼:\n" + "\n".join([f"âŒ {m}" for m in missing[:3]]))

    return data


# =============================================================================
# ë¦¬ìŠ¤í¬ ì œì•½ ë°©ë²•ì— ë”°ë¥¸ ì¼ë³„ ìˆ˜ìµë¥  ì¬ê³„ì‚°
# =============================================================================


# =============================================================================
# ì¼ë³„ ì„±ê³¼ ì‹œê°í™” í•¨ìˆ˜ (ìˆ˜ì •)
# =============================================================================
def display_daily_returns(
        daily_returns_original: pd.DataFrame,
        daily_returns_constrained: pd.DataFrame,
        position_changes_df: pd.DataFrame,
        constraint_method: str,
        inception_date: pd.Timestamp = None
):
    """
    ì¼ë³„ ìˆ˜ìµë¥  ì‹œê°í™” (ì›ë³¸ vs ì œì•½ ì ìš© ë¹„êµ)

    Args:
        daily_returns_original: ì›ë³¸ ì¼ë³„ ìˆ˜ìµë¥ 
        daily_returns_constrained: ì œì•½ ì ìš© ì¼ë³„ ìˆ˜ìµë¥ 
        position_changes_df: í¬ì§€ì…˜ ë³€í™” ì¶”ì 
        constraint_method: ì ìš©ëœ ì œì•½ ë°©ë²•
        inception_date: Inception Date
    """
    if daily_returns_original.empty and daily_returns_constrained.empty:
        st.info("ì¼ë³„ ìˆ˜ìµë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # Inception Date í•„í„°ë§
    if inception_date is not None:
        if not daily_returns_original.empty:
            daily_returns_original = daily_returns_original[
                daily_returns_original.index >= inception_date
                ].copy()
        if not daily_returns_constrained.empty:
            daily_returns_constrained = daily_returns_constrained[
                daily_returns_constrained.index >= inception_date
                ].copy()

        if daily_returns_original.empty and daily_returns_constrained.empty:
            st.warning(f"âš ï¸ {inception_date.date()} ì´í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

    try:
        # ì œì•½ ë°©ë²• í‘œì‹œ
        constraint_display_map = {
            "3Y_MDD": "3ë…„ MDD",
            "-3STD": "-3 í‘œì¤€í¸ì°¨ (3M)",
            "-2STD": "-2 í‘œì¤€í¸ì°¨ (3M)",
            "-1STD": "-1 í‘œì¤€í¸ì°¨ (3M)"
        }

        st.info(f"ğŸ¯ ì ìš©ëœ ë¦¬ìŠ¤í¬ ì œì•½: **{CONSTRAINT_DISPLAY_MAP.get(constraint_method, constraint_method)}**")

        # íƒ­ìœ¼ë¡œ êµ¬ë¶„
        tab1, tab2, tab3 = st.tabs(["ğŸ“Š ì„±ê³¼ ë¹„êµ", "ğŸ“ˆ ëˆ„ì  ìˆ˜ìµë¥ ", "ğŸ“‹ í¬ì§€ì…˜ ë³€í™”"])

        # ===== Tab 1: ì„±ê³¼ ë¹„êµ =====
        with tab1:
            st.subheader("ğŸ“Š ì„±ê³¼ ì§€í‘œ ë¹„êµ: ì›ë³¸ vs ì œì•½ ì ìš©")

            # ì›ë³¸ê³¼ ì œì•½ ì ìš© ë°ì´í„°ê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°
            if not daily_returns_original.empty and not daily_returns_constrained.empty:
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("### ğŸ“‰ ì›ë³¸ (CSV ë°ì´í„°)")
                    metrics_cols_orig = st.columns(3)

                    for idx, col_name in enumerate(['Portfolio_Return', 'Benchmark_Return', 'Active_Return']):
                        if col_name in daily_returns_original.columns:
                            metrics = calculate_annualized_metrics(daily_returns_original[col_name])

                            display_name = {
                                'Portfolio_Return': 'í¬íŠ¸í´ë¦¬ì˜¤',
                                'Benchmark_Return': 'ë²¤ì¹˜ë§ˆí¬',
                                'Active_Return': 'ì´ˆê³¼ìˆ˜ìµ'
                            }[col_name]

                            with metrics_cols_orig[idx]:
                                st.markdown(f"**{display_name}**")
                                st.metric("ëˆ„ì ", f"{metrics['cumulative_return'] * 10000:.3f}bp")
                                st.metric("ì—°ìœ¨í™”", f"{metrics['annualized_return'] * 10000:.3f}bp")
                                st.metric("ë³€ë™ì„±", f"{metrics['annualized_volatility'] * 10000:.3f}bp")

                with col2:
                    st.markdown(f"### ğŸ“ˆ ì œì•½ ì ìš© ({constraint_display_map[constraint_method]})")
                    metrics_cols_const = st.columns(3)

                    for idx, col_name in enumerate(['Portfolio_Return', 'Benchmark_Return', 'Active_Return']):
                        if col_name in daily_returns_constrained.columns:
                            metrics = calculate_annualized_metrics(daily_returns_constrained[col_name])

                            # ì›ë³¸ê³¼ ë¹„êµ
                            if col_name in daily_returns_original.columns:
                                metrics_orig = calculate_annualized_metrics(daily_returns_original[col_name])
                                delta_cum = (metrics['cumulative_return'] - metrics_orig['cumulative_return']) * 10000
                                delta_ann = (metrics['annualized_return'] - metrics_orig['annualized_return']) * 10000
                                delta_vol = (metrics['annualized_volatility'] - metrics_orig[
                                    'annualized_volatility']) * 10000
                            else:
                                delta_cum = delta_ann = delta_vol = 0.0

                            display_name = {
                                'Portfolio_Return': 'í¬íŠ¸í´ë¦¬ì˜¤',
                                'Benchmark_Return': 'ë²¤ì¹˜ë§ˆí¬',
                                'Active_Return': 'ì´ˆê³¼ìˆ˜ìµ'
                            }[col_name]

                            with metrics_cols_const[idx]:
                                st.markdown(f"**{display_name}**")
                                st.metric("ëˆ„ì ", f"{metrics['cumulative_return'] * 10000:.3f}bp",
                                          delta=f"{delta_cum:+.3f}bp")
                                st.metric("ì—°ìœ¨í™”", f"{metrics['annualized_return'] * 10000:.3f}bp",
                                          delta=f"{delta_ann:+.3f}bp")
                                st.metric("ë³€ë™ì„±", f"{metrics['annualized_volatility'] * 10000:.3f}bp",
                                          delta=f"{delta_vol:+.3f}bp")

            # ì œì•½ ì ìš© ë°ì´í„°ë§Œ ìˆëŠ” ê²½ìš°
            elif not daily_returns_constrained.empty:
                st.markdown(f"### ğŸ“ˆ ì œì•½ ì ìš© ({constraint_display_map[constraint_method]})")
                metrics_cols = st.columns(3)

                for idx, col_name in enumerate(['Portfolio_Return', 'Benchmark_Return', 'Active_Return']):
                    if col_name in daily_returns_constrained.columns:
                        metrics = calculate_annualized_metrics(daily_returns_constrained[col_name])

                        display_name = {
                            'Portfolio_Return': 'í¬íŠ¸í´ë¦¬ì˜¤',
                            'Benchmark_Return': 'ë²¤ì¹˜ë§ˆí¬',
                            'Active_Return': 'ì´ˆê³¼ìˆ˜ìµ'
                        }[col_name]

                        with metrics_cols[idx]:
                            st.markdown(f"**{display_name}**")
                            st.metric("ëˆ„ì  ìˆ˜ìµë¥ ", f"{metrics['cumulative_return'] * 10000:.3f}bp")
                            st.metric("ì—°ìœ¨í™” ìˆ˜ìµë¥ ", f"{metrics['annualized_return'] * 10000:.3f}bp")
                            st.metric("ì—°ìœ¨í™” ë³€ë™ì„±", f"{metrics['annualized_volatility'] * 10000:.3f}bp")
                            st.caption(f"ê±°ë˜ì¼: {metrics['n_days']}ì¼")

        # ===== Tab 2: ëˆ„ì  ìˆ˜ìµë¥  =====
        with tab2:
            st.subheader("ğŸ“ˆ ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ")

            fig = make_subplots(
                rows=2, cols=1,
                subplot_titles=("ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ", "ì¼ë³„ ì´ˆê³¼ìˆ˜ìµ ë¹„êµ"),
                vertical_spacing=0.12,
                row_heights=[0.6, 0.4]
            )

            # ì›ë³¸ ë°ì´í„°
            if not daily_returns_original.empty:
                cum_returns_orig = (1 + daily_returns_original).cumprod() - 1

                for col in ["Portfolio_Return", "Benchmark_Return", "Active_Return"]:
                    if col in cum_returns_orig.columns:
                        name_map = {
                            "Portfolio_Return": "í¬íŠ¸í´ë¦¬ì˜¤ (ì›ë³¸)",
                            "Benchmark_Return": "ë²¤ì¹˜ë§ˆí¬ (ì›ë³¸)",
                            "Active_Return": "ì´ˆê³¼ìˆ˜ìµ (ì›ë³¸)"
                        }
                        color_map = {
                            "Portfolio_Return": "lightblue",
                            "Benchmark_Return": "lightgray",
                            "Active_Return": "lightgreen"
                        }
                        fig.add_trace(
                            go.Scatter(
                                x=cum_returns_orig.index,
                                y=cum_returns_orig[col] * 10000,
                                name=name_map[col],
                                line=dict(color=color_map[col], width=2, dash='dot'),
                                hovertemplate="%{y:.3f}bp<extra></extra>"
                            ),
                            row=1, col=1
                        )

                # ì¼ë³„ ì´ˆê³¼ìˆ˜ìµ (ì›ë³¸)
                if "Active_Return" in daily_returns_original.columns:
                    colors = ["lightgreen" if r > 0 else "lightcoral"
                              for r in daily_returns_original["Active_Return"]]
                    fig.add_trace(
                        go.Bar(
                            x=daily_returns_original.index,
                            y=daily_returns_original["Active_Return"] * 10000,
                            name="ì´ˆê³¼ìˆ˜ìµ (ì›ë³¸)",
                            marker_color=colors,
                            opacity=0.5,
                            hovertemplate="%{y:.3f}bp<extra></extra>"
                        ),
                        row=2, col=1
                    )

            # ì œì•½ ì ìš© ë°ì´í„°
            if not daily_returns_constrained.empty:
                cum_returns_const = (1 + daily_returns_constrained).cumprod() - 1

                for col in ["Portfolio_Return", "Benchmark_Return", "Active_Return"]:
                    if col in cum_returns_const.columns:
                        name_map = {
                            "Portfolio_Return": "í¬íŠ¸í´ë¦¬ì˜¤ (ì œì•½)",
                            "Benchmark_Return": "ë²¤ì¹˜ë§ˆí¬ (ì œì•½)",
                            "Active_Return": "ì´ˆê³¼ìˆ˜ìµ (ì œì•½)"
                        }
                        color_map = {
                            "Portfolio_Return": "blue",
                            "Benchmark_Return": "gray",
                            "Active_Return": "green"
                        }
                        fig.add_trace(
                            go.Scatter(
                                x=cum_returns_const.index,
                                y=cum_returns_const[col] * 10000,
                                name=name_map[col],
                                line=dict(color=color_map[col], width=3),
                                hovertemplate="%{y:.3f}bp<extra></extra>"
                            ),
                            row=1, col=1
                        )

                # ì¼ë³„ ì´ˆê³¼ìˆ˜ìµ (ì œì•½)
                if "Active_Return" in daily_returns_constrained.columns:
                    colors = ["green" if r > 0 else "red"
                              for r in daily_returns_constrained["Active_Return"]]
                    fig.add_trace(
                        go.Bar(
                            x=daily_returns_constrained.index,
                            y=daily_returns_constrained["Active_Return"] * 10000,
                            name="ì´ˆê³¼ìˆ˜ìµ (ì œì•½)",
                            marker_color=colors,
                            hovertemplate="%{y:.3f}bp<extra></extra>"
                        ),
                        row=2, col=1
                    )

            fig.update_xaxes(title_text="", row=2, col=1)
            fig.update_yaxes(title_text="ìˆ˜ìµë¥  (bp)", row=1, col=1, tickformat=".3f")
            fig.update_yaxes(title_text="ì´ˆê³¼ìˆ˜ìµ (bp)", row=2, col=1, tickformat=".3f")
            fig.update_layout(
                height=700,
                hovermode='x unified',
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )

            # í°íŠ¸ í¬ê¸° ì ìš©
            fig = apply_chart_font_settings(fig)

            st.plotly_chart(fig, use_container_width=True)

        # Tab 3: í¬ì§€ì…˜ ë³€í™”
        with tab3:
            st.subheader("ğŸ“‹ Pairë³„ í¬ì§€ì…˜ ë³€í™”")

            if position_changes_df.empty:
                st.info("í¬ì§€ì…˜ ë³€í™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ìµœê·¼ ë‚ ì§œ ì„ íƒ
                unique_dates = sorted(position_changes_df['Date'].unique(), reverse=True)

                if len(unique_dates) > 0:
                    selected_date = st.selectbox(
                        "ë‚ ì§œ ì„ íƒ",
                        unique_dates,
                        format_func=lambda x: x.strftime('%Y-%m-%d')
                    )

                    # ì„ íƒëœ ë‚ ì§œì˜ í¬ì§€ì…˜
                    daily_positions = position_changes_df[
                        position_changes_df['Date'] == selected_date
                        ].copy()

                    if not daily_positions.empty:
                        # í¬ì§€ì…˜ í¬ê¸° ìˆœìœ¼ë¡œ ì •ë ¬
                        daily_positions['Abs_Position'] = daily_positions['Position_per_leg_bp'].abs()  # â˜… ìˆ˜ì •
                        daily_positions = daily_positions.sort_values('Abs_Position', ascending=False)

                        # í‘œì‹œ
                        st.markdown(f"#### {selected_date.strftime('%Y-%m-%d')} í¬ì§€ì…˜")

                        # ìš”ì•½ í†µê³„
                        # ìš”ì•½ í†µê³„
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Active Pairs", len(daily_positions))
                        with col2:
                            avg_pos = daily_positions['Position_per_leg_bp'].abs().mean()
                            st.metric("í‰ê·  Per-Leg í¬ì§€ì…˜", f"{avg_pos:.3f}bp")
                        with col3:
                            avg_notional = daily_positions['Total_Notional_bp'].mean()
                            st.metric("í‰ê·  Total Notional", f"{avg_notional:.3f}bp")
                        with col4:
                            avg_loss = daily_positions['Max_Loss_bp'].mean()
                            st.metric("í‰ê·  ìµœëŒ€ ì†ì‹¤", f"{avg_loss:.3f}bp")

                        # ìƒì„¸ í…Œì´ë¸”
                        # ìƒì„¸ í…Œì´ë¸”
                        display_cols = ['Pair_ID', 'Pair', 'Signal', 'Position_per_leg_bp',
                                        'Total_Notional_bp', 'Constraint_Value_%', 'Max_Loss_bp',
                                        'Actual_Loss_bp']
                        display_df = daily_positions[display_cols].copy()

                        # í¬ë§·íŒ…
                        display_df['Signal'] = display_df['Signal'].apply(lambda x: f"{x:.1f}")
                        display_df['Position_per_leg_bp'] = display_df['Position_per_leg_bp'].apply(
                            lambda x: f"{x:.3f}")
                        display_df['Total_Notional_bp'] = display_df['Total_Notional_bp'].apply(lambda x: f"{x:.3f}")
                        display_df['Constraint_Value_%'] = display_df['Constraint_Value_%'].apply(lambda x: f"{x:.2f}%")
                        display_df['Max_Loss_bp'] = display_df['Max_Loss_bp'].apply(lambda x: f"{x:.3f}")
                        display_df['Actual_Loss_bp'] = display_df['Actual_Loss_bp'].apply(lambda x: f"{x:.3f}")

                        st.dataframe(display_df, use_container_width=True)

                        # ì°¨íŠ¸
                        # ì°¨íŠ¸
                        fig_pos = go.Figure()

                        fig_pos.add_trace(go.Bar(
                            x=daily_positions['Pair'],
                            y=daily_positions['Position_per_leg_bp'],  # â¬…ï¸ ë³€ê²½
                            marker_color=['green' if p > 0 else 'red'
                                          for p in daily_positions['Position_per_leg_bp']],  # â¬…ï¸ ë³€ê²½
                        ))

                        fig_pos.update_layout(
                            title=f"{selected_date.strftime('%Y-%m-%d')} Pairë³„ Per-Leg í¬ì§€ì…˜",
                            xaxis_title="Pair",
                            yaxis_title="Per-Leg í¬ì§€ì…˜ (bp)",
                            yaxis_tickformat=".3f",
                            height=400
                        )

                        fig_pos = apply_chart_font_settings(fig_pos)

                        st.plotly_chart(fig_pos, use_container_width=True)

                # ì‹œê³„ì—´ í¬ì§€ì…˜ ë³€í™”
                st.markdown("---")
                st.subheader("ğŸ“ˆ í¬ì§€ì…˜ ì‹œê³„ì—´ ë³€í™”")

                # Pair ì„ íƒ
                unique_pairs = sorted(position_changes_df['Pair'].unique())
                selected_pairs = st.multiselect(
                    "Pair ì„ íƒ",
                    unique_pairs,
                    default=unique_pairs[:5] if len(unique_pairs) >= 5 else unique_pairs
                )

                if selected_pairs:
                    fig_ts = go.Figure()

                    for pair in selected_pairs:
                        pair_data = position_changes_df[position_changes_df['Pair'] == pair]

                        fig_ts.add_trace(go.Scatter(
                            x=pair_data['Date'],
                            y=pair_data['Position_per_leg_bp'],
                            mode='lines+markers',
                            name=pair,
                            line=dict(width=2),
                            marker=dict(size=6),
                            hovertemplate=f"{pair}<br>%{{x|%Y-%m-%d}}<br>%{{y:.3f}}bp<extra></extra>"
                        ))

                    fig_ts.update_layout(
                        title="Pairë³„ Per-Leg í¬ì§€ì…˜ ì‹œê³„ì—´",
                        xaxis_title="ë‚ ì§œ",
                        yaxis_title="Per-Leg í¬ì§€ì…˜ (bp)",
                        yaxis_tickformat=".3f",
                        height=500,
                        hovermode='x unified'
                    )

                    fig_ts.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
                    fig_ts = apply_chart_font_settings(fig_ts)

                    st.plotly_chart(fig_ts, use_container_width=True)

        # Inception Date ì •ë³´ í‘œì‹œ
        if inception_date is not None:
            if not daily_returns_constrained.empty:
                n_days = len(daily_returns_constrained)
                st.info(f"ğŸ“… Inception Date: {inception_date.date()} (ì´í›„ {n_days}ì¼)")

    except Exception as e:
        st.warning(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def display_rebalance_log(rebalance_log_df: pd.DataFrame):
    """ë¦¬ë°¸ëŸ°ì‹± ë¡œê·¸ í‘œì‹œ"""
    if rebalance_log_df.empty:
        st.info("ë¦¬ë°¸ëŸ°ì‹± ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        col1, col2, col3 = st.columns(3)
        with col1:
            total_rebal = len(rebalance_log_df)
            st.metric("ì´ ë¦¬ë°¸ëŸ°ì‹± íšŸìˆ˜", f"{total_rebal}íšŒ")
        with col2:
            if "Reason" in rebalance_log_df.columns:
                view_changes = rebalance_log_df["Reason"].str.contains("View", na=False).sum()
                st.metric("View ë³€ê²½ ë¦¬ë°¸ëŸ°ì‹±", f"{view_changes}íšŒ")
        with col3:
            if "N_Views" in rebalance_log_df.columns:
                avg_views = rebalance_log_df["N_Views"].mean()
                st.metric("í‰ê·  Active Views", f"{avg_views:.1f}ê°œ")

        st.subheader("ìµœê·¼ ë¦¬ë°¸ëŸ°ì‹± ì´ë²¤íŠ¸")
        for _, row in rebalance_log_df.tail(10).iterrows():
            reason_color = "#ff7f0e" if "View" in str(row.get("Reason", "")) else "#1f77b4"
            date_str = "N/A"
            if pd.notna(row.get('Rebalance_Date')):
                try:
                    date_str = row['Rebalance_Date'].strftime('%Y-%m-%d')
                except Exception:
                    date_str = str(row['Rebalance_Date'])

            te_bp = row.get('TE_ann', 0) * 10000
            st.markdown(f"""
            <div class="rebalance-log" style="border-left-color: {reason_color}">
                <b>{date_str}</b> - {row.get('Reason', 'N/A')}<br>
                <small>Views: {row.get('N_Views', 0):.0f} | TE: {te_bp:.3f}bp | Regime: {row.get('Regime_Score', 0):.2f}</small>
            </div>
            """, unsafe_allow_html=True)
    except Exception as e:
        st.warning(f"ë¦¬ë°¸ëŸ°ì‹± ë¡œê·¸ í‘œì‹œ ì¤‘ ì˜¤ë¥˜: {str(e)}")


def display_checkpoint_weights(checkpoints_df: pd.DataFrame, assets: list = None):
    """ì²´í¬í¬ì¸íŠ¸ ê°€ì¤‘ì¹˜ í‘œì‹œ - í°íŠ¸ í¬ê¸° ì¦ê°€"""
    if checkpoints_df.empty:
        st.info("ì²´í¬í¬ì¸íŠ¸ ê°€ì¤‘ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        active_cols = [col for col in checkpoints_df.columns if col.endswith('_Active')]
        if not active_cols:
            st.warning("Active weight ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        if assets is None:
            last_checkpoint = checkpoints_df.iloc[-1]
            top_active = last_checkpoint[active_cols].abs().nlargest(10)
            assets = [col.replace('_Active', '') for col in top_active.index]

        fig = go.Figure()
        for asset in assets:
            col_name = f"{asset}_Active"
            if col_name in checkpoints_df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=checkpoints_df.index,
                        y=checkpoints_df[col_name] * 10000,
                        mode='lines+markers',
                        name=asset,
                        line=dict(width=2),
                        marker=dict(size=8),
                        hovertemplate=f"{asset}<br>%{{x|%Y-%m-%d}}<br>%{{y:.3f}}bp<extra></extra>"
                    )
                )

        fig.update_layout(
            title="<b>ì²´í¬í¬ì¸íŠ¸ Active Weight ë³€í™”</b>",
            xaxis_title="ë‚ ì§œ",
            yaxis_title="Active Weight (bp)",
            height=500,
            hovermode='x unified',
            legend=dict(orientation="h", yanchor="bottom", y=-0.2, xanchor="center", x=0.5)
        )
        fig.update_yaxes(tickformat=".3f")
        fig.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)

        # í°íŠ¸ í¬ê¸° ì ìš©
        fig = apply_chart_font_settings(fig)

        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"ì²´í¬í¬ì¸íŠ¸ ê°€ì¤‘ì¹˜ í‘œì‹œ ì¤‘ ì˜¤ë¥˜: {str(e)}")


# =============================================================================
# BL/Pair ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =============================================================================
def calculate_asset_rankings(weights_df: pd.DataFrame, views_df: pd.DataFrame, expected_returns_df: pd.DataFrame,
                             cov_matrix: Optional[pd.DataFrame] = None) -> pd.DataFrame:
    """ìì‚° ìˆœìœ„ ê³„ì‚°"""
    if weights_df is None or weights_df.empty:
        return pd.DataFrame()

    try:
        asset_names_rank = weights_df["Asset"].astype(str).tolist()
        cash_mask = np.array([is_cash_asset(a) for a in asset_names_rank])

        # Pairwise scores (raw points from +/- signals; 2 -> 1pt, 1 -> 0.5pt)
        pairwise_raw = np.zeros(len(asset_names_rank))
        if views_df is not None and not views_df.empty:
            for _, view in views_df.iterrows():
                la = str(view.get("Long_Asset", ""))
                sa = str(view.get("Short_Asset", ""))
                try:
                    sig = float(view.get("Signal", 0.0)) or 0.0
                except Exception:
                    sig = 0.0
                # Each pair contributes half the signal magnitude per leg
                delta = 0.5 * sig
                if la in asset_names_rank:
                    pairwise_raw[asset_names_rank.index(la)] += delta
                if sa in asset_names_rank:
                    pairwise_raw[asset_names_rank.index(sa)] -= delta

        # Return scores
        return_scores = np.zeros(len(asset_names_rank))
        if expected_returns_df is not None and not expected_returns_df.empty and "Asset" in expected_returns_df.columns:
            ret_series = pd.to_numeric(
                expected_returns_df.set_index("Asset")["Expected_Return"],
                errors="coerce"
            ).reindex(asset_names_rank).fillna(0.0)
            return_scores = ret_series.values

        # Risk scores
        vols = np.ones(len(asset_names_rank))
        risk_scores = np.ones(len(asset_names_rank))
        if cov_matrix is not None and not cov_matrix.empty:
            cov = cov_matrix.reindex(index=asset_names_rank, columns=asset_names_rank).fillna(0.0)
            diag = np.diag(cov.values).astype(float)
            diag = np.clip(diag, 1e-8, None)
            vols = np.sqrt(diag)
            vols[cash_mask] = 1e-8
            risk_scores = 1.0 / vols
            risk_scores[cash_mask] = 0.0

        # Normalize
        pairwise_n = normalize_score(pairwise_raw, 0, 1)
        return_n = normalize_score(return_scores, 0, 1)
        risk_n = normalize_score(risk_scores, 0, 1)

        # Total score
        total = np.zeros(len(asset_names_rank))
        total[~cash_mask] = (
            0.4 * pairwise_n[~cash_mask]
            + 0.5 * return_n[~cash_mask]
            + 0.1 * risk_n[~cash_mask]
        )
        total[cash_mask] = 0.4 * pairwise_n[cash_mask] + 0.6 * return_n[cash_mask]

        ranks = rankdata(-total, method="average").astype(int)

        df = pd.DataFrame({
            "Asset": asset_names_rank,
            "Is_Cash": cash_mask,
            "Pairwise_Score": pairwise_raw,
            "Return_Score": return_n,
            "Risk_Score": risk_n,
            "Total_Score": total,
            "Rank": ranks,
            "Rank_Volatility": normalize_score(vols, 0, 3)
        }).sort_values("Rank")

        return df
    except Exception:
        return pd.DataFrame()

def ensure_decimal_returns(df_ret):
    """
    df_retê°€ % ìŠ¤ì¼€ì¼(ì˜ˆ: 1.2 = 1.2%)ì¸ì§€ ì†Œìˆ˜(0.012)ì¸ì§€ ê°ì§€í•´ ì†Œìˆ˜ë¡œ í†µì¼.
    ê¸°ì¤€: |99% ë¶„ìœ„ìˆ˜|ê°€ 0.5(=50%) ì´ˆê³¼ë©´ %ë¡œ ê°„ì£¼í•˜ê³  /100.
    """
    q99 = df_ret.abs().quantile(0.99, numeric_only=True).max()
    if q99 is not None and np.isfinite(q99) and q99 > 0.5:
        return df_ret / 100.0
    return df_ret


def build_recent_cov_constant_corr(df_ret_dec, window=63, rho=0.25):
    """
    ìµœê·¼ window(ê¸°ë³¸ 63ì˜ì—…ì¼) ì¼ê°„ ìˆ˜ìµë¥ (ì†Œìˆ˜)ë¡œ ê³µë¶„ì‚°ì„ ë§Œë“¤ê³ ,
    ìƒìˆ˜ìƒê´€(Constant-Correlation) íƒ€ê¹ƒìœ¼ë¡œ Ï=0.25 ìˆ˜ì¶•(Convex combination)í•©ë‹ˆë‹¤.
    ë°˜í™˜: cov_daily_dec (ì†Œìˆ˜ ìŠ¤ì¼€ì¼)
    """
    # ìµœê·¼ êµ¬ê°„ ì¶”ì¶œ
    R = df_ret_dec.tail(window).dropna(how="all")
    R = R.dropna(axis=1, how="any")  # NaN ì»¬ëŸ¼ ì œê±°
    if R.shape[1] == 0:
        raise ValueError("No valid columns for covariance after NaN filtering.")

    # ìƒ˜í”Œ ê³µë¶„ì‚° (ì†Œìˆ˜ ìŠ¤ì¼€ì¼)
    Sigma = R.cov(min_periods=max(10, window // 2)).values

    # ìƒìˆ˜ìƒê´€ íƒ€ê¹ƒ êµ¬ì„±
    std = R.std().values
    std = np.where(std <= 0, 1e-8, std)
    # ìƒ˜í”Œ ìƒê´€
    with np.errstate(divide='ignore', invalid='ignore'):
        Corr = Sigma / np.outer(std, std)
        Corr = np.nan_to_num(Corr, nan=0.0, posinf=0.0, neginf=0.0)
    # í‰ê·  ìƒê´€ (ëŒ€ê° ì œì™¸)
    n = Corr.shape[0]
    if n > 1:
        r_bar = (Corr.sum() - np.trace(Corr)) / (n * (n - 1))
    else:
        r_bar = 0.0
    Corr_cc = np.full_like(Corr, r_bar, dtype=float)
    np.fill_diagonal(Corr_cc, 1.0)

    Sigma_cc = np.outer(std, std) * Corr_cc

    # ìˆ˜ì¶•(Ï=0.25): Î£* = (1-Ï)Î£ + ÏÎ£_cc
    Sigma_star = (1.0 - rho) * Sigma + rho * Sigma_cc
    return np.asarray(Sigma_star, dtype=float)


def build_incidence_matrix(assets: List[str], pairs: List[Tuple[str, str]]) -> np.ndarray:
    """Incidence í–‰ë ¬ ìƒì„±"""
    idx = {a: i for i, a in enumerate(assets)}
    N = len(assets)
    K = len(pairs)
    B = np.zeros((N, K))
    for j, (a_long, a_short) in enumerate(pairs):
        if a_long in idx and a_short in idx:
            B[idx[a_long], j] = +1.0
            B[idx[a_short], j] = -1.0
    return B


def reconstruct_pair_sizes(active_weights: np.ndarray, B: np.ndarray, signals: np.ndarray) -> np.ndarray:
    """NNLSë¡œ Pair ì‚¬ì´ì¦ˆ ì¶”ì •"""
    if B.shape[1] == 0:
        return np.zeros(0)

    sgn = np.sign(signals)
    sgn[sgn == 0] = 1.0
    Bsig = B * sgn
    y, residual = nnls(Bsig, active_weights)
    x = sgn * y
    return x


def estimate_pair_contributions_nnls(Wact: pd.DataFrame, returns_df: pd.DataFrame, timeline_df: pd.DataFrame,
                                     start_date: pd.Timestamp, end_date: pd.Timestamp) -> pd.DataFrame:
    """Pairë³„ ê¸°ì—¬ ì¶”ì •"""
    if Wact.empty or returns_df.empty or timeline_df.empty:
        return pd.DataFrame()

    dates = returns_df.index[(returns_df.index >= start_date) & (returns_df.index <= end_date)]
    if len(dates) == 0:
        return pd.DataFrame()

    all_pairs = timeline_df[["Pair_ID", "Long_Asset", "Short_Asset"]].dropna().drop_duplicates()
    pair_key = list(map(tuple, all_pairs.values.tolist()))
    pair2idx = {k: i for i, k in enumerate(pair_key)}
    pair_contrib = np.zeros(len(pair_key))

    for d in dates:
        active = timeline_df[(timeline_df["Signal"] != 0)]
        if 'Start_Date' in active.columns:
            active = active[active['Start_Date'].fillna(pd.Timestamp.min) <= d]
        if 'End_Date' in active.columns:
            active = active[active['End_Date'].fillna(pd.Timestamp.max) >= d]
        if active.empty:
            continue

        common_assets = [c for c in Wact.columns if c in returns_df.columns]
        if not common_assets:
            break

        w = Wact.reindex(index=[d]).ffill().bfill()
        if w.empty:
            continue

        w_vec = w.iloc[0][common_assets].fillna(0.0).values
        r_vec = returns_df.loc[d, common_assets].fillna(0.0).values

        pairs_today = [(str(row['Long_Asset']), str(row['Short_Asset'])) for _, row in active.iterrows()]
        sig_today = active['Signal'].astype(float).values
        B = build_incidence_matrix(common_assets, pairs_today)
        if B.size == 0:
            continue

        x = reconstruct_pair_sizes(w_vec, B, sig_today)

        spreads = []
        for (la, sa) in pairs_today:
            if la in returns_df.columns and sa in returns_df.columns:
                spreads.append(float(returns_df.loc[d, la] - returns_df.loc[d, sa]))
            else:
                spreads.append(0.0)
        spreads = np.array(spreads)
        contrib_today = x * spreads

        for j, (la, sa) in enumerate(pairs_today):
            pid = active.iloc[j].get('Pair_ID', None)
            key = (pid, la, sa)
            if key in pair2idx:
                pair_contrib[pair2idx[key]] += contrib_today[j]

    out = all_pairs.copy()
    out['Contribution_%'] = (pair_contrib * 100.0)
    tot = float(np.sum(pair_contrib))
    out['Share_of_Active_%'] = (pair_contrib / tot * 100.0) if abs(tot) > 1e-12 else 0.0
    out['Contribution_bp'] = out['Contribution_%'] * 100.0
    out = out.sort_values('Contribution_%', ascending=False).reset_index(drop=True)
    return out


def compute_te_from_active(cov: pd.DataFrame, assets: List[str], w_act_series: pd.Series) -> float:
    """Active weightë¡œë¶€í„° TE ê³„ì‚°"""
    if cov.empty or w_act_series.empty:
        return 0.0

    cov_use = cov.reindex(index=assets, columns=assets).fillna(0.0).values
    w = w_act_series.reindex(assets).fillna(0.0).values
    te2 = float(w @ cov_use @ w)
    return float(np.sqrt(max(te2, 0.0)))


def calculate_current_max_loss_bp(x_cur: np.ndarray, constraint_values: np.ndarray) -> float:
    """í˜„ì¬ í¬ì§€ì…˜ì˜ í‰ê·  ìµœëŒ€ ì†ì‹¤ ê³„ì‚° (bp)"""
    if len(x_cur) == 0 or len(constraint_values) == 0:
        return 0.1

    losses = np.abs(x_cur) * np.abs(constraint_values)
    if len(losses) == 0 or np.all(losses == 0):
        return 0.1

    avg_loss_bp = np.mean(losses[losses > 0]) * 10000 if np.any(losses > 0) else 0.1
    return max(0.05, float(avg_loss_bp))


def calculate_period_performance(daily_returns_df, periods={'1M': 21, '3M': 63, '6M': 126, '12M': 252}):
    """
    ê¸°ê°„ë³„ ì„±ê³¼ ê³„ì‚° í•¨ìˆ˜

    Args:
        daily_returns_df: ì¼ë³„ ìˆ˜ìµë¥  DataFrame (Portfolio_Return, Benchmark_Return, Active_Return)
        periods: ê¸°ê°„ë³„ ì˜ì—…ì¼ ìˆ˜ ë”•ì…”ë„ˆë¦¬

    Returns:
        DataFrame: ê¸°ê°„ë³„ ì„±ê³¼ ì§€í‘œ
    """
    if daily_returns_df.empty:
        return pd.DataFrame()

    latest_date = daily_returns_df.index[-1]
    results = []

    for period_name, days in periods.items():
        # í•´ë‹¹ ê¸°ê°„ì˜ ë°ì´í„° ì¶”ì¶œ
        period_data = daily_returns_df.tail(days)

        if len(period_data) < days:
            # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë°ì´í„° ì‚¬ìš©
            period_data = daily_returns_df
            actual_days = len(period_data)
            note = f"(ì‹¤ì œ {actual_days}ì¼)"
        else:
            actual_days = days
            note = ""

        if len(period_data) == 0:
            continue

        # ê° ì»¬ëŸ¼ë³„ ì„±ê³¼ ê³„ì‚°
        for col in ['Portfolio_Return', 'Benchmark_Return', 'Active_Return']:
            if col in period_data.columns:
                # ëˆ„ì  ìˆ˜ìµë¥ 
                cum_ret = (1 + period_data[col]).prod() - 1

                # ì—°ìœ¨í™” ìˆ˜ìµë¥ 
                if actual_days > 0:
                    ann_ret = (1 + cum_ret) ** (252 / actual_days) - 1
                else:
                    ann_ret = 0.0

                # ì—°ìœ¨í™” ë³€ë™ì„±
                ann_vol = period_data[col].std() * np.sqrt(252)

                # Sharpe Ratio (Active Returnì˜ ê²½ìš°)
                if col == 'Active_Return' and ann_vol > 0:
                    sharpe = ann_ret / ann_vol
                else:
                    sharpe = np.nan

                results.append({
                    'Period': f"{period_name}{note}",
                    'Type': col.replace('_Return', ''),
                    'Cumulative_bp': cum_ret * 10000,
                    'Annualized_bp': ann_ret * 10000,
                    'Volatility_bp': ann_vol * 10000,
                    'Sharpe': sharpe,
                    'Start_Date': period_data.index[0].strftime('%Y-%m-%d'),
                    'End_Date': period_data.index[-1].strftime('%Y-%m-%d'),
                    'Days': actual_days
                })

    return pd.DataFrame(results)


# =============================================================================
# ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# =============================================================================
def main():
    st.title("ğŸ“Š ITAA Black-Litterman Portfolio Tracker")
    st.markdown("### ì¼ë³„ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë° Pairwise View ë¶„ì„ (bp ë‹¨ìœ„)")
    st.markdown("---")

    # Session state ì´ˆê¸°í™” (ê¸°ë³¸ê°’ ì„¤ì •)
    if 'constraint_method' not in st.session_state:
        st.session_state.constraint_method = "-3STD"  # ê¸°ë³¸ê°’
    if 'lookback_years' not in st.session_state:
        st.session_state.lookback_years = 3  # ê¸°ë³¸ê°’
    if 'adjusted_views' not in st.session_state:
        st.session_state.adjusted_views = None
    if 'inception_date' not in st.session_state:
        st.session_state.inception_date = None
    if 'common_positions' not in st.session_state:
        st.session_state.common_positions = None

    # Sidebar ì„¤ì • (ê°„ì†Œí™”)
    # Streamlit Cloudìš© ìƒëŒ€ ê²½ë¡œ ì„¤ì •
    from pathlib import Path
    BASE_DIR = Path(__file__).parent
    DEFAULT_DATA_DIR = str(BASE_DIR / "iTAA")
    DEFAULT_MARKET_CSV = str(BASE_DIR / "data" / "pr_res_bd.csv")
    DEFAULT_EXCEL_PATH = str(BASE_DIR / "data" / "itaa_Master.xlsx")

    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        data_dir = st.text_input(
            "ê²°ê³¼ CSV ë””ë ‰í† ë¦¬",
            value=DEFAULT_DATA_DIR,
            help="portfolio_weights ë“± CSVê°€ ì €ì¥ëœ í´ë”",
        )
        market_csv = st.text_input(
            "ì‹œì¥ ë°ì´í„° CSV (pr_res_bd.csv)",
            value=DEFAULT_MARKET_CSV
        )
        excel_path = st.text_input(
            "itaa_Master.xlsx ê²½ë¡œ",
            value=DEFAULT_EXCEL_PATH,
            help="Asset_Universe/Pairs_Definition/Views_Timeline/Benchmark_Weights ë§¤í•‘"
        )

        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
            st.cache_data.clear()
            st.session_state.adjusted_views = None
            st.rerun()

    # ê¸°ë³¸ ë¶„ì„ ê¸°ê°„ ì„¤ì • (ì‚¬ì´ë“œë°” ì—†ì´ ìë™ ì„¤ì •)
    default_end = pd.Timestamp.now().normalize()
    default_start = default_end - pd.Timedelta(days=90)
    start_date = default_start
    end_date = default_end

    # ê¸°ë³¸ constraint_methodì™€ lookback_years ì‚¬ìš©
    constraint_method = st.session_state.constraint_method
    lookback_years = st.session_state.lookback_years


    # ë°ì´í„° ë¡œë“œ
    try:
        data = load_csv_data(data_dir)
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()


    # CSV ë°ì´í„° ì¶”ì¶œ
    daily_returns_port = data.get("daily_returns_series", pd.DataFrame())
    views_df_csv = data.get("active_views", pd.DataFrame())
    weights_df = data.get("portfolio_weights", pd.DataFrame())
    expected_returns_df = data.get("expected_returns", pd.DataFrame())
    cov_matrix = data.get("covariance_matrix", pd.DataFrame())
    rebalance_log_df = data.get("rebalance_log", pd.DataFrame())
    rebalance_calendar_df = data.get("rebalance_calendar", pd.DataFrame())
    w_opt_daily = data.get("daily_weights_optimal", pd.DataFrame())
    w_bmk_daily = data.get("daily_weights_benchmark", pd.DataFrame())
    weight_history = data.get("weight_history", pd.DataFrame())
    timeline_history = data.get("view_timeline_history", pd.DataFrame())
    attrib_report = data.get("attribution_report", pd.DataFrame())
    attrib_summary = data.get("attribution_summary", pd.DataFrame())
    pair_mdd_report_file = data.get("pair_mdd_report", pd.DataFrame())
    pair_constraints_file = data.get("pair_constraints", pd.DataFrame())
    performance_metrics = data.get("performance_metrics", pd.DataFrame())

    # ìì‚° ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    if not weights_df.empty:
        asset_names = weights_df["Asset"].astype(str).tolist()
    elif not w_opt_daily.empty:
        asset_names = list(map(str, w_opt_daily.columns))
    elif not weight_history.empty:
        tmp_cols = [c.replace('_Optimal', '').replace('_Benchmark', '').replace('_Active', '') for c in
                    weight_history.columns]
        asset_names = sorted(list(pd.Index(tmp_cols).unique()))
    else:
        asset_names = []

    # ì‹œì¥ ìˆ˜ìµë¥  ë¡œë“œ
    returns_by_asset = load_market_returns_csv(market_csv, asset_names, excel_path) if asset_names else pd.DataFrame()

    # Views ë¡œë“œ
    views_from_excel = load_views_from_excel(excel_path)
    asof_for_views = end_date
    views_from_timeline = load_active_views_from_timeline(timeline_history, asof_for_views)
    views_source = views_from_excel if not views_from_excel.empty else views_from_timeline

    # ì¼ë³„ ìˆ˜ìµë¥  í•©ì„± (í•„ìš”ì‹œ)
    if daily_returns_port.empty and not weight_history.empty and not returns_by_asset.empty:
        st.info("ğŸ§® weight_history ê¸°ë°˜ daily_returns_series í•©ì„± ìƒì„±")
        weight_history = weight_history.sort_index()
        assets_from_wh = sorted({c.replace('_Optimal', '').replace('_Benchmark', '').replace('_Active', '') for c in
                                 weight_history.columns})
        common_assets = [a for a in assets_from_wh if a in returns_by_asset.columns]

        def get_weights_for_day(day):
            idx = weight_history.index.searchsorted(day, side='right') - 1
            if idx < 0:
                return None
            row = weight_history.iloc[idx]
            w_opt = np.array([row.get(f"{a}_Optimal", 0.0) for a in common_assets])
            w_bmk = np.array([row.get(f"{a}_Benchmark", 0.0) for a in common_assets])
            return w_opt, w_bmk

        port_ret_series = []
        bmk_ret_series = []
        act_ret_series = []
        idx_used = []

        for day, r in returns_by_asset[common_assets].iterrows():
            w = get_weights_for_day(day)
            if w is None:
                continue
            w_opt, w_bmk = w
            pr = float(np.dot(r.values, w_opt))
            br = float(np.dot(r.values, w_bmk))
            port_ret_series.append(pr)
            bmk_ret_series.append(br)
            act_ret_series.append(pr - br)
            idx_used.append(day)

        daily_returns_port = pd.DataFrame({
            'Portfolio_Return': port_ret_series,
            'Benchmark_Return': bmk_ret_series,
            'Active_Return': act_ret_series
        }, index=pd.to_datetime(idx_used))

        daily_returns_port = daily_returns_port.loc[
            (daily_returns_port.index >= start_date) & (daily_returns_port.index <= end_date)]
        st.success(f"âœ… í•©ì„± ì¼ë³„ ìˆ˜ìµë¥  ìƒì„±: {len(daily_returns_port)} ì˜ì—…ì¼")

    # ë¦¬ìŠ¤í¬ ì œì•½ ì ìš© ì¼ë³„ ìˆ˜ìµë¥  ì¬ê³„ì‚°
    # ë¦¬ìŠ¤í¬ ì œì•½ ì ìš© ì¼ë³„ ìˆ˜ìµë¥  ì¬ê³„ì‚°
    daily_returns_constrained = pd.DataFrame()
    position_changes_df = pd.DataFrame()

    if not returns_by_asset.empty and not views_source.empty and not w_bmk_daily.empty:
        with st.spinner(f"ğŸ”„ {constraint_method} ì œì•½ ì ìš© ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚° ì¤‘..."):
            daily_returns_constrained, position_changes_df = calculate_daily_returns_with_constraint(
                returns_by_asset=returns_by_asset,
                views_timeline=views_source,
                w_bmk_daily=w_bmk_daily,
                w_opt_daily=w_opt_daily,  # â˜… ì¶”ê°€
                start_date=start_date,
                end_date=end_date,
                constraint_method=constraint_method,
                lookback_years=3,
                sizing_mode="full_cap",
            )

        if not daily_returns_constrained.empty:
            st.success(f"âœ… ì œì•½ ì ìš© ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚° ì™„ë£Œ: {len(daily_returns_constrained)} ì˜ì—…ì¼")

            # ì§„ë‹¨ ì •ë³´ í‘œì‹œ
            if not position_changes_df.empty:
                avg_position = position_changes_df['Position_per_leg_bp'].abs().mean()
                max_position = position_changes_df['Position_per_leg_bp'].abs().max()
                avg_total_active = position_changes_df['Total_Active_bp'].mean()
                avg_loss = position_changes_df['Actual_Loss_bp'].mean()

                st.info(f"""
                ğŸ“Š í¬ì§€ì…˜ í†µê³„:
                - í‰ê·  Per-leg í¬ì§€ì…˜: {avg_position:.3f}bp
                - ìµœëŒ€ Per-leg í¬ì§€ì…˜: {max_position:.3f}bp
                - í‰ê·  Total Active: {avg_total_active:.3f}bp
                - í‰ê·  ì‹¤ì œ ì†ì‹¤ (ì œì•½ ë°œìƒ ì‹œ): {avg_loss:.3f}bp
                """)
    # Active PnL ê³„ì‚°
    def _calc_active_pnl_simple():
        if returns_by_asset.empty or w_opt_daily.empty or w_bmk_daily.empty:
            return pd.DataFrame(), [], 0.0, pd.DataFrame()

        s = start_date
        e = end_date
        r = returns_by_asset.loc[(returns_by_asset.index >= s) & (returns_by_asset.index <= e)].copy()
        Wopt = w_opt_daily.reindex(r.index).ffill().bfill()
        Wbmk = w_bmk_daily.reindex(r.index).ffill().bfill()
        common = [c for c in r.columns if c in Wopt.columns and c in Wbmk.columns]
        if not common:
            return pd.DataFrame(), [], 0.0, pd.DataFrame()

        r = r[common]
        Wopt = Wopt[common]
        Wbmk = Wbmk[common]
        Wact = Wopt - Wbmk
        pnl_ai = Wact * r
        total_active_return = pnl_ai.sum(axis=1).sum() * 100
        return pnl_ai, common, total_active_return, Wact

    pnl_ai, common_assets, total_active_return, Wact_period = _calc_active_pnl_simple()

    # íƒ­ êµ¬ì„±
    tabs = st.tabs([
        "ğŸ¯ Active View ìˆœìœ„",
        "ğŸ“ˆ ìˆ˜ìµ ê¸°ì—¬ë„",
        "âš–ï¸ ì•¡í‹°ë¸Œ í¬ì§€ì…˜",
        "ğŸ“Š ì¼ë³„ ì„±ê³¼",
        "ğŸ”„ ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„",
        "âš¡ ê°€ì¤‘ì¹˜ ì¶”ì ",
        "ğŸ“‹ í¬íŠ¸í´ë¦¬ì˜¤ ê°œìš”",
        "âš ï¸ ë¦¬ìŠ¤í¬ ë¶„ì„",
        "ğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„",
        "ğŸ² Pair ê¸°ëŒ€ìˆ˜ìµë¥  (3M Rolling)",
        "ğŸ›‘ ë¦¬ìŠ¤í¬ ì œì•½ ê°ë„ë¶„ì„",
        "ğŸ“Š ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼"  # â† ìƒˆë¡œ ì¶”ê°€

    ])

    # =========================================================================
    # Tab 0: Active View ìˆœìœ„
    # =========================================================================
    with tabs[0]:
        st.header("ğŸ¯ Active Pairwise Viewì— ë”°ë¥¸ ìì‚° ìˆœìœ„ ë³€í™” (Signal ì „ìš©)")

        if (views_source is None or views_source.empty) or weights_df.empty:
            st.warning("í•„ìš”í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Views ë˜ëŠ” Weights ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            # ========== 1. í¬ì§€ì…˜ í¬ê¸° ê²°ì • ê¸°ì¤€ ì„ íƒ (ìµœìƒë‹¨) ==========
            st.subheader("âš™ï¸ í¬ì§€ì…˜ í¬ê¸° ê²°ì • ê¸°ì¤€")
            st.markdown("""
            ëª¨ë“  íƒ­ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•  í¬ì§€ì…˜ ê³„ì‚° ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”.  
            ğŸ’¡ **3ê°œì›” ë¡¤ë§ ë¦¬í„´** ê¸°ë°˜ (EWM halflife=126ì¼)
            """)

            col_config1, col_config2 = st.columns(2)

            with col_config1:
                constraint_method = st.selectbox(
                    "ë¦¬ìŠ¤í¬ ì œì•½ ë°©ë²•",
                    ["3Y_MDD", "-3STD", "-2STD", "-1STD"],
                    index=1,  # ê¸°ë³¸ê°’: -3STD
                    key="global_constraint_method",
                    help="í˜ì–´ë³„ í¬ì§€ì…˜ í¬ê¸°ë¥¼ ê²°ì •í•˜ëŠ” ë¦¬ìŠ¤í¬ ì œì•½ ë°©ë²•"
                )

            with col_config2:
                lookback_years = st.slider(
                    "ë£©ë°± ê¸°ê°„ (ë…„)",
                    1, 5, 3,
                    key="global_lookback_years",
                    help="3ê°œì›” ë¡¤ë§ ë¦¬í„´ ê³„ì‚°ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„"
                )

            # Constraint ë°©ë²• í‘œì‹œ ë§µ
            CONSTRAINT_DISPLAY_MAP = {
                "3Y_MDD": "3ë…„ ìµœëŒ€ì†ì‹¤(MDD)",
                "-3STD": "-3 í‘œì¤€í¸ì°¨ (3M ë¡¤ë§)",
                "-2STD": "-2 í‘œì¤€í¸ì°¨ (3M ë¡¤ë§)",
                "-1STD": "-1 í‘œì¤€í¸ì°¨ (3M ë¡¤ë§)"
            }

            constraint_display = CONSTRAINT_DISPLAY_MAP.get(constraint_method, constraint_method)
            st.info(f"ğŸ¯ ì„ íƒëœ ì œì•½: **{constraint_display}**, ë£©ë°±: **{lookback_years}ë…„**")

            # Session stateì— ì„¤ì • ì €ì¥
            st.session_state.constraint_method = constraint_method
            st.session_state.lookback_years = lookback_years

            st.markdown("---")

            # ========== 2. As-of ê°€ì¤‘ì¹˜ ì¤€ë¹„ ==========
            if not w_opt_daily.empty and not w_bmk_daily.empty:
                asof = min(w_opt_daily.index.max(), w_bmk_daily.index.max())
                Wopt_last = w_opt_daily.loc[asof].fillna(0.0)
                Wbmk_last = w_bmk_daily.loc[asof].fillna(0.0)
            elif not weight_history.empty:
                asof = weight_history.index.max()
                row = weight_history.loc[asof]
                assets_wh = sorted({c.replace('_Optimal', '').replace('_Benchmark', '').replace('_Active', '')
                                    for c in weight_history.columns})
                Wopt_last = pd.Series({a: row.get(f"{a}_Optimal", 0.0) for a in assets_wh})
                Wbmk_last = pd.Series({a: row.get(f"{a}_Benchmark", 0.0) for a in assets_wh})
            else:
                Wopt_last = pd.Series(dtype=float)
                Wbmk_last = pd.Series(dtype=float)

            # ========== 3. ë ˆì´ì•„ì›ƒ: View ì¡°ì • + ìˆœìœ„ ë³€í™” ==========
            col1, col2 = st.columns([1, 2])

            with col1:
                st.subheader("ğŸ“ View ì¡°ì •")
                adjusted_views = views_source.copy().reset_index(drop=True)

                for idx in range(len(adjusted_views)):
                    row = adjusted_views.iloc[idx]
                    pair_id = row.get('Pair_ID', idx + 1)
                    pair_name = f"Pair {pair_id}: {row.get('Long_Asset', '')} vs {row.get('Short_Asset', '')}"

                    with st.expander(f"**{pair_name}**", expanded=(idx < 3)):
                        signal = st.slider(
                            "Signal",
                            -2, 2,
                            int(_to_float(row.get('Signal', 0)) or 0),
                            key=f"signal_{idx}"
                        )
                        adjusted_views.loc[idx, 'Signal'] = float(signal)

                        # Signalì— ë”°ë¥¸ ì†ì‹¤ í—ˆìš©ì¹˜ í‘œì‹œ
                        abs_sig = abs(signal)
                        if abs_sig >= 2.0:
                            max_loss = 0.15
                        elif abs_sig >= 1.0:
                            max_loss = 0.10
                        else:
                            max_loss = 0.10 + abs_sig * 0.5

                        st.caption(f"ğŸ’¡ ìµœëŒ€ ì†ì‹¤ í—ˆìš©: {max_loss:.2f}bp (Signal {abs_sig:.0f} ê¸°ì¤€)")

                # ì¡°ì •ëœ viewsë¥¼ session_stateì— ì €ì¥
                st.session_state.adjusted_views = adjusted_views

                # ========== 4. ê³µí†µ í¬ì§€ì…˜ ê³„ì‚° ë° ì €ì¥ ==========
                st.markdown("---")
                st.subheader("ğŸ“Š Pairë³„ í¬ì§€ì…˜ í¬ê¸°")

                if not returns_by_asset.empty and not adjusted_views.empty:
                    with st.spinner("í¬ì§€ì…˜ ê³„ì‚° ì¤‘... (EWM ë°©ì‹ì˜ 3ê°œì›” ë¡¤ë§ ë¦¬í„´)"):
                        common_positions = calculate_common_positions(
                            returns_by_asset,
                            adjusted_views,
                            constraint_method,
                            lookback_years
                        )

                    if not common_positions.empty:
                        # âš ï¸ Session stateì— ì €ì¥ (ëª¨ë“  íƒ­ì—ì„œ ì‚¬ìš©)
                        st.session_state.common_positions = common_positions

                        st.success("âœ… í¬ì§€ì…˜ì´ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤. (ëª¨ë“  íƒ­ì— ì ìš©)")

                        # ìš”ì•½ ë©”íŠ¸ë¦­
                        col_m1, col_m2, col_m3 = st.columns(3)
                        with col_m1:
                            total_notional = common_positions['Total_Notional_bp'].abs().sum()
                            st.metric("ì´ Notional", f"{total_notional:.1f}bp")
                        with col_m2:
                            avg_position = common_positions['Per_Leg_Position_bp'].abs().mean()
                            st.metric("í‰ê·  Per-Leg", f"{avg_position:.2f}bp")
                        with col_m3:
                            n_pairs = len(common_positions)
                            n_cash = common_positions['Is_Cash_Pair'].sum()
                            st.metric("Pair ìˆ˜", f"{n_pairs} ({n_cash}ê°œ Cash)")

                        # ìƒì„¸ í…Œì´ë¸”
                        with st.expander("ğŸ“‹ í¬ì§€ì…˜ ìƒì„¸ ì •ë³´", expanded=True):
                            display_cols = [
                                'Pair_ID', 'Pair', 'Signal', 'Leg_Factor',
                                'Risk_Unit_3M_%', 'Max_Loss_bp',
                                'Per_Leg_Position_bp', 'Total_Notional_bp'
                            ]
                            position_display = common_positions[display_cols].copy()

                            # í¬ë§·íŒ…
                            position_display['Risk_Unit_3M_%'] = position_display['Risk_Unit_3M_%'].apply(
                                lambda x: f"{x:.3f}%"
                            )
                            position_display['Max_Loss_bp'] = position_display['Max_Loss_bp'].apply(
                                lambda x: f"{x:.2f}"
                            )
                            position_display['Per_Leg_Position_bp'] = position_display['Per_Leg_Position_bp'].apply(
                                lambda x: f"{x:.3f}"
                            )
                            position_display['Total_Notional_bp'] = position_display['Total_Notional_bp'].apply(
                                lambda x: f"{x:.3f}"
                            )

                            st.dataframe(position_display, use_container_width=True)

                            st.caption(f"âœ… {constraint_display} ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°")

                        # í¬ì§€ì…˜ ë¶„í¬ ì°¨íŠ¸
                        fig_pos = go.Figure()

                        colors = ['#2ca02c' if s > 0 else '#d62728'
                                  for s in common_positions['Signal']]

                        fig_pos.add_trace(go.Bar(
                            x=common_positions['Pair'],
                            y=common_positions['Total_Notional_bp'],
                            marker_color=colors,
                            text=common_positions['Total_Notional_bp'].apply(lambda x: f"{x:.1f}"),
                            textposition='outside',
                            hovertemplate="<b>%{x}</b><br>Notional: %{y:.2f}bp<extra></extra>"
                        ))

                        fig_pos.update_layout(
                            title=f"Pairë³„ Total Notional (bp)",
                            xaxis_title="Pair",
                            yaxis_title="Total Notional (bp)",
                            height=400,
                            showlegend=False
                        )
                        fig_pos.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
                        fig_pos = apply_chart_font_settings(fig_pos)
                        st.plotly_chart(fig_pos, use_container_width=True)

                    else:
                        st.warning("í¬ì§€ì…˜ ê³„ì‚° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("í¬ì§€ì…˜ ê³„ì‚°ì— í•„ìš”í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

                # ========== 5. ì˜ˆìƒ ë¦¬ìŠ¤í¬ ì§€í‘œ ==========
                st.markdown("---")
                st.subheader("ğŸ“Š ì˜ˆìƒ ë¦¬ìŠ¤í¬ ì§€í‘œ")

                # Benchmark ìƒíƒœ í™•ì¸
                if not Wbmk_last.empty:
                    bm_sum = Wbmk_last.sum()
                    if abs(bm_sum) < 0.001:
                        st.info(f"ğŸ’¡ Benchmark = 0 (100% Cash) â†’ **TE = Vol**")

                # ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°
                if not returns_by_asset.empty and not Wopt_last.empty:
                    # ê³µí†µ ì»¬ëŸ¼ ì •ë ¬
                    cols = [c for c in returns_by_asset.columns if c in Wopt_last.index]
                    R = returns_by_asset[cols]
                    w_p = Wopt_last.reindex(cols).fillna(0.0)

                    if not Wbmk_last.empty:
                        w_b = Wbmk_last.reindex(cols).fillna(0.0)
                    else:
                        w_b = pd.Series(0.0, index=cols)

                    # ê³µë¶„ì‚° (63ì¼, ìƒìˆ˜ìƒê´€ Ï=0.25)
                    R_dec = _pc_ensure_decimal_returns(R)
                    C = _pc_build_recent_cov_constant_corr(R_dec, window=63, rho=0.25)

                    # í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬
                    cur_te_bp = _pc_te_bp_from_cov((w_p - w_b).values, C, 252)
                    cur_vol_bp = _pc_te_bp_from_cov(w_p.values, C, 252)

                    # ì¡°ì • í›„ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
                    if 'common_positions' in st.session_state and st.session_state.common_positions is not None:
                        common_pos_df = st.session_state.common_positions

                        pairs_adj = [(str(r['Long_Asset']), str(r['Short_Asset']))
                                     for _, r in adjusted_views.iterrows()]
                        signals_adj = adjusted_views['Signal'].astype(float).values

                        # Incidence matrix
                        B = build_incidence_matrix(cols, pairs_adj)

                        if B.size > 0 and len(pairs_adj) > 0:
                            # Per-leg í¬ì§€ì…˜ (Signal ë°©í–¥ ë°˜ì˜, ì†Œìˆ˜ ë³€í™˜)
                            x_adj = np.zeros(len(pairs_adj))

                            for i, pid in enumerate(adjusted_views.get('Pair_ID', range(len(pairs_adj)))):
                                pos_row = common_pos_df[common_pos_df['Pair_ID'] == pid]
                                if not pos_row.empty:
                                    # âœ… bp â†’ ì†Œìˆ˜ ì˜¬ë°”ë¥¸ ë³€í™˜ (1bp = 0.0001 = 0.01%)
                                    per_leg_bp = float(pos_row.iloc[0]['Per_Leg_Position_bp'])
                                    per_leg_decimal = per_leg_bp / 10000.0

                                    # Signal ë°©í–¥ ë°˜ì˜
                                    x_adj[i] = float(np.sign(signals_adj[i]) * per_leg_decimal)

                            # Active weights
                            w_active_adj = pd.Series(B @ x_adj, index=cols)

                            # ì´ìƒì¹˜ ê°ì§€
                            max_active = w_active_adj.abs().max()
                            sum_active = w_active_adj.abs().sum()

                            if max_active > 0.5 or sum_active > 2.0:
                                st.error(f"âš ï¸ ì¡°ì • í›„ ê°€ì¤‘ì¹˜ ì´ìƒ ê°ì§€!")
                                st.error(f"Max: {max_active * 100:.1f}%, Sum: {sum_active * 100:.1f}%")
                                w_pa = w_p.copy()
                            else:
                                # Portfolio weights = Benchmark + Active
                                w_portfolio_raw = w_b + w_active_adj

                                bm_sum = float(w_b.sum())

                                if abs(bm_sum) < 1e-6:
                                    # BM=0 (í˜„ê¸ˆ) â†’ Active ê·¸ëŒ€ë¡œ (ìˆ í—ˆìš©)
                                    w_pa = w_portfolio_raw
                                else:
                                    # BM ìˆì„ ë•Œ: ë¡±ì˜¨ë¦¬ + ì •ê·œí™”
                                    w_pa = w_portfolio_raw.clip(lower=0)
                                    s = w_pa.sum()
                                    w_pa = (w_pa / s) if s > 0 else w_p.copy()

                            # ì¡°ì • í›„ ë¦¬ìŠ¤í¬
                            adj_te_bp = _pc_te_bp_from_cov((w_pa - w_b).values, C, 252)
                            adj_vol_bp = _pc_te_bp_from_cov(w_pa.values, C, 252)

                            # ì´ìƒì¹˜ ì¬ê²€ì¦
                            if adj_te_bp > 1000:
                                st.error(f"ğŸš¨ ì¡°ì • í›„ TE ë¹„ì •ìƒ: {adj_te_bp:.1f}bp")
                                adj_te_bp = cur_te_bp
                                adj_vol_bp = cur_vol_bp
                        else:
                            adj_te_bp = cur_te_bp
                            adj_vol_bp = cur_vol_bp
                    else:
                        adj_te_bp = cur_te_bp
                        adj_vol_bp = cur_vol_bp

                    # í™”ë©´ ì¶œë ¥
                    col_r1, col_r2 = st.columns(2)

                    with col_r1:
                        st.markdown("#### ğŸ“‰ í˜„ì¬ ì˜ˆìƒ ë¦¬ìŠ¤í¬")
                        st.metric("ì˜ˆìƒ TE", f"{cur_te_bp:,.2f}bp")
                        st.metric("ì˜ˆìƒ Vol", f"{cur_vol_bp:,.2f}bp")

                    with col_r2:
                        st.markdown("#### ğŸ“ˆ ì¡°ì • í›„ ì˜ˆìƒ ë¦¬ìŠ¤í¬")
                        delta_te = adj_te_bp - cur_te_bp
                        delta_vol = adj_vol_bp - cur_vol_bp

                        st.metric("ì˜ˆìƒ TE", f"{adj_te_bp:,.2f}bp", delta=f"{delta_te:+.2f}bp")
                        st.metric("ì˜ˆìƒ Vol", f"{adj_vol_bp:,.2f}bp", delta=f"{delta_vol:+.2f}bp")

                    # ========== 6. ì†ì‹¤ í•œë„ ì ê²€ ==========
                    st.markdown("---")
                    st.subheader("âš ï¸ ì†ì‹¤ í•œë„ ì ê²€")



                    if 'common_positions' in st.session_state and st.session_state.common_positions is not None:
                        check_df = common_positions.copy()

                        # âœ… ìˆ˜ì •: get_max_loss_for_signal í•¨ìˆ˜
                        def get_max_loss_for_signal(signal):
                            abs_sig = abs(signal)
                            if abs_sig >= 2.0:
                                return 0.15  # bp
                            elif abs_sig >= 1.0:
                                return 0.1  # bp
                            else:
                                return 0.1 + abs_sig * 0.05

                        check_df['Max_Loss_Allowed_bp'] = check_df['Signal'].apply(
                            get_max_loss_for_signal
                        )



                        # ì‹¤ì œ ì†ì‹¤ (bp): Risk_Unit Ã— Position Ã— Leg_Factor
                        check_df['Expected_Loss_bp'] = (
                                check_df['Risk_Unit_3M_%'] / 100.0 *  # % â†’ ì†Œìˆ˜
                                check_df['Per_Leg_Position_bp'].abs() / 10000.0 *  # bp â†’ ì†Œìˆ˜
                                check_df['Leg_Factor'] * 10000.0  # bpë¡œ ë³€í™˜
                        )

                        # Max LossëŠ” ì´ë¯¸ ì˜¬ë°”ë¦„
                        check_df['Utilization_%'] = (
                                check_df['Expected_Loss_bp'] / check_df['Max_Loss_bp'] * 100
                        )
                        # ìœ„ë°˜ ì—¬ë¶€ (1% ì—¬ìœ )
                        check_df['Violation'] = (check_df['Utilization_%'] > 101)

                        # ìš”ì•½
                        n_violations = check_df['Violation'].sum()
                        avg_util = check_df['Utilization_%'].mean()
                        max_util = check_df['Utilization_%'].max()

                        col_c1, col_c2, col_c3 = st.columns(3)

                        with col_c1:
                            if n_violations > 0:
                                st.error(f"âš ï¸ ìœ„ë°˜: {n_violations}ê°œ")
                            else:
                                st.success("âœ… ëª¨ë‘ í•œë„ ë‚´")

                        with col_c2:
                            st.metric("í‰ê·  í™œìš©ë¥ ", f"{avg_util:.1f}%")

                        with col_c3:
                            color = "ğŸ”´" if max_util > 101 else "ğŸŸ¢"
                            st.metric("ìµœëŒ€ í™œìš©ë¥ ", f"{color} {max_util:.1f}%")

                        # ìœ„ë°˜ í•­ëª© í‘œì‹œ
                        if n_violations > 0:
                            st.warning(f"âš ï¸ {n_violations}ê°œ Pair ì†ì‹¤ í•œë„ ì´ˆê³¼:")

                            violation_df = check_df[check_df['Violation']].copy()
                            display_cols = [
                                'Pair_ID', 'Pair', 'Signal',
                                'Max_Loss_bp', 'Expected_Loss_bp', 'Utilization_%'
                            ]

                            viol_display = violation_df[display_cols].copy()
                            viol_display = viol_display.style.apply(
                                lambda x: ['background-color: #ffe6e6'] * len(x), axis=1
                            ).format({
                                'Max_Loss_bp': '{:.2f}',
                                'Expected_Loss_bp': '{:.2f}',
                                'Utilization_%': '{:.1f}'
                            })

                            st.dataframe(viol_display, use_container_width=True)
                        else:
                            with st.expander("âœ… ì†ì‹¤ í•œë„ ìƒì„¸", expanded=False):
                                detail_cols = [
                                    'Pair_ID', 'Pair', 'Signal',
                                    'Max_Loss_bp', 'Expected_Loss_bp', 'Utilization_%'
                                ]
                                detail_df = check_df[detail_cols].copy()
                                st.dataframe(
                                    detail_df.style.format({
                                        'Max_Loss_bp': '{:.2f}',
                                        'Expected_Loss_bp': '{:.2f}',
                                        'Utilization_%': '{:.1f}'
                                    }),
                                    use_container_width=True
                                )
                    else:
                        st.info("í¬ì§€ì…˜ ê³„ì‚° í›„ ì†ì‹¤ í•œë„ë¥¼ ì ê²€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                    # ë¦¬ìŠ¤í¬ ê²½ê³ 
                    if adj_te_bp > 50.0:
                        st.warning("âš ï¸ **ë†’ì€ ë¦¬ìŠ¤í¬**: TE > 50bp. View ê°•ë„ ì¡°ì • ê¶Œì¥")
                    elif adj_te_bp > 30.0:
                        st.info("â„¹ï¸ ì¤‘ê°„ ë¦¬ìŠ¤í¬ ìˆ˜ì¤€. View ì„¤ì • ê²€í†  í•„ìš”")

                else:
                    st.warning("âš ï¸ ì‹œì¥ ë°ì´í„° ë˜ëŠ” í¬ì§€ì…˜ ì •ë³´ê°€ ì—†ì–´ ë¦¬ìŠ¤í¬ ê³„ì‚° ë¶ˆê°€")

            # ========== 7. ì˜¤ë¥¸ìª½ ì»¬ëŸ¼: ì‹¤ì‹œê°„ ìˆœìœ„ ë³€í™” ==========
            with col2:
                st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ìˆœìœ„ ë³€í™”")

                expected_returns_use = expected_returns_df
                if (expected_returns_use is None or expected_returns_use.empty) and not returns_by_asset.empty:
                    ret_series = returns_by_asset.mean() * 252.0
                    expected_returns_use = pd.DataFrame({
                        "Asset": ret_series.index,
                        "Expected_Return": ret_series.values
                    })

                cov_matrix_use = cov_matrix
                if (cov_matrix_use is None or cov_matrix_use.empty) and not returns_by_asset.empty:
                    cov_matrix_use = returns_by_asset.cov() * 252.0

                current_ranking = calculate_asset_rankings(
                    weights_df, views_source, expected_returns_use, cov_matrix_use
                )
                adjusted_ranking = calculate_asset_rankings(
                    weights_df, adjusted_views, expected_returns_use, cov_matrix_use
                )

                if not current_ranking.empty and not adjusted_ranking.empty:
                    cash_assets_list = current_ranking[current_ranking['Is_Cash']]['Asset'].tolist()
                    if cash_assets_list:
                        st.info(f"ğŸ’µ Cash ìì‚°: {', '.join(cash_assets_list)}")

                    fig = go.Figure()

                    # í˜„ì¬ ìˆœìœ„
                    fig.add_trace(go.Scatter(
                        x=current_ranking['Rank_Volatility'],
                        y=current_ranking['Rank'].max() - current_ranking['Rank'] + 1,
                        mode='markers',
                        name='í˜„ì¬ ìˆœìœ„',
                        marker=dict(
                            size=15,
                            color='lightgray',
                            symbol='circle-open',
                            line=dict(width=2)
                        ),
                        text=current_ranking['Asset'],
                        hovertemplate="<b>%{text}</b><br>í˜„ì¬: %{customdata}<extra></extra>",
                        customdata=current_ranking['Rank']
                    ))

                    # ì¡°ì • ìˆœìœ„
                    fig.add_trace(go.Scatter(
                        x=adjusted_ranking['Rank_Volatility'],
                        y=adjusted_ranking['Rank'].max() - adjusted_ranking['Rank'] + 1,
                        mode='markers+text',
                        name='ì¡°ì • ìˆœìœ„',
                        marker=dict(
                            size=adjusted_ranking['Total_Score'] * 30 + 10,
                            color=adjusted_ranking['Total_Score'],
                            colorscale='Viridis',
                            showscale=True,
                            colorbar=dict(title="ì¢…í•©ì ìˆ˜")
                        ),
                        text=adjusted_ranking['Asset'],
                        textposition="top center",
                        hovertemplate=(
                            "<b>%{text}</b><br>"
                            "ì¡°ì • ìˆœìœ„: %{customdata[0]}<br>"
                            "Pairwise: %{customdata[1]:.3f}<br>"
                            "Return: %{customdata[2]:.3f}<br>"
                            "Risk: %{customdata[3]:.3f}<br>"
                            "<extra></extra>"
                        ),
                        customdata=adjusted_ranking[[
                            'Rank', 'Pairwise_Score', 'Return_Score', 'Risk_Score'
                        ]].values
                    ))

                    # ìˆœìœ„ ë³€í™” í™”ì‚´í‘œ
                    for _, row in current_ranking.iterrows():
                        asset = row['Asset']
                        current_rank = row['Rank']
                        adj_row = adjusted_ranking[adjusted_ranking['Asset'] == asset]

                        if not adj_row.empty:
                            adjusted_rank = adj_row.iloc[0]['Rank']
                            if current_rank != adjusted_rank:
                                fig.add_annotation(
                                    x=adj_row.iloc[0]['Rank_Volatility'],
                                    y=adjusted_ranking['Rank'].max() - adjusted_rank + 1,
                                    ax=row['Rank_Volatility'],
                                    ay=current_ranking['Rank'].max() - current_rank + 1,
                                    xref="x", yref="y",
                                    axref="x", ayref="y",
                                    showarrow=True,
                                    arrowhead=2,
                                    arrowsize=1,
                                    arrowwidth=1,
                                    arrowcolor="red" if adjusted_rank > current_rank else "green",
                                    opacity=0.5
                                )

                    fig.update_layout(
                        title="ìì‚° ìˆœìœ„ ë³€í™” (Y: ìˆœìœ„, X: Rank ë³€ë™ì„±)",
                        xaxis_title="Rank ë³€ë™ì„±",
                        yaxis_title="ìˆœìœ„ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)",
                        height=600,
                        hovermode='closest',
                        showlegend=True
                    )

                    fig = apply_chart_font_settings(fig)
                    st.plotly_chart(fig, use_container_width=True)

                    # ìƒì„¸ ìˆœìœ„ í…Œì´ë¸”
                    st.subheader("ğŸ“‹ ìƒì„¸ ìˆœìœ„ ì •ë³´")

                    display_df = adjusted_ranking[[
                        'Rank', 'Asset', 'Is_Cash', 'Total_Score',
                        'Pairwise_Score', 'Return_Score', 'Risk_Score'
                    ]].copy()

                    display_df['Is_Cash'] = display_df['Is_Cash'].map({True: 'ğŸ’µ', False: ''})

                    max_assets = len(display_df)
                    if max_assets > 1:
                        n_display = st.slider(
                            "í‘œì‹œ ìì‚° ìˆ˜",
                            min_value=min(5, max_assets),
                            max_value=max_assets,
                            value=min(10, max_assets),
                            key="asset_ranking_display"
                        )
                        display_subset = display_df.head(n_display).copy()
                    else:
                        display_subset = display_df.copy()

                    st.dataframe(display_subset, use_container_width=True)

                    fig_pairwise = go.Figure(
                        data=[go.Bar(
                            x=display_subset['Asset'],
                            y=display_subset['Pairwise_Score'],
                            marker=dict(color=display_subset['Pairwise_Score'], colorscale='RdBu')
                        )]
                    )
                    fig_pairwise.update_layout(
                        title="ìì‚°ë³„ Pairwise Score",
                        xaxis_title="Asset",
                        yaxis_title="Pairwise Score (pts)",
                        yaxis=dict(range=[-1.2, 1.2]),
                        height=400
                    )
                    fig_pairwise = apply_chart_font_settings(fig_pairwise)
                    st.plotly_chart(fig_pairwise, use_container_width=True)


    # =========================================================================
    # Tab 1: ìˆ˜ìµ ê¸°ì—¬ë„
    # =========================================================================
    with tabs[1]:
        st.header("ğŸ“ˆ Pairwise Viewë³„ ìˆ˜ìµ ê¸°ì—¬ë„ (bp ë‹¨ìœ„)")

        with st.expander("ğŸ” ë°ì´í„° ë¡œë“œ ìƒíƒœ í™•ì¸", expanded=False):
            st.write(
                f"returns_by_asset: {len(returns_by_asset)} rows, {len(returns_by_asset.columns) if not returns_by_asset.empty else 0} cols")
            st.write(
                f"w_opt_daily: {len(w_opt_daily)} rows, {len(w_opt_daily.columns) if not w_opt_daily.empty else 0} cols")
            st.write(
                f"w_bmk_daily: {len(w_bmk_daily)} rows, {len(w_bmk_daily.columns) if not w_bmk_daily.empty else 0} cols")
            st.write(f"ì„ íƒ ê¸°ê°„: {start_date.date()} ~ {end_date.date()}")
            st.write(f"pnl_ai: {len(pnl_ai)} rows, {len(pnl_ai.columns) if not pnl_ai.empty else 0} cols")
            st.write(f"common_assets: {len(common_assets) if common_assets else 0}ê°œ")

        if returns_by_asset.empty:
            st.error("âŒ ì‹œì¥ ìˆ˜ìµë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. pr_res_bd.csv íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        elif pnl_ai.empty and weight_history.empty:
            st.error(f"âŒ ì„ íƒí•œ ê¸°ê°„ì— Active PnL ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‚ ì§œ ë²”ìœ„ë¥¼ ì¡°ì •í•˜ì„¸ìš”.")
            if not w_opt_daily.empty:
                st.info(f"ğŸ“… ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ë²”ìœ„: {w_opt_daily.index.min().date()} ~ {w_opt_daily.index.max().date()}")
        else:
            st.success(f"âœ… Active PnL ê³„ì‚° ì™„ë£Œ")

            pair_contrib = pd.DataFrame()
            if not attrib_report.empty:
                pair_contrib = attrib_report.copy()
                if 'Contribution_bps' in pair_contrib.columns and 'Contribution_%' not in pair_contrib.columns:
                    pair_contrib['Contribution_%'] = pair_contrib['Contribution_bps'] / 100.0
                st.info(f"âœ… attribution_report.csv ì‚¬ìš© ({len(pair_contrib)}ê°œ í˜ì–´)")

            if pair_contrib.empty and not timeline_history.empty:
                st.info("ğŸ§® íƒ€ì„ë¼ì¸ + NNLS ê¸°ë°˜ ì¶”ì • ê¸°ì—¬ ê³„ì‚°")
                if Wact_period is None or Wact_period.empty:
                    if not weight_history.empty:
                        wh = weight_history.sort_index()
                        wh_assets = sorted(
                            {c.replace('_Optimal', '').replace('_Benchmark', '').replace('_Active', '') for c in
                             wh.columns}
                        )
                        common_wh = [a for a in wh_assets if a in returns_by_asset.columns]
                        rows = []
                        for d in returns_by_asset.index[
                            (returns_by_asset.index >= start_date) & (returns_by_asset.index <= end_date)]:
                            idx = wh.index.searchsorted(d, side='right') - 1
                            if idx < 0:
                                continue
                            row = wh.iloc[idx]
                            wopt = np.array([row.get(f"{a}_Optimal", 0.0) for a in common_wh])
                            wbmk = np.array([row.get(f"{a}_Benchmark", 0.0) for a in common_wh])
                            rows.append(pd.Series(wopt - wbmk, index=common_wh, name=d))
                        Wact_period = pd.DataFrame(rows).sort_index()

                if not Wact_period.empty:
                    pair_contrib = estimate_pair_contributions_nnls(Wact_period, returns_by_asset, timeline_history,
                                                                    start_date, end_date)

            if pair_contrib.empty:
                st.warning("ì €ì¥ëœ Attribution/ì¶”ì • ë¶ˆê°€ â†’ ìì‚°ë³„ ê¸°ì—¬ë§Œ í‘œì‹œ")
                if not pnl_ai.empty:
                    asset_contrib = pnl_ai.sum(axis=0).sort_values(ascending=False) * 10000
                    fig = go.Figure(data=[go.Bar(x=asset_contrib.index, y=asset_contrib.values)])
                    fig.update_layout(yaxis_tickformat=".3f", yaxis_title="ê¸°ì—¬ë„ (bp)")
                    fig = apply_chart_font_settings(fig)
                    st.plotly_chart(fig, use_container_width=True)
            else:
                show_cols = [c for c in ['Pair_ID', 'Long_Asset', 'Short_Asset', 'Contribution_bp', 'Share_of_Active_%']
                             if c in pair_contrib.columns]
                pair_display = pair_contrib[show_cols].head(20).copy()
                if 'Contribution_bp' in pair_display.columns:
                    pair_display['Contribution_bp'] = pair_display['Contribution_bp'].apply(lambda x: f"{x:.3f}")
                st.dataframe(pair_display, use_container_width=True)

    # =========================================================================
    # Tab 2: ì•¡í‹°ë¸Œ í¬ì§€ì…˜
    # =========================================================================
    # =========================================================================
    # Tab 2: ì•¡í‹°ë¸Œ í¬ì§€ì…˜ (Signal ì¡°ì • ë°˜ì˜)
    # =========================================================================
    with tabs[2]:
        st.header("âš–ï¸ í˜„ì¬ ì•¡í‹°ë¸Œ í¬ì§€ì…˜ (as-of, bp ë‹¨ìœ„)")

        # Signal ì¡°ì • í™•ì¸
        views_for_position = st.session_state.get('adjusted_views')
        if views_for_position is not None:
            st.success("âœ… Asset View íƒ­ì—ì„œ ì¡°ì •í•œ Signalì´ ë°˜ì˜ë©ë‹ˆë‹¤")
        else:
            views_for_position = views_source
            st.info("â„¹ï¸ ì›ë³¸ Signalì„ ì‚¬ìš©í•©ë‹ˆë‹¤")

        # ê³µí†µ í¬ì§€ì…˜ í™•ì¸
        if 'common_positions' not in st.session_state or st.session_state.common_positions is None:
            st.warning("âš ï¸ **í¬ì§€ì…˜ì´ ê³„ì‚°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**")
            st.info("Asset View íƒ­ì—ì„œ í¬ì§€ì…˜ì„ ë¨¼ì € ê³„ì‚°í•˜ì„¸ìš”.")
            st.stop()

        common_positions = st.session_state.common_positions
        constraint_method = st.session_state.get('constraint_method', '-3STD')

        # As-of ë‚ ì§œ
        if not w_opt_daily.empty and not w_bmk_daily.empty:
            asof = min(w_opt_daily.index.max(), w_bmk_daily.index.max())
            st.caption(f"ğŸ“… As-of: {asof.date()}")
        elif not weight_history.empty:
            asof = weight_history.index.max()
            st.caption(f"ğŸ“… As-of: {asof.date()} (from weight_history)")
        else:
            asof = None
            st.warning("As-of ë‚ ì§œë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        # Pairë³„ í¬ì§€ì…˜ êµ¬ì„±
        st.subheader("ğŸ“Š Pairë³„ Active í¬ì§€ì…˜")

        # í¬ì§€ì…˜ ìš”ì•½
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            total_notional = common_positions['Total_Notional_bp'].abs().sum()
            st.metric("ì´ Notional", f"{total_notional:.1f}bp")
        with col2:
            avg_position = common_positions['Per_Leg_Position_bp'].abs().mean()
            st.metric("í‰ê·  Per-Leg", f"{avg_position:.2f}bp")
        with col3:
            n_pairs = len(common_positions)
            st.metric("í™œì„± Pair", f"{n_pairs}ê°œ")
        with col4:
            st.metric("ì œì•½ ë°©ë²•", CONSTRAINT_DISPLAY_MAP.get(constraint_method, constraint_method))

        # ìƒì„¸ í…Œì´ë¸”
        st.markdown("---")
        display_cols = [
            'Pair_ID', 'Pair', 'Long_Asset', 'Short_Asset', 'Signal',
            'Per_Leg_Position_bp', 'Total_Notional_bp', 'Leg_Factor',
            'Risk_Unit_3M_%', 'Max_Loss_bp'
        ]

        position_display = common_positions[display_cols].copy()

        # í¬ë§·íŒ…
        position_display['Signal'] = position_display['Signal'].apply(lambda x: f"{x:.1f}")
        position_display['Per_Leg_Position_bp'] = position_display['Per_Leg_Position_bp'].apply(lambda x: f"{x:.3f}")
        position_display['Total_Notional_bp'] = position_display['Total_Notional_bp'].apply(lambda x: f"{x:.3f}")
        position_display['Risk_Unit_3M_%'] = position_display['Risk_Unit_3M_%'].apply(lambda x: f"{x:.3f}")
        position_display['Max_Loss_bp'] = position_display['Max_Loss_bp'].apply(lambda x: f"{x:.3f}")

        st.dataframe(position_display, use_container_width=True)

        # í¬ì§€ì…˜ ì°¨íŠ¸
        st.markdown("---")
        st.subheader("ğŸ“Š Pairë³„ í¬ì§€ì…˜ í¬ê¸°")

        fig = go.Figure()

        # Signalì— ë”°ë¥¸ ìƒ‰ìƒ
        colors = ['#2ca02c' if s > 0 else '#d62728' for s in common_positions['Signal']]

        fig.add_trace(go.Bar(
            x=common_positions['Pair'],
            y=common_positions['Total_Notional_bp'],
            marker_color=colors,
            text=common_positions['Total_Notional_bp'].apply(lambda x: f"{x:.1f}"),
            textposition='outside',
            hovertemplate="<b>%{x}</b><br>Total Notional: %{y:.3f}bp<extra></extra>"
        ))

        fig.update_layout(
            title="Pairë³„ Total Notional (bp)",
            xaxis_title="Pair",
            yaxis_title="Total Notional (bp)",
            height=450,
            showlegend=False
        )
        fig.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
        fig = apply_chart_font_settings(fig)
        st.plotly_chart(fig, use_container_width=True)

        # ìì‚°ë³„ ì§‘ê³„ëœ Active Weight
        st.markdown("---")
        st.subheader("ğŸ“Š ìì‚°ë³„ Active Weight")

        # Incidence matrixë¡œ ìì‚°ë³„ ì§‘ê³„
        pairs = [(str(r['Long_Asset']), str(r['Short_Asset'])) for _, r in common_positions.iterrows()]
        signals = common_positions['Signal'].values

        if not returns_by_asset.empty:
            assets_list = returns_by_asset.columns.tolist()
            B = build_incidence_matrix(assets_list, pairs)

            if B.size > 0:
                # Per-leg í¬ì§€ì…˜ (ì†Œìˆ˜)
                x_pair = common_positions['Per_Leg_Position_bp'].values / 10000.0

                # ìì‚°ë³„ Active weight
                asset_active = pd.Series(B @ x_pair, index=assets_list)
                asset_active = asset_active[asset_active != 0].sort_values(ascending=False)

                # âœ… ìˆ˜ì •: ìŠ¬ë¼ì´ë” ì¡°ê±´ë¶€ í‘œì‹œ
                max_assets = len(asset_active)

                if max_assets == 0:
                    st.info("í™œì„± ìì‚°ì´ ì—†ìŠµë‹ˆë‹¤.")
                elif max_assets == 1:
                    # ìì‚°ì´ 1ê°œë©´ ìŠ¬ë¼ì´ë” ì—†ì´ ë°”ë¡œ í‘œì‹œ
                    n_display = 1
                    st.caption("í‘œì‹œí•  ìì‚°: 1ê°œ")
                elif max_assets == 2:
                    # ìì‚°ì´ 2ê°œë©´ ìŠ¬ë¼ì´ë” ì—†ì´ ë°”ë¡œ í‘œì‹œ
                    n_display = 2
                    st.caption("í‘œì‹œí•  ìì‚°: 2ê°œ")
                else:
                    # ìì‚°ì´ 3ê°œ ì´ìƒì¼ ë•Œë§Œ ìŠ¬ë¼ì´ë” í‘œì‹œ
                    min_display = min(3, max_assets)
                    max_display = min(30, max_assets)
                    default_display = min(15, max_assets)

                    n_display = st.slider(
                        "í‘œì‹œí•  ìì‚° ìˆ˜",
                        min_value=min_display,
                        max_value=max_display,
                        value=default_display,
                        key="asset_position_display"
                    )

                # í…Œì´ë¸”
                asset_display = pd.DataFrame({
                    'Asset': asset_active.head(n_display).index,
                    'Active_Weight_bp': (asset_active.head(n_display) * 10000).values
                })
                asset_display['Active_Weight_bp'] = asset_display['Active_Weight_bp'].apply(lambda x: f"{x:.3f}")
                st.dataframe(asset_display, use_container_width=True)

                # ì°¨íŠ¸
                fig_asset = go.Figure()

                fig_asset.add_trace(go.Bar(
                    x=asset_active.head(n_display).index,
                    y=asset_active.head(n_display).values * 10000,
                    marker_color=['#2ca02c' if v > 0 else '#d62728' for v in asset_active.head(n_display)],
                    hovertemplate="%{x}: %{y:.3f}bp<extra></extra>"
                ))

                fig_asset.update_layout(
                    title="ìì‚°ë³„ Active Weight (bp)",
                    xaxis_title="Asset",
                    yaxis_title="Active Weight (bp)",
                    height=400,
                    showlegend=False
                )
                fig_asset.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
                fig_asset = apply_chart_font_settings(fig_asset)
                st.plotly_chart(fig_asset, use_container_width=True)
            else:
                st.info("Incidence matrix ìƒì„± ì‹¤íŒ¨")
        else:
            st.info("ì‹œì¥ ìˆ˜ìµë¥  ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")



    # =========================================================================
    # Tab 3: ì¼ë³„ ì„±ê³¼ (Signal ì¡°ì • ë°˜ì˜ + ì§„ë‹¨ ê¸°ëŠ¥)
    # =========================================================================
    with tabs[3]:
        st.header("ğŸ“Š ì¼ë³„ ì„±ê³¼ (bp ë‹¨ìœ„)")

        # ===== Inception Date ì„¤ì • =====
        st.subheader("ğŸ“… Inception Date ì„¤ì •")

        col_inc1, col_inc2 = st.columns([1, 3])

        with col_inc1:
            use_inception = st.checkbox(
                "Inception Date ì‚¬ìš©",
                value=True,
                key="use_inception_tab3",
                help="íŠ¹ì • ë‚ ì§œë¶€í„°ì˜ ì„±ê³¼ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤"
            )

        with col_inc2:
            if use_inception:
                default_inception = pd.Timestamp.now() - pd.Timedelta(days=90)

                if not returns_by_asset.empty:
                    min_date = returns_by_asset.index.min()
                    max_date = returns_by_asset.index.max()
                else:
                    min_date = default_inception
                    max_date = pd.Timestamp.now()

                inception_date = st.date_input(
                    "Inception Date",
                    value=max(default_inception.date(), min_date.date()),
                    min_value=min_date.date(),
                    max_value=max_date.date(),
                    key="inception_date_tab3",
                    help="ì´ ë‚ ì§œë¶€í„°ì˜ ìˆ˜ìµë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤"
                )
                inception_date = pd.Timestamp(inception_date)
                st.success(f"âœ… Inception: {inception_date.strftime('%Y-%m-%d')}")
            else:
                inception_date = None
                st.info("ì „ì²´ ê¸°ê°„ì˜ ì„±ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤")

        st.markdown("---")

        # ===== Signal ì¡°ì • ì—¬ë¶€ í™•ì¸ =====
        views_to_use = st.session_state.get('adjusted_views')
        signal_adjusted = (views_to_use is not None)

        if signal_adjusted:
            st.success("âœ… **Asset View íƒ­ì—ì„œ ì¡°ì •í•œ Signalì´ ë°˜ì˜ë©ë‹ˆë‹¤**")

            with st.expander("ğŸ“ ì¡°ì •ëœ Signal í™•ì¸", expanded=False):
                if not views_to_use.empty:
                    signal_summary = views_to_use[['Pair_ID', 'Long_Asset', 'Short_Asset', 'Signal']].copy()
                    signal_summary['Signal'] = signal_summary['Signal'].apply(lambda x: f"{x:.1f}")
                    st.dataframe(signal_summary, use_container_width=True)
        else:
            views_to_use = views_source
            st.info("â„¹ï¸ ì›ë³¸ Signalì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Asset View íƒ­ì—ì„œ Signalì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # ===== í¬ì§€ì…˜ ë° ì„¤ì • í™•ì¸ =====
        if 'common_positions' not in st.session_state or st.session_state.common_positions is None:
            st.warning("âš ï¸ **í¬ì§€ì…˜ì´ ê³„ì‚°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**")
            st.info("""
            ğŸ’¡ **ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰í•˜ì„¸ìš”:**
            1. **Asset View íƒ­**ìœ¼ë¡œ ì´ë™
            2. í¬ì§€ì…˜ í¬ê¸° ê²°ì • ê¸°ì¤€ ì„ íƒ
            3. Signal ì¡°ì • (í•„ìš”ì‹œ)
            4. í¬ì§€ì…˜ ê³„ì‚° í›„ ì´ íƒ­ìœ¼ë¡œ ëŒì•„ì˜¤ì„¸ìš”
            """)
            st.stop()

        common_positions = st.session_state.common_positions
        constraint_method = st.session_state.get('constraint_method', '-3STD')
        lookback_years = st.session_state.get('lookback_years', 3)

        # ===== ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚° =====
        st.subheader("ğŸ”„ ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚°")

        if returns_by_asset.empty:
            st.error("ì‹œì¥ ìˆ˜ìµë¥  ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()

        if views_to_use.empty:
            st.warning("í™œì„± Pair ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()

        active_views = views_to_use[views_to_use['Signal'] != 0].copy()

        if active_views.empty:
            st.info("í˜„ì¬ í™œì„± Pairê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        # Pairs, signals, IDs
        pairs = [(str(r['Long_Asset']), str(r['Short_Asset']))
                 for _, r in active_views.iterrows()]
        signals = active_views['Signal'].astype(float).values
        pair_ids = active_views.get('Pair_ID', range(len(pairs))).values

        # í¬ì§€ì…˜ ë§µ ìƒì„±
        position_map = dict(zip(
            common_positions['Pair_ID'],
            common_positions['Per_Leg_Position_bp'] / 10000  # bp â†’ ì†Œìˆ˜
        ))
        leg_factor_map = dict(zip(
            common_positions['Pair_ID'],
            common_positions['Leg_Factor']
        ))
        signal_map = dict(zip(
            common_positions['Pair_ID'],
            common_positions['Signal']
        ))

        # ===== ì¼ë³„ P&L ê³„ì‚° =====
        with st.spinner("ì¼ë³„ ì„±ê³¼ ê³„ì‚° ì¤‘..."):
            pair_daily_pnl = {}

            for pid, (la, sa) in zip(pair_ids, pairs):
                if la not in returns_by_asset.columns or sa not in returns_by_asset.columns:
                    continue

                # Signal ê°€ì ¸ì˜¤ê¸°
                signal = signal_map.get(pid, 1.0)

                # âœ… ìŠ¤í”„ë ˆë“œ ìˆ˜ìµë¥  ê³„ì‚° (í•­ìƒ Long - Short)
                spread_ret = returns_by_asset[la] - returns_by_asset[sa]

                # âœ… í¬ì§€ì…˜ í¬ê¸° (ë¶€í˜¸ í¬í•¨ - ì´ë¯¸ Signal ë°©í–¥ ë°˜ì˜ë¨)
                signed_pos = position_map.get(pid, 0.0)
                legs = leg_factor_map.get(pid, 2)

                # âœ… ì¼ë³„ P&L ê³„ì‚°
                # Signal > 0: (Long - Short) * (+pos) * legs = ì˜¬ë°”ë¦„
                # Signal < 0: (Long - Short) * (-pos) * legs = ì˜¬ë°”ë¦„ (ë¶€í˜¸ ë°˜ì „)
                daily_pnl = spread_ret * signed_pos * legs

                pair_daily_pnl[pid] = daily_pnl

            # ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ì¼ë³„ ìˆ˜ìµë¥ 
            if pair_daily_pnl:
                portfolio_daily_returns = sum(pair_daily_pnl.values())

                # DataFrame ìƒì„±
                daily_returns = pd.DataFrame({
                    'Portfolio_Return': portfolio_daily_returns
                })

                # Benchmark ì¶”ê°€
                if not w_bmk_daily.empty:
                    common_assets = [a for a in returns_by_asset.columns if a in w_bmk_daily.columns]
                    if common_assets:
                        bmk_returns = []
                        for date in portfolio_daily_returns.index:
                            if date in w_bmk_daily.index:
                                w_bmk = w_bmk_daily.loc[date, common_assets].fillna(0.0)
                            else:
                                prev_dates = w_bmk_daily.index[w_bmk_daily.index <= date]
                                if len(prev_dates) > 0:
                                    w_bmk = w_bmk_daily.loc[prev_dates[-1], common_assets].fillna(0.0)
                                else:
                                    w_bmk = pd.Series(0.0, index=common_assets)

                            bmk_ret = (w_bmk * returns_by_asset.loc[date, common_assets]).sum()
                            bmk_returns.append(bmk_ret)

                        daily_returns['Benchmark_Return'] = bmk_returns
                        daily_returns['Active_Return'] = daily_returns['Portfolio_Return'] - daily_returns[
                            'Benchmark_Return']
                else:
                    daily_returns['Benchmark_Return'] = 0.0
                    daily_returns['Active_Return'] = daily_returns['Portfolio_Return']

                # Session state ì €ì¥
                st.session_state['daily_returns_recalculated'] = daily_returns
                st.session_state['pair_daily_pnl'] = pair_daily_pnl

                st.success(f"âœ… ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚° ì™„ë£Œ: {len(daily_returns)}ì¼")

                if signal_adjusted:
                    st.info(f"ğŸ’¡ ì¡°ì •ëœ Signalì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤ ({constraint_method}, {lookback_years}ë…„)")
            else:
                st.error("ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.stop()

        # Inception Date í•„í„°ë§
        if inception_date is not None:
            daily_returns = daily_returns[daily_returns.index >= inception_date].copy()

            if daily_returns.empty:
                st.error(f"âš ï¸ {inception_date.date()} ì´í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

        # ===== í¬ì§€ì…˜ ìš”ì•½ =====
        with st.expander("ğŸ“‹ í˜„ì¬ ì ìš©ëœ í¬ì§€ì…˜ ìš”ì•½", expanded=False):
            col_s1, col_s2, col_s3, col_s4 = st.columns(4)

            with col_s1:
                total_notional = common_positions['Total_Notional_bp'].abs().sum()
                st.metric("ì´ Notional", f"{total_notional:.1f}bp")
            with col_s2:
                avg_position = common_positions['Per_Leg_Position_bp'].abs().mean()
                st.metric("í‰ê·  Per-Leg", f"{avg_position:.2f}bp")
            with col_s3:
                n_pairs = len(common_positions)
                st.metric("í™œì„± Pair", f"{n_pairs}ê°œ")
            with col_s4:
                avg_risk = common_positions['Risk_Unit_3M_%'].mean()
                st.metric("í‰ê·  ë¦¬ìŠ¤í¬", f"{avg_risk:.2f}%")

            st.dataframe(
                common_positions[[
                    'Pair_ID', 'Pair', 'Signal', 'Per_Leg_Position_bp',
                    'Total_Notional_bp', 'Risk_Unit_3M_%'
                ]].style.format({
                    'Signal': '{:.1f}',
                    'Per_Leg_Position_bp': '{:.3f}',
                    'Total_Notional_bp': '{:.3f}',
                    'Risk_Unit_3M_%': '{:.3f}'
                }),
                use_container_width=True
            )

        # ===== ì§„ë‹¨: Pairë³„ ìµœê·¼ ì„±ê³¼ =====
        st.markdown("---")
        if st.checkbox("ğŸ” Pairë³„ ìµœê·¼ ì„±ê³¼ ì§„ë‹¨", value=False, key="show_pair_diagnosis"):
            st.subheader("ğŸ” Pairë³„ ìµœê·¼ 5ì¼ ì„±ê³¼ ì§„ë‹¨")

            if 'pair_daily_pnl' in st.session_state:
                pair_pnl_dict = st.session_state['pair_daily_pnl']

                # ìµœê·¼ 5ì¼ ë°ì´í„°
                n_days_to_show = min(5, len(daily_returns))
                recent_dates = daily_returns.index[-n_days_to_show:]

                for pid in pair_ids:
                    if pid not in pair_pnl_dict:
                        continue

                    pair_info = common_positions[common_positions['Pair_ID'] == pid]
                    if pair_info.empty:
                        continue

                    pair_row = pair_info.iloc[0]
                    pair_name = pair_row['Pair']
                    signal = pair_row['Signal']
                    position_bp = pair_row['Per_Leg_Position_bp']
                    legs = pair_row['Leg_Factor']

                    with st.expander(f"**{pair_name}** (Signal: {signal:.1f}, Position: {position_bp:.3f}bp)",
                                     expanded=False):
                        # ìµœê·¼ 5ì¼ P&L
                        pnl_series = pair_pnl_dict[pid]
                        recent_pnl = pnl_series.loc[recent_dates]

                        # ìì‚° ìˆ˜ìµë¥ 
                        la, sa = pair_name.split(' vs ')

                        if la in returns_by_asset.columns and sa in returns_by_asset.columns:
                            asset_rets = returns_by_asset.loc[recent_dates, [la, sa]] * 100  # % ë³€í™˜

                            # í…Œì´ë¸” ìƒì„±
                            diag_df = pd.DataFrame({
                                'Date': [d.strftime('%Y-%m-%d') for d in recent_dates],
                                f'{la} (%)': asset_rets[la].values,
                                f'{sa} (%)': asset_rets[sa].values,
                                'Spread (%)': (asset_rets[la] - asset_rets[sa]).values,
                                'Position': [f"{position_bp:.3f}bp"] * len(recent_dates),
                                'Legs': [legs] * len(recent_dates),
                                'Pair PnL (bp)': (recent_pnl * 10000).values
                            })

                            # í¬ë§·íŒ…
                            for col in [f'{la} (%)', f'{sa} (%)', 'Spread (%)']:
                                diag_df[col] = diag_df[col].apply(lambda x: f"{x:.2f}")
                            diag_df['Pair PnL (bp)'] = diag_df['Pair PnL (bp)'].apply(lambda x: f"{x:.3f}")

                            st.dataframe(diag_df, use_container_width=True)

                            # ìµœê·¼ ë‚ ì§œ ê²€ì¦
                            last_date = recent_dates[-1]
                            last_la_ret = asset_rets[la].iloc[-1]
                            last_sa_ret = asset_rets[sa].iloc[-1]
                            last_spread = last_la_ret - last_sa_ret
                            last_pnl = recent_pnl.iloc[-1] * 10000

                            # ë°©í–¥ ê²€ì¦
                            if signal > 0:
                                expected_sign = "ì–‘ìˆ˜" if last_spread > 0 else "ìŒìˆ˜"
                            else:
                                expected_sign = "ì–‘ìˆ˜" if last_spread < 0 else "ìŒìˆ˜"

                            actual_sign = "ì–‘ìˆ˜" if last_pnl > 0 else "ìŒìˆ˜"

                            st.markdown(f"""
                            **{last_date.strftime('%Y-%m-%d')} ê²€ì¦:**
                            - {la}: {last_la_ret:.2f}% | {sa}: {last_sa_ret:.2f}% 
                            - Spread: {last_spread:.2f}% 
                            - Signal: {signal:.1f} ({"Long" if signal > 0 else "Short"})
                            - Position: {position_bp:.3f}bp Ã— {legs}legs
                            - P&L: {last_pnl:.3f}bp
                            """)

                            if expected_sign == actual_sign:
                                st.success(f"âœ… ë°©í–¥ ì¼ì¹˜: ì˜ˆìƒ {expected_sign}, ì‹¤ì œ {actual_sign}")
                            else:
                                st.error(f"âš ï¸ ë°©í–¥ ë¶ˆì¼ì¹˜! ì˜ˆìƒ {expected_sign}, ì‹¤ì œ {actual_sign}")
                        else:
                            st.warning(f"ìì‚° ìˆ˜ìµë¥  ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {la}, {sa}")

        # ===== ì„±ê³¼ ì§€í‘œ ê³„ì‚° =====
        st.markdown("---")
        st.subheader("ğŸ“Š ì„±ê³¼ ì§€í‘œ")

        metrics_data = {}

        for col in ['Portfolio_Return', 'Benchmark_Return', 'Active_Return']:
            if col in daily_returns.columns:
                series = daily_returns[col].dropna()

                if len(series) == 0:
                    continue

                # ëˆ„ì  ìˆ˜ìµë¥ 
                cum_ret = (1 + series).prod() - 1

                # ê±°ë˜ì¼ ìˆ˜
                n_days = len(series)

                # ì—°ìœ¨í™” ìˆ˜ìµë¥ 
                if n_days > 0:
                    ann_ret = (1 + cum_ret) ** (252 / n_days) - 1
                else:
                    ann_ret = 0.0

                # ì—°ìœ¨í™” ë³€ë™ì„±
                ann_vol = series.std() * np.sqrt(252)

                # Sharpe Ratio
                if col == 'Active_Return' and ann_vol > 0:
                    sharpe = ann_ret / ann_vol
                else:
                    sharpe = np.nan

                # MDD ê³„ì‚°
                cum_series = (1 + series).cumprod()
                running_max = cum_series.expanding().max()
                drawdown = (cum_series - running_max) / running_max
                mdd = drawdown.min()

                metrics_data[col] = {
                    'cumulative': cum_ret * 10000,
                    'annualized': ann_ret * 10000,
                    'volatility': ann_vol * 10000,
                    'sharpe': sharpe,
                    'mdd': mdd * 100,
                    'n_days': n_days
                }

        # 3ë‹¨ ë ˆì´ì•„ì›ƒ
        if metrics_data:
            cols = st.columns(3)

            col_names = {
                'Portfolio_Return': 'ğŸ“ˆ í¬íŠ¸í´ë¦¬ì˜¤',
                'Benchmark_Return': 'ğŸ“‰ ë²¤ì¹˜ë§ˆí¬',
                'Active_Return': 'âš¡ ì´ˆê³¼ìˆ˜ìµ'
            }

            for idx, (col_key, col_label) in enumerate(col_names.items()):
                if col_key in metrics_data:
                    with cols[idx]:
                        st.markdown(f"### {col_label}")
                        metrics = metrics_data[col_key]

                        st.metric("ëˆ„ì  ìˆ˜ìµë¥ ", f"{metrics['cumulative']:.3f}bp")
                        st.metric("ì—°ìœ¨í™” ìˆ˜ìµë¥ ", f"{metrics['annualized']:.3f}bp")
                        st.metric("ì—°ìœ¨í™” ë³€ë™ì„±", f"{metrics['volatility']:.3f}bp")

                        if col_key == 'Active_Return' and not np.isnan(metrics['sharpe']):
                            st.metric("Sharpe Ratio", f"{metrics['sharpe']:.3f}")

                        st.metric("MDD", f"{metrics['mdd']:.2f}%")
                        st.caption(f"ê±°ë˜ì¼: {metrics['n_days']}ì¼")

        # ===== ëˆ„ì  ìˆ˜ìµë¥  ê·¸ë˜í”„ =====
        st.markdown("---")
        st.subheader("ğŸ“ˆ ëˆ„ì  ìˆ˜ìµë¥  ì¶”ì´")

        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=("ëˆ„ì  ìˆ˜ìµë¥  (bp)", "ì¼ë³„ ì´ˆê³¼ìˆ˜ìµ (bp)"),
            vertical_spacing=0.12,
            row_heights=[0.65, 0.35]
        )

        cum_returns = (1 + daily_returns).cumprod() - 1

        colors = {
            'Portfolio_Return': '#1f77b4',
            'Benchmark_Return': '#7f7f7f',
            'Active_Return': '#2ca02c'
        }

        names = {
            'Portfolio_Return': 'í¬íŠ¸í´ë¦¬ì˜¤',
            'Benchmark_Return': 'ë²¤ì¹˜ë§ˆí¬',
            'Active_Return': 'ì´ˆê³¼ìˆ˜ìµ'
        }

        for col in ['Portfolio_Return', 'Benchmark_Return', 'Active_Return']:
            if col in cum_returns.columns:
                fig.add_trace(
                    go.Scatter(
                        x=cum_returns.index,
                        y=cum_returns[col] * 10000,
                        name=names[col],
                        line=dict(color=colors[col], width=2.5),
                        hovertemplate=f"{names[col]}: %{{y:.3f}}bp<extra></extra>"
                    ),
                    row=1, col=1
                )

        if 'Active_Return' in daily_returns.columns:
            bar_colors = ['#2ca02c' if r > 0 else '#d62728'
                          for r in daily_returns['Active_Return']]

            fig.add_trace(
                go.Bar(
                    x=daily_returns.index,
                    y=daily_returns['Active_Return'] * 10000,
                    marker_color=bar_colors,
                    showlegend=False,
                    hovertemplate="ì´ˆê³¼ìˆ˜ìµ: %{y:.3f}bp<extra></extra>"
                ),
                row=2, col=1
            )

        fig.update_xaxes(title_text="ë‚ ì§œ", row=2, col=1)
        fig.update_yaxes(title_text="ëˆ„ì  ìˆ˜ìµë¥  (bp)", row=1, col=1, tickformat=".3f")
        fig.update_yaxes(title_text="ì¼ë³„ ì´ˆê³¼ìˆ˜ìµ (bp)", row=2, col=1, tickformat=".3f")

        fig.update_layout(
            height=700,
            hovermode='x unified',
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )

        fig.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1, row=1, col=1)
        fig.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1, row=2, col=1)

        fig = apply_chart_font_settings(fig)
        st.plotly_chart(fig, use_container_width=True)

        # ===== Drawdown ì°¨íŠ¸ =====
        st.markdown("---")
        st.subheader("ğŸ“‰ Drawdown ì¶”ì´")

        fig_dd = go.Figure()

        for col in ['Portfolio_Return', 'Active_Return']:
            if col in daily_returns.columns:
                cum_series = (1 + daily_returns[col]).cumprod()
                running_max = cum_series.expanding().max()
                drawdown = (cum_series - running_max) / running_max

                fig_dd.add_trace(
                    go.Scatter(
                        x=drawdown.index,
                        y=drawdown * 100,
                        name=names[col],
                        line=dict(color=colors[col], width=2),
                        fill='tozeroy',
                        hovertemplate=f"{names[col]}: %{{y:.2f}}%<extra></extra>"
                    )
                )

        fig_dd.update_layout(
            title="Drawdown (%)",
            xaxis_title="ë‚ ì§œ",
            yaxis_title="Drawdown (%)",
            height=400,
            hovermode='x unified'
        )

        fig_dd.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
        fig_dd = apply_chart_font_settings(fig_dd)
        st.plotly_chart(fig_dd, use_container_width=True)

        # ===== ê¸°ê°„ë³„ ì„±ê³¼ =====
        st.markdown("---")
        st.subheader("ğŸ“Š ê¸°ê°„ë³„ ì„±ê³¼")

        periods = {'1M': 21, '3M': 63, '6M': 126, '1Y': 252}
        period_results = []

        for period_name, days in periods.items():
            if len(daily_returns) < days:
                continue

            period_data = daily_returns.tail(days)

            for col in ['Portfolio_Return', 'Benchmark_Return', 'Active_Return']:
                if col not in period_data.columns:
                    continue

                series = period_data[col].dropna()
                if len(series) == 0:
                    continue

                cum_ret = (1 + series).prod() - 1
                ann_ret = (1 + cum_ret) ** (252 / len(series)) - 1
                ann_vol = series.std() * np.sqrt(252)

                period_results.append({
                    'ê¸°ê°„': period_name,
                    'ìœ í˜•': names[col],
                    'ëˆ„ì  (bp)': f"{cum_ret * 10000:.3f}",
                    'ì—°ìœ¨í™” (bp)': f"{ann_ret * 10000:.3f}",
                    'ë³€ë™ì„± (bp)': f"{ann_vol * 10000:.3f}"
                })

        if period_results:
            period_df = pd.DataFrame(period_results)

            for metric in ['ëˆ„ì  (bp)', 'ì—°ìœ¨í™” (bp)', 'ë³€ë™ì„± (bp)']:
                st.markdown(f"**{metric}**")
                pivot = period_df.pivot(index='ê¸°ê°„', columns='ìœ í˜•', values=metric)
                st.dataframe(pivot, use_container_width=True)
                st.markdown("")

        # ===== ë°ì´í„° ë‹¤ìš´ë¡œë“œ =====
        st.markdown("---")
        st.subheader("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")

        download_df = daily_returns.copy()
        for col in download_df.columns:
            download_df[col] = download_df[col] * 10000

        csv_data = download_df.to_csv().encode('utf-8-sig')

        filename_suffix = f"from_{inception_date.strftime('%Y%m%d')}" if inception_date else "full_period"
        signal_suffix = "_adjusted" if signal_adjusted else "_original"

        st.download_button(
            label="ğŸ“¥ ì¼ë³„ ìˆ˜ìµë¥  ë‹¤ìš´ë¡œë“œ (CSV)",
            data=csv_data,
            file_name=f"daily_returns_{filename_suffix}{signal_suffix}_{constraint_method}.csv",
            mime="text/csv",
            key="download_daily_returns_tab3"
        )

        # ì •ë³´ í‘œì‹œ
        info_parts = []
        if inception_date:
            info_parts.append(f"ğŸ“… Inception: {inception_date.strftime('%Y-%m-%d')}")
        info_parts.append(f"ğŸ“Š ê±°ë˜ì¼: {len(daily_returns)}ì¼")
        info_parts.append(f"ğŸ¯ ì œì•½: {CONSTRAINT_DISPLAY_MAP.get(constraint_method, constraint_method)}")
        if signal_adjusted:
            info_parts.append("âœ… Signal ì¡°ì • ë°˜ì˜")

        st.info(" | ".join(info_parts))


    # =========================================================================
    # Tab 4: ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„
    # =========================================================================
    with tabs[4]:
        st.header("ğŸ”„ ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„")
        display_rebalance_log(rebalance_log_df)
        if not rebalance_calendar_df.empty:
            st.subheader("ğŸ“… ë¦¬ë°¸ëŸ°ì‹± ìº˜ë¦°ë”")
            st.dataframe(rebalance_calendar_df, use_container_width=True)

    # =========================================================================
    # Tab 5: ê°€ì¤‘ì¹˜ ì¶”ì 
    # =========================================================================
    with tabs[5]:
        st.header("âš¡ ê°€ì¤‘ì¹˜ ì¶”ì  (bp ë‹¨ìœ„)")
        checkpoints = data.get("weights_checkpoints", pd.DataFrame())
        if checkpoints.empty and not weight_history.empty:
            df = weight_history.copy()
            has_active = any(c.endswith("_Active") for c in df.columns)
            if not has_active:
                base_assets = sorted(
                    {c.replace('_Optimal', '').replace('_Benchmark', '').replace('_Active', '') for c in df.columns}
                )
                for a in base_assets:
                    df[f"{a}_Active"] = df.get(f"{a}_Optimal", 0.0) - df.get(f"{a}_Benchmark", 0.0)
            checkpoints = df
        display_checkpoint_weights(checkpoints)

    # =========================================================================
    # Tab 6: í¬íŠ¸í´ë¦¬ì˜¤ ê°œìš”
    # =========================================================================
    with tabs[6]:
        st.header("ğŸ“‹ í¬íŠ¸í´ë¦¬ì˜¤ ê°œìš”")
        c1, c2 = st.columns(2)
        with c1:
            st.subheader("Performance Metrics (bp ë‹¨ìœ„)")
            pm = data.get("performance_metrics", pd.DataFrame())
            if not pm.empty:
                pm_display = pm.copy()
                if "Metric" in pm_display.columns and "Value" in pm_display.columns:
                    for idx, row in pm_display.iterrows():
                        metric_name = str(row["Metric"]).lower()
                        if any(k in metric_name for k in ["tracking_error", "volatility", "active_return", "return"]):
                            pm_display.at[idx, "Value"] = f"{row['Value'] * 10000:.3f}"
                st.dataframe(pm_display, use_container_width=True)
            else:
                st.info("Performance Metrics íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        with c2:
            st.subheader("Portfolio Weights (Latest, bp ë‹¨ìœ„)")
            if not weights_df.empty:
                weights_display = weights_df.copy()
                for col in ["Optimal_Weight", "Benchmark_Weight", "Active_Weight"]:
                    if col in weights_display.columns:
                        weights_display[col] = weights_display[col].apply(lambda x: f"{x * 10000:.3f}")
                st.dataframe(weights_display, use_container_width=True)
            else:
                st.info("Portfolio Weights íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # =========================================================================
    # Tab 7: ë¦¬ìŠ¤í¬ ë¶„ì„
    # =========================================================================
    with tabs[7]:
        st.header("âš ï¸ ë¦¬ìŠ¤í¬ ë¶„ì„ (bp ë‹¨ìœ„)")

        if cov_matrix.empty:
            st.info("ê³µë¶„ì‚° í–‰ë ¬ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            if not w_opt_daily.empty and not w_bmk_daily.empty:
                asof = min(w_opt_daily.index.max(), w_bmk_daily.index.max())
                Wopt_last = w_opt_daily.loc[asof].fillna(0.0)
                Wbmk_last = w_bmk_daily.loc[asof].fillna(0.0)
                st.caption(f"As-of: {asof.date()}")
            elif not weight_history.empty:
                asof = weight_history.index.max()
                row = weight_history.loc[asof]
                assets_wh = sorted({c.replace('_Optimal', '').replace('_Benchmark', '').replace('_Active', '') for c in
                                    weight_history.columns})
                Wopt_last = pd.Series({a: row.get(f"{a}_Optimal", 0.0) for a in assets_wh})
                Wbmk_last = pd.Series({a: row.get(f"{a}_Benchmark", 0.0) for a in assets_wh})
                st.caption(f"As-of: {asof.date()} (from weight_history)")
            else:
                Wopt_last = pd.Series(dtype=float)
                Wbmk_last = pd.Series(dtype=float)

            if Wopt_last.empty or Wbmk_last.empty:
                st.info("í˜„ì¬ í¬ì§€ì…˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ TE ê³„ì‚°ì„ ìƒëµí•©ë‹ˆë‹¤.")
            else:
                Wact_last = (Wopt_last - Wbmk_last).fillna(0.0)
                assets_list = [a for a in Wact_last.index if a in cov_matrix.index]
                te = compute_te_from_active(cov_matrix, assets_list, Wact_last.reindex(assets_list))
                st.metric("Tracking Error (ì—°ìœ¨)", f"{te * 10000:.3f}bp")

                cov_use = cov_matrix.reindex(index=assets_list, columns=assets_list).fillna(0.0).values
                w = Wact_last.reindex(assets_list).fillna(0.0).values
                if np.any(np.isfinite(cov_use)) and np.any(np.isfinite(w)):
                    mct = cov_use @ w
                    cont = w * mct
                    cont_series = pd.Series(cont, index=assets_list).sort_values(ascending=False)

                    # BP ë‹¨ìœ„ë¡œ ë³€í™˜
                    cont_series_bp = cont_series * 10000

                    st.subheader("TE ê¸°ì—¬(ê·¼ì‚¬) Top 15 (bp ë‹¨ìœ„)")
                    fig = go.Figure(data=[go.Bar(
                        x=cont_series_bp.head(15).index,
                        y=cont_series_bp.head(15).values,
                        hovertemplate="%{y:.3f}bp<extra></extra>"
                    )])
                    fig.update_layout(
                        yaxis_tickformat=".3f",
                        yaxis_title="TE ê¸°ì—¬ (bp)",
                        height=500
                    )
                    fig = apply_chart_font_settings(fig)
                    st.plotly_chart(fig, use_container_width=True)

    # =========================================================================
    # Tab 8: ìƒê´€ê´€ê³„ ë¶„ì„
    # =========================================================================
    with tabs[8]:
        st.header("ğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„")

        if returns_by_asset.empty:
            st.info("ìƒê´€ê´€ê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ìµë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ë°ì´í„° í’ˆì§ˆ í™•ì¸
            st.subheader("ğŸ“Š ë°ì´í„° í’ˆì§ˆ í™•ì¸")
            data_quality = pd.DataFrame({
                'Asset': returns_by_asset.columns,
                'Total_Rows': len(returns_by_asset),
                'Valid_Rows': returns_by_asset.notna().sum().values,
                'Valid_Ratio': (returns_by_asset.notna().sum() / len(returns_by_asset)).values,
                'Mean': returns_by_asset.mean().values,
                'Std': returns_by_asset.std().values
            })
            data_quality['Valid_Ratio_%'] = (data_quality['Valid_Ratio'] * 100).round(2)

            # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ìì‚° í‘œì‹œ
            low_quality = data_quality[data_quality['Valid_Ratio'] < 0.8]
            if not low_quality.empty:
                st.warning(f"âš ï¸ {len(low_quality)}ê°œ ìì‚°ì˜ ë°ì´í„° ë¹„ìœ¨ì´ 80% ë¯¸ë§Œì…ë‹ˆë‹¤:")
                st.dataframe(low_quality[['Asset', 'Valid_Rows', 'Valid_Ratio_%']])

            with st.expander("ì „ì²´ ë°ì´í„° í’ˆì§ˆ ë³´ê¸°"):
                st.dataframe(data_quality)

            # Rolling correlation
            st.markdown("---")
            st.subheader("ğŸ“ˆ Rolling Correlation")
            window = st.slider("ë¡¤ë§ ìƒê´€ ìœˆë„ìš°(ì¼)", 20, 252, 60, step=5)
            rc = calculate_rolling_correlation(returns_by_asset, window=window)

            if rc:
                pair = st.selectbox("í˜ì–´ ì„ íƒ", list(rc.keys()))
                series = rc[pair]
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=series.index, y=series.values, mode='lines', name=pair))
                fig.update_layout(height=400, title=f"{pair} ë¡¤ë§ ìƒê´€({window}D)")
                fig = apply_chart_font_settings(fig)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("ê³„ì‚° ê°€ëŠ¥í•œ rolling correlationì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° í’ˆì§ˆì„ í™•ì¸í•˜ì„¸ìš”.")

            # Correlation matrix
            st.markdown("---")
            st.subheader("ğŸ—ºï¸ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")

            lookback_days = st.slider("ì‚¬ìš© ë°ì´í„° ê¸°ê°„(ì¼)", 60, 756, 252, step=30)
            recent_returns = returns_by_asset.tail(lookback_days)

            valid_ratio = recent_returns.notna().sum() / len(recent_returns)
            assets_to_use = valid_ratio[valid_ratio >= 0.7].index.tolist()

            if len(assets_to_use) < 2:
                st.error("ìœ íš¨í•œ ë°ì´í„°ê°€ ìˆëŠ” ìì‚°ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ (ìµœì†Œ 2ê°œ í•„ìš”).")
            else:
                st.info(f"âœ… {len(assets_to_use)}ê°œ ìì‚°ìœ¼ë¡œ ìƒê´€ê´€ê³„ ê³„ì‚° (70% ì´ìƒ ìœ íš¨ ë°ì´í„°)")

                corr_matrix_viz = recent_returns[assets_to_use].corr()

                fig = px.imshow(
                    corr_matrix_viz,
                    text_auto='.2f',
                    aspect='auto',
                    color_continuous_scale='RdBu_r',
                    color_continuous_midpoint=0,
                    zmin=-1, zmax=1
                )
                fig.update_layout(height=700, title=f"ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ({lookback_days}ì¼ ê¸°ì¤€)")
                fig = apply_chart_font_settings(fig)
                st.plotly_chart(fig, use_container_width=True)

            # Stability
            st.markdown("---")
            st.subheader("ğŸ“Š ìƒê´€ ì•ˆì •ì„±(ìœˆë„ìš°ë³„ í‘œì¤€í¸ì°¨) Heatmap")
            stab = calculate_correlation_stability(returns_by_asset, window=window)

            if not stab.empty:
                fig = px.imshow(stab, text_auto='.3f', aspect='auto', color_continuous_scale='RdBu_r', origin='lower')
                fig.update_layout(height=600, title=f"ìƒê´€ê´€ê³„ ì•ˆì •ì„± ({window}ì¼ ìœˆë„ìš°)")
                fig = apply_chart_font_settings(fig)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ì•ˆì •ì„± íˆíŠ¸ë§µì„ ê³„ì‚°í•  êµ¬ê°„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    # =========================================================================
    # Tab 9: Pair ê¸°ëŒ€ìˆ˜ìµë¥  (3M Rolling) - ì¡°ì •ëœ Signal ë°˜ì˜
    # =========================================================================
    with tabs[9]:
        st.header("ğŸ² Pair ì „ëµ ê¸°ëŒ€ìˆ˜ìµë¥  ë¶„ì„ (3ê°œì›” Rolling Return ê¸°ì¤€)")
        st.markdown("""
        ì´ íƒ­ì—ì„œëŠ” ì„ ì •ëœ Pair ì „ëµì˜ **3ê°œì›” rolling return** ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ  
        **-3Ïƒ, -2Ïƒ, -1Ïƒ, +1Ïƒ, +2Ïƒ, +3Ïƒ** ìˆ˜ì¤€ì—ì„œì˜ ê¸°ëŒ€ìˆ˜ìµë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

        ğŸ’¡ **3ê°œì›” Rolling Return**: ì¼ë³„ ìˆ˜ìµë¥ ì„ 63ì˜ì—…ì¼(ì•½ 3ê°œì›”) ë‹¨ìœ„ë¡œ ëˆ„ì í•œ ìˆ˜ìµë¥   
        ğŸ’¡ **EWM í†µê³„**: ìµœê·¼ ë°ì´í„°ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ (halflife=126ì¼)

        âœ… **Asset View íƒ­ì—ì„œ ì¡°ì •í•œ Signalê³¼ í¬ì§€ì…˜ì´ ìë™ìœ¼ë¡œ ë°˜ì˜ë©ë‹ˆë‹¤.**
        """)

        # ===== ê³µí†µ í¬ì§€ì…˜ í™•ì¸ =====
        if 'common_positions' not in st.session_state or st.session_state.common_positions is None:
            st.warning("âš ï¸ **í¬ì§€ì…˜ì´ ê³„ì‚°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**")
            st.info("""
            ğŸ’¡ **ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰í•˜ì„¸ìš”:**
            1. **Asset View íƒ­**ìœ¼ë¡œ ì´ë™
            2. í¬ì§€ì…˜ í¬ê¸° ê²°ì • ê¸°ì¤€ ì„ íƒ (ì˜ˆ: -3STD)
            3. Signal ì¡°ì • (í•„ìš”ì‹œ)
            4. í¬ì§€ì…˜ì´ ìë™ìœ¼ë¡œ ê³„ì‚°ë˜ê³  ì´ íƒ­ì— ë°˜ì˜ë©ë‹ˆë‹¤
            """)
            st.stop()

        if returns_by_asset.empty:
            st.warning("ì‹œì¥ ìˆ˜ìµë¥  ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()

        # Session stateì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        common_positions = st.session_state.common_positions
        constraint_method = st.session_state.get('constraint_method', '-3STD')
        lookback_years = st.session_state.get('lookback_years', 3)

        st.success(f"âœ… Asset Viewì˜ í¬ì§€ì…˜ ì‚¬ìš© ì¤‘ ({constraint_method}, {lookback_years}ë…„)")

        # Views ê°€ì ¸ì˜¤ê¸°
        views_to_use = (
            st.session_state.adjusted_views
            if st.session_state.get("adjusted_views") is not None
            else views_source
        )

        if views_to_use.empty:
            st.warning("í™œì„± Pair ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()

        # í™œì„± Pair
        active_views = views_to_use[views_to_use['Signal'] != 0].copy()

        if st.session_state.get("adjusted_views") is not None:
            st.info("â„¹ï¸ Asset Viewì—ì„œ ì¡°ì •í•œ Signalì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

        if active_views.empty:
            st.info("í˜„ì¬ í™œì„± Pairê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        # âœ… pairs, signals, pair_ids ì •ì˜
        pairs = [(str(r['Long_Asset']), str(r['Short_Asset']))
                 for _, r in active_views.iterrows()]
        signals = active_views['Signal'].astype(float).values
        pair_ids = active_views.get('Pair_ID', range(len(pairs))).values

        position_map = dict(zip(
            common_positions['Pair_ID'],
            common_positions['Per_Leg_Position_bp'] / 10000  # bp â†’ ì†Œìˆ˜
        ))
        leg_factor_map = dict(zip(
            common_positions['Pair_ID'],
            common_positions['Leg_Factor']
        ))

        # ===== 3ê°œì›” ë¡¤ë§ ë¦¬í„´ ê³„ì‚° =====
        scenarios_data = []

        with st.spinner("3ê°œì›” rolling return ê³„ì‚° ì¤‘... (EWM ë°©ì‹)"):
            for idx, (pid, (la, sa)) in enumerate(zip(pair_ids, pairs)):
                pair_name = f"{la} vs {sa}"
                signal = signals[idx]  # âœ… Signal ê°€ì ¸ì˜¤ê¸°

                # âœ… Signal ì „ë‹¬í•˜ì—¬ ë°©í–¥ ë°˜ì˜
                r3 = calculate_pair_3m_rolling_returns(
                    returns_by_asset, la, sa, signal, lookback_years
                )

                if r3.empty or len(r3) < 2:
                    continue

                # âœ… EWM í†µê³„ (RiskConstraintCalculatorì™€ ë™ì¼í•œ ë°©ì‹)
                if len(r3) >= 126:
                    ewm_mean = r3.ewm(halflife=126).mean().iloc[-1]
                    ewm_std = r3.ewm(halflife=126).std().iloc[-1]
                    mu = float(ewm_mean)
                    sd = float(ewm_std)
                else:
                    mu = float(r3.mean())
                    sd = float(r3.std(ddof=1))

                # ì‹œë‚˜ë¦¬ì˜¤ (ì†Œìˆ˜)
                scenarios = {
                    '-4std': mu - 4.0 * sd,
                    '-3std': mu - 3.0 * sd,
                    '-2std': mu - 2.0 * sd,
                    '-1std': mu - 1.0 * sd,
                    'Mean': mu,
                    '+1std': mu + 1.0 * sd,
                    '+2std': mu + 2.0 * sd,
                    '+3std': mu + 3.0 * sd,
                }

                # í¬ì§€ì…˜ (ê³µí†µ í¬ì§€ì…˜ ì‚¬ìš©)
                signed_pos_per_leg_dec = position_map.get(pid, 0.0)  # ì†Œìˆ˜
                abs_pos_per_leg_dec = abs(signed_pos_per_leg_dec)
                abs_pos_per_leg_bp = abs_pos_per_leg_dec * 10000
                legs = leg_factor_map.get(pid, 2)

                # âœ… ê°„ë‹¨í•œ Expected Loss ê³„ì‚°
                pos_row = common_positions[common_positions['Pair_ID'] == pid]

                if not pos_row.empty:
                    # Tab 0ê³¼ ë™ì¼í•œ Risk_Unit ì‚¬ìš©
                    risk_unit_decimal = pos_row.iloc[0]['Risk_Unit_3M_%'] / 100.0
                    per_leg_decimal = abs_pos_per_leg_dec
                    legs = int(pos_row.iloc[0]['Leg_Factor'])

                    expected_loss_bp = risk_unit_decimal * per_leg_decimal * legs * 10000
                else:
                    # Fallback (ì´ ê²½ìš°ëŠ” ê±°ì˜ ì—†ì–´ì•¼ í•¨)
                    loss_scenario_decimal = abs(scenarios[scenario_key])
                    expected_loss_bp = loss_scenario_decimal * abs_pos_per_leg_dec * legs * 10000

                # Signalë³„ ìµœëŒ€ ì†ì‹¤ í—ˆìš©ì¹˜
                abs_signal = abs(signals[idx])
                if abs_signal >= 2.0:
                    max_loss_bp = 0.15
                elif abs_signal >= 1.0:
                    max_loss_bp = 0.1
                else:
                    max_loss_bp = 0.1 + abs_signal * 0.05

                # âœ… Utilization
                util_pct = (expected_loss_bp / max_loss_bp) * 100.0

                # í¬íŠ¸í´ë¦¬ì˜¤ ê¸°ì—¬ë„ (Signal ë°©í–¥ ë°˜ì˜)
                scenarios_bp = {
                    k: v * signed_pos_per_leg_dec * legs * 10000
                    for k, v in scenarios.items()
                }

                # ì—°ìœ¨í™”
                mu_ann = mu * 4.0
                sd_ann = sd * np.sqrt(4.0)
                sharpe_3m = (mu / sd) if sd > 0 else np.nan

                scenarios_data.append({
                    'Pair_ID': pid,
                    'Pair': pair_name,
                    'Long': la,
                    'Short': sa,
                    'Signal': float(signals[idx]),
                    'Position_bp': abs_pos_per_leg_bp,
                    'Total_Notional_bp': abs_pos_per_leg_bp * legs,
                    'Legs': int(legs),

                    # í˜ì–´ í†µê³„ (%)
                    'Pair_Mean_3M_%': mu * 100,
                    'Pair_Std_3M_%': sd * 100,
                    'Sharpe_3M': sharpe_3m,
                    'Pair_Annual_Return_%': mu_ann * 100,
                    'Pair_Annual_Std_%': sd_ann * 100,

                    # í¬íŠ¸í´ë¦¬ì˜¤ ê¸°ì—¬ë„ (bp)
                    'Portfolio_Mean_3M_bp': scenarios_bp['Mean'],
                    'Portfolio_Std_3M_bp': sd * abs_pos_per_leg_dec * legs * 10000,
                    'Portfolio_Annual_Return_bp': mu_ann * signed_pos_per_leg_dec * legs * 10000,
                    'Portfolio_Annual_Std_bp': sd_ann * abs_pos_per_leg_dec * legs * 10000,

                    # ì‹œë‚˜ë¦¬ì˜¤ (%)
                    '-3std_%': scenarios['-3std'] * 100,
                    '-2std_%': scenarios['-2std'] * 100,
                    '-1std_%': scenarios['-1std'] * 100,
                    'Mean_%': scenarios['Mean'] * 100,
                    '+1std_%': scenarios['+1std'] * 100,
                    '+2std_%': scenarios['+2std'] * 100,
                    '+3std_%': scenarios['+3std'] * 100,

                    # ì‹œë‚˜ë¦¬ì˜¤ (bp)
                    '-3std_bp': scenarios_bp['-3std'],
                    '-2std_bp': scenarios_bp['-2std'],
                    '-1std_bp': scenarios_bp['-1std'],
                    '+1std_bp': scenarios_bp['+1std'],
                    '+2std_bp': scenarios_bp['+2std'],
                    '+3std_bp': scenarios_bp['+3std'],

                    # âœ… ì†ì‹¤ ì ê²€ (ê°„ì†Œí™”)
                    'Expected_Loss_3M_bp': expected_loss_bp,
                    'Max_Loss_bp': max_loss_bp,
                    'Utilization_%': util_pct,

                    'N_Observations': int(len(r3))
                })
        if not scenarios_data:
            st.warning("ê³„ì‚° ê°€ëŠ¥í•œ Pairê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        scenarios_df = pd.DataFrame(scenarios_data)

        # ===== í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ =====
        st.subheader("ğŸ“ˆ í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ (3M Rolling Return ê¸°ì¤€)")

        portfolio_scenarios = {
            c: float(scenarios_df[c].sum())
            for c in ['-3std_bp', '-2std_bp', '-1std_bp', '+1std_bp', '+2std_bp', '+3std_bp']
        }
        mean_return_3m = float(scenarios_df['Portfolio_Mean_3M_bp'].sum())
        total_std_3m = float(np.sqrt((scenarios_df['Portfolio_Std_3M_bp'] ** 2).sum()))
        annual_return = float(scenarios_df['Portfolio_Annual_Return_bp'].sum())
        annual_std = float(np.sqrt((scenarios_df['Portfolio_Annual_Std_bp'] ** 2).sum()))

        # ì†ì‹¤ í•œë„ ì ê²€
        total_expected_loss = float(scenarios_df['Expected_Loss_3M_bp'].sum())
        total_max_loss = float(scenarios_df['Max_Loss_bp'].sum())
        total_util = (total_expected_loss / total_max_loss * 100) if total_max_loss > 0 else np.nan

        # 3ì—´ ë ˆì´ì•„ì›ƒ
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown(f"""
            <div class="scenario-box">
                <h4>ğŸ“‰ í•˜ë°© ì‹œë‚˜ë¦¬ì˜¤ (3M)</h4>
                <p><b>-3Ïƒ:</b> {portfolio_scenarios['-3std_bp']:.2f}bp</p>
                <p><b>-2Ïƒ:</b> {portfolio_scenarios['-2std_bp']:.2f}bp</p>
                <p><b>-1Ïƒ:</b> {portfolio_scenarios['-1std_bp']:.2f}bp</p>
            </div>
            """, unsafe_allow_html=True)

        with col2:
            st.markdown(f"""
            <div class="scenario-box" style="border-color:#28a745;">
                <h4>ğŸ“Š ì¤‘ì‹¬ ê²½í–¥</h4>
                <p><b>í‰ê·  (3M):</b> {mean_return_3m:.2f}bp</p>
                <p><b>í‘œì¤€í¸ì°¨ (3M):</b> {total_std_3m:.2f}bp</p>
                <p><b>ì—°ìœ¨í™” ìˆ˜ìµë¥ :</b> {annual_return:.2f}bp</p>
                <p><b>ì—°ìœ¨í™” Std:</b> {annual_std:.2f}bp</p>
            </div>
            """, unsafe_allow_html=True)

        with col3:
            st.markdown(f"""
            <div class="scenario-box">
                <h4>ğŸ“ˆ ìƒë°© ì‹œë‚˜ë¦¬ì˜¤ (3M)</h4>
                <p><b>+1Ïƒ:</b> {portfolio_scenarios['+1std_bp']:.2f}bp</p>
                <p><b>+2Ïƒ:</b> {portfolio_scenarios['+2std_bp']:.2f}bp</p>
                <p><b>+3Ïƒ:</b> {portfolio_scenarios['+3std_bp']:.2f}bp</p>
            </div>
            """, unsafe_allow_html=True)

        # ì†ì‹¤ í•œë„ ìš”ì•½
        st.markdown("---")
        st.subheader("âš ï¸ ì†ì‹¤ í•œë„ ì ê²€")

        col_l1, col_l2, col_l3 = st.columns(3)

        with col_l1:
            st.metric("ì˜ˆìƒ ìµœëŒ€ ì†ì‹¤ (-3Ïƒ)", f"{total_expected_loss:.2f}bp")
        with col_l2:
            st.metric("í—ˆìš© ìµœëŒ€ ì†ì‹¤", f"{total_max_loss:.2f}bp")
        with col_l3:
            util_color = "ğŸŸ¢" if total_util < 80 else "ğŸŸ¡" if total_util < 100 else "ğŸ”´"
            st.metric("Utilization", f"{util_color} {total_util:.1f}%")

        if total_util > 100:
            st.error("âš ï¸ **ì†ì‹¤ í•œë„ ì´ˆê³¼!** Asset Viewì—ì„œ Signalì„ ì¡°ì •í•˜ê±°ë‚˜ ì œì•½ ë°©ë²•ì„ ë³€ê²½í•˜ì„¸ìš”.")
        elif total_util > 90:
            st.warning("âš ï¸ ì†ì‹¤ í•œë„ì— ê·¼ì ‘í–ˆìŠµë‹ˆë‹¤. ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # ===== ë§‰ëŒ€ ì°¨íŠ¸ =====
        st.markdown("---")
        st.subheader("ğŸ“Š ê¸°ëŒ€ìˆ˜ìµë¥  ë¶„í¬ (3M Rolling Return)")

        scenario_names = ['-3Ïƒ', '-2Ïƒ', '-1Ïƒ', 'Mean', '+1Ïƒ', '+2Ïƒ', '+3Ïƒ']
        scenario_values = [
            portfolio_scenarios['-3std_bp'],
            portfolio_scenarios['-2std_bp'],
            portfolio_scenarios['-1std_bp'],
            mean_return_3m,
            portfolio_scenarios['+1std_bp'],
            portfolio_scenarios['+2std_bp'],
            portfolio_scenarios['+3std_bp'],
        ]

        fig = go.Figure()

        colors = ['#d62728' if v < 0 else '#2ca02c' for v in scenario_values]

        fig.add_trace(go.Bar(
            x=scenario_names,
            y=scenario_values,
            marker_color=colors,
            text=[f"{v:.2f}" for v in scenario_values],
            textposition='outside',
            hovertemplate="%{x}: %{y:.2f}bp<extra></extra>"
        ))

        fig.update_layout(
            title="í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ê¸°ëŒ€ìˆ˜ìµë¥  ì‹œë‚˜ë¦¬ì˜¤ (3M, bp)",
            xaxis_title="ì‹œë‚˜ë¦¬ì˜¤",
            yaxis_title="ê¸°ëŒ€ìˆ˜ìµë¥  (bp)",
            height=500,
            showlegend=False
        )
        fig.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
        fig = apply_chart_font_settings(fig)
        st.plotly_chart(fig, use_container_width=True)

        # ===== ìƒì„¸ í…Œì´ë¸” =====
        st.markdown("---")
        st.subheader("ğŸ“‹ Pairë³„ ìƒì„¸ ì‹œë‚˜ë¦¬ì˜¤")

        display_cols = [
            'Pair_ID', 'Pair', 'Signal', 'Position_bp', 'Total_Notional_bp', 'Legs',

            # í˜ì–´ í†µê³„ (%)
            'Pair_Mean_3M_%', 'Pair_Std_3M_%', 'Sharpe_3M',
            'Pair_Annual_Return_%', 'Pair_Annual_Std_%',

            # ì‹œë‚˜ë¦¬ì˜¤ (%)
            '-3std_%', '-2std_%', '-1std_%', 'Mean_%',
            '+1std_%', '+2std_%', '+3std_%',

            # í¬íŠ¸í´ë¦¬ì˜¤ ê¸°ì—¬ë„ (bp)
            'Portfolio_Mean_3M_bp', 'Portfolio_Std_3M_bp',
            '-3std_bp', '-2std_bp', '-1std_bp',
            '+1std_bp', '+2std_bp', '+3std_bp',

            # ì†ì‹¤ ì ê²€
            'Expected_Loss_3M_bp', 'Max_Loss_bp', 'Utilization_%',
            'N_Observations'
        ]

        scenarios_display = scenarios_df[display_cols].copy()

        # í¬ë§·íŒ…
        format_dict = {}
        for c in scenarios_display.columns:
            if c.endswith('_bp'):
                format_dict[c] = '{:.3f}'
            elif c.endswith('_%'):
                format_dict[c] = '{:.2f}'
            elif c in ['Sharpe_3M']:
                format_dict[c] = '{:.3f}'
            elif c in ['Legs', 'N_Observations']:
                scenarios_display[c] = scenarios_display[c].astype(int)

        # Utilization ìƒ‰ìƒ
        def highlight_util(row):
            util = row['Utilization_%']
            if util > 100:
                color = '#ffe6e6'  # ë¹¨ê°•
            elif util > 90:
                color = '#fff4e6'  # ë…¸ë‘
            else:
                color = 'white'
            return ['background-color: {}'.format(color)] * len(row)

        styled_df = scenarios_display.style.apply(highlight_util, axis=1).format(format_dict)
        st.dataframe(styled_df, use_container_width=True)

        # ===== 3M ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ =====
        st.markdown("---")
        st.subheader("ğŸ“Š 3M Rolling Return ë¶„í¬")

        selected_pair_hist = st.selectbox(
            "ë¶„í¬ë¥¼ í™•ì¸í•  Pair ì„ íƒ",
            scenarios_df['Pair'].tolist(),
            key="hist_pair_select"
        )

        if selected_pair_hist:
            info = scenarios_df[scenarios_df['Pair'] == selected_pair_hist].iloc[0]
            la, sa = selected_pair_hist.split(' vs ')

            r3_hist = calculate_pair_3m_rolling_returns(
                returns_by_asset, la, sa, lookback_years
            )

            if not r3_hist.empty:
                fig_hist = go.Figure()

                # íˆìŠ¤í† ê·¸ë¨
                fig_hist.add_trace(go.Histogram(
                    x=r3_hist * 100,  # % ë‹¨ìœ„
                    nbinsx=50,
                    name='3M Returns',
                    opacity=0.7,
                    marker_color='#1f77b4'
                ))

                # í‰ê·  ë° í‘œì¤€í¸ì°¨ ì„ 
                mean_pct = float(info['Pair_Mean_3M_%'])
                std_pct = float(info['Pair_Std_3M_%'])

                fig_hist.add_vline(
                    x=mean_pct,
                    line_dash="dash",
                    line_color="red",
                    line_width=2,
                    annotation_text=f"í‰ê· : {mean_pct:.2f}%",
                    annotation_position="top"
                )

                for i in [-3, -2, -1, 1, 2, 3]:
                    x_val = mean_pct + i * std_pct
                    fig_hist.add_vline(
                        x=x_val,
                        line_dash="dot",
                        line_color="orange" if abs(i) <= 1 else "gray",
                        line_width=1,
                        annotation_text=f"{i:+d}Ïƒ"
                    )

                fig_hist.update_layout(
                    title=f"{selected_pair_hist} - 3ê°œì›” Rolling Return ë¶„í¬ (EWM)",
                    xaxis_title="3M Return (%)",
                    yaxis_title="ë¹ˆë„",
                    height=400,
                    showlegend=False
                )
                fig_hist = apply_chart_font_settings(fig_hist)
                st.plotly_chart(fig_hist, use_container_width=True)

                # í†µê³„ ìš”ì•½
                col_h1, col_h2, col_h3, col_h4 = st.columns(4)
                with col_h1:
                    st.metric("í‰ê· ", f"{mean_pct:.2f}%")
                with col_h2:
                    st.metric("í‘œì¤€í¸ì°¨", f"{std_pct:.2f}%")
                with col_h3:
                    st.metric("-3Ïƒ", f"{mean_pct - 3 * std_pct:.2f}%")
                with col_h4:
                    st.metric("+3Ïƒ", f"{mean_pct + 3 * std_pct:.2f}%")

        # ===== ë‹¤ìš´ë¡œë“œ =====
        st.markdown("---")
        st.subheader("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")

        csv_scenarios = scenarios_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ Pair ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ë‹¤ìš´ë¡œë“œ (CSV)",
            data=csv_scenarios,
            file_name=f"pair_scenarios_3m_rolling_{constraint_method}_{lookback_years}y.csv",
            mime="text/csv",
            key="download_scenarios_3m"
        )
    # =========================================================================
    # Tab 10: ë¦¬ìŠ¤í¬ ì œì•½ ê°ë„ë¶„ì„
    # =========================================================================
    with tabs[10]:
        st.header("ğŸ›‘ ë¦¬ìŠ¤í¬ ì œì•½ ê°ë„ë¶„ì„")
        st.markdown(f"""
        í˜„ì¬ ì„ íƒëœ ì œì•½ ë°©ë²•: **{CONSTRAINT_DISPLAY_MAP.get(constraint_method, constraint_method)}**


        ì´ íƒ­ì—ì„œëŠ” ê° Pairì˜ ì œì•½ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœëŒ€ í—ˆìš© ì†ì‹¤ì„ ì„¤ì •í•˜ê³ , 
        ì´ì— ë”°ë¼ í¬ì§€ì…˜ ì‚¬ì´ì¦ˆë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
        """)

        if returns_by_asset.empty:
            st.info("ì‹œì¥ ìˆ˜ìµë¥  ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            # as-of ê°€ì¤‘ì¹˜
            if not w_opt_daily.empty and not w_bmk_daily.empty:
                asof = min(w_opt_daily.index.max(), w_bmk_daily.index.max())
                Wopt_last = w_opt_daily.loc[asof]
                Wbmk_last = w_bmk_daily.loc[asof]
            elif not weight_history.empty:
                asof = weight_history.index.max()
                row = weight_history.loc[asof]
                assets_wh = sorted({c.replace('_Optimal', '').replace('_Benchmark', '').replace('_Active', '') for c in
                                    weight_history.columns})
                Wopt_last = pd.Series({a: row.get(f"{a}_Optimal", 0.0) for a in assets_wh})
                Wbmk_last = pd.Series({a: row.get(f"{a}_Benchmark", 0.0) for a in assets_wh})
            else:
                asof = None
                Wopt_last = pd.Series(dtype=float)
                Wbmk_last = pd.Series(dtype=float)

            if Wopt_last.empty or Wbmk_last.empty:
                st.warning("í˜„ì¬ í¬ì§€ì…˜ì´ ì—†ì–´ ê°ë„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                Wact_last = (Wopt_last - Wbmk_last).fillna(0.0)
                assets_list = [a for a in Wact_last.index if a in returns_by_asset.columns]
                Wact_last = Wact_last.reindex(assets_list).fillna(0.0)

                tl = timeline_history.copy() if not timeline_history.empty else views_source.copy()
                if tl.empty or 'Long_Asset' not in tl.columns or 'Short_Asset' not in tl.columns:
                    st.warning("í˜ì–´ íƒ€ì„ë¼ì¸/ë·° ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                else:
                    for c in ["Start_Date", "End_Date"]:
                        if c in tl.columns:
                            tl[c] = pd.to_datetime(tl[c], errors="coerce")

                    active_rows = tl.copy()
                    now_ref = asof or pd.Timestamp.today()
                    if 'Start_Date' in active_rows.columns:
                        active_rows = active_rows[active_rows['Start_Date'].fillna(pd.Timestamp.min) <= now_ref]
                    if 'End_Date' in active_rows.columns:
                        active_rows = active_rows[active_rows['End_Date'].fillna(pd.Timestamp.max) >= now_ref]

                    if active_rows.empty:
                        st.warning("í˜„ì¬ í™œì„± Pairê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        pairs = active_rows[['Long_Asset', 'Short_Asset']].dropna().astype(str).values.tolist()
                        signals = pd.to_numeric(active_rows.get('Signal', 0.0), errors='coerce').fillna(0.0).values
                        pair_ids = active_rows.get('Pair_ID', range(len(pairs))).values

                        B = build_incidence_matrix(assets_list, pairs)
                        if B.size == 0:
                            st.warning("Incidence í–‰ë ¬ ìƒì„± ì‹¤íŒ¨(ìì‚°-í˜ì–´ ë§¤í•‘ í™•ì¸).")
                        else:
                            # ê¸°ë³¸ ì„¤ì •
                            st.subheader("ğŸ›ï¸ ê¸°ë³¸ ì„¤ì •")
                            col1, col2 = st.columns(2)

                            with col1:
                                lookback_years = st.slider(
                                    "ì œì•½ ê³„ì‚° ë£©ë°± ê¸°ê°„ (ë…„)",
                                    1, 5, 3,
                                    key="constraint_lookback",
                                    help="Historical ì œì•½ ê°’ ê³„ì‚°ì— ì‚¬ìš©í•  ê³¼ê±° ê¸°ê°„"
                                )

                            # ì œì•½ ê°’ ê³„ì‚°
                            risk_calc = RiskConstraintCalculator(returns_by_asset, lookback_years=lookback_years)

                            # í˜„ì¬ í˜ì–´ ì‚¬ì´ì¦ˆ ì¶”ì •
                            x_cur = reconstruct_pair_sizes(Wact_last.values, B, signals)

                            # ê° Pairì˜ ì œì•½ ê°’ ê³„ì‚°
                            constraint_values, cap_arr_default = risk_calc.calculate_position_caps(
                                pairs, signals, constraint_method
                            )

                            # í˜„ì¬ ì ìš©ëœ ìµœëŒ€ ì†ì‹¤ ê³„ì‚°
                            current_max_loss = calculate_current_max_loss_bp(x_cur, constraint_values)

                            with col2:
                                # ì†ì‹¤ í•œë„ ë²”ìœ„: 0.01bp ~ 0.25bp
                                default_max_loss_bp = st.slider(
                                    "ê¸°ë³¸ ìµœëŒ€ í—ˆìš© ì†ì‹¤ (bp)",
                                    min_value=0.01,
                                    max_value=0.25,
                                    value=min(max(0.1, current_max_loss), 0.25),
                                    step=0.01,
                                    format="%.3f",
                                    key="default_constraint_loss",
                                    help=f"í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ì ìš© ì†ì‹¤: {current_max_loss:.3f}bp"
                                )

                            st.info(
                                f"ğŸ’¡ í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ì— ì ìš©ëœ í‰ê·  ì†ì‹¤ í•œë„: **{current_max_loss:.3f}bp** | ì„¤ì •ê°’: **{default_max_loss_bp:.3f}bp**"
                            )

                            # Pairë³„ ê°œë³„ ì œì•½ ì„¤ì •
                            st.markdown("---")
                            st.subheader("âš™ï¸ Pairë³„ ìµœëŒ€ ì†ì‹¤ í—ˆìš©ì¹˜ ì„¤ì • (0.01bp~0.25bp)")

                            # Session state ì´ˆê¸°í™”
                            if 'pair_max_loss_constraint' not in st.session_state:
                                st.session_state.pair_max_loss_constraint = {}

                            max_loss_per_pair = np.full(len(pairs), default_max_loss_bp)

                            col_count = 2
                            cols = st.columns(col_count)

                            for idx in range(len(pairs)):
                                pair_id = pair_ids[idx]
                                la, sa = pairs[idx]

                                col_idx = idx % col_count
                                with cols[col_idx]:
                                    with st.expander(f"**Pair {pair_id}: {la} vs {sa}**", expanded=False):
                                        constraint_pct = constraint_values[idx] * 100
                                        cur_pos = x_cur[idx] * 10000

                                        constraint_label = {
                                            "3Y_MDD": "Historical MDD",
                                            "-3STD": "-3 í‘œì¤€í¸ì°¨",
                                            "-2STD": "-2 í‘œì¤€í¸ì°¨",
                                            "-1STD": "-1 í‘œì¤€í¸ì°¨"
                                        }[constraint_method]

                                        st.metric(constraint_label, f"{constraint_pct:.2f}%")
                                        st.metric("í˜„ì¬ í¬ì§€ì…˜", f"{cur_pos:.3f}bp")

                                        # í˜„ì¬ pairì˜ ì‹¤ì œ ì†ì‹¤ ê³„ì‚°
                                        pair_current_loss = abs(x_cur[idx]) * abs(constraint_values[idx]) * 10000
                                        st.caption(f"í˜„ì¬ ì ìš© ì†ì‹¤: {pair_current_loss:.3f}bp")

                                        loss_bp = st.slider(
                                            "ìµœëŒ€ í—ˆìš© ì†ì‹¤ (bp)",
                                            min_value=0.01,
                                            max_value=0.25,
                                            value=float(st.session_state.pair_max_loss_constraint.get(idx,
                                                                                                      default_max_loss_bp)),
                                            step=0.01,
                                            format="%.3f",
                                            key=f"pair_constraint_loss_{idx}",
                                            help=f"ì´ Pairì˜ ìµœëŒ€ ì†ì‹¤ í—ˆìš©ì¹˜ (0.01bp~0.25bp)"
                                        )
                                        st.session_state.pair_max_loss_constraint[idx] = loss_bp
                                        max_loss_per_pair[idx] = loss_bp

                            # ê° Pairë³„ ìµœëŒ€ í¬ì§€ì…˜ ê³„ì‚°
                            _views_for_caps = st.session_state.get("adjusted_views", views_source).reset_index(
                                drop=True)
                            _loss_caps_bp = _compute_loss_caps_bp_from_views(_views_for_caps)

                            # ê¸°ì¡´ cap_arr ìƒì„±ë¶€ êµì²´
                            cap_arr = np.array([
                                float(max_loss_per_pair[i] / 10000.0) / (abs(constraint_values[i]) * 2.0)
                                if abs(constraint_values[i]) > 1e-8
                                else 1.0
                                for i in range(len(constraint_values))
                            ])

                            # ìº¡ ì ìš©í•œ ëŒ€ì•ˆ í¬ì§€ì…˜
                            x_cap = np.clip(x_cur, -cap_arr, cap_arr)
                            Wact_alt = pd.Series(B @ x_cap, index=assets_list)

                            # í¬ì§€ì…˜ ë³€ê²½ ê°ì§€
                            position_changes = np.abs((x_cap - x_cur) * 10000)
                            has_changes = position_changes > 1e-9
                            n_changed = has_changes.sum()

                            # ì§„ë‹¨ ì •ë³´
                            st.markdown("---")
                            st.subheader("ğŸ”¬ í¬ì§€ì…˜ ë³€ê²½ ì§„ë‹¨")

                            col_diag1, col_diag2, col_diag3 = st.columns(3)
                            with col_diag1:
                                st.metric("ì´ Pair ìˆ˜", len(pairs))
                            with col_diag2:
                                st.metric(
                                    "í¬ì§€ì…˜ ë³€ê²½ Pair",
                                    f"{n_changed}ê°œ",
                                    help="ì œì•½ ë³€ê²½ìœ¼ë¡œ í¬ì§€ì…˜ì´ ë³€ê²½ëœ Pair"
                                )
                            with col_diag3:
                                total_change = position_changes.sum()
                                st.metric("ì´ ë³€ê²½ëŸ‰", f"{total_change:.3f}bp")

                            if n_changed > 0:
                                st.success(f"âœ… {n_changed}ê°œ Pairì—ì„œ í¬ì§€ì…˜ ë³€ê²½ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                            else:
                                st.info("â„¹ï¸ ëª¨ë“  Pairì˜ í˜„ì¬ í¬ì§€ì…˜ì´ í—ˆìš© ìº¡ ì´ë‚´ì…ë‹ˆë‹¤. ë” ì‘ì€ ì†ì‹¤ í•œë„ë¥¼ ì„¤ì •í•˜ë©´ ì œì•½ì´ ì ìš©ë©ë‹ˆë‹¤.")

                            # TE ë° ë³€ë™ì„± ê³„ì‚°
                            if cov_matrix.empty:
                                te_cur = te_alt = vol_cur = vol_alt = np.nan
                            else:
                                cov_use_assets = [a for a in assets_list if a in cov_matrix.index]
                                te_cur = compute_te_from_active(cov_matrix, cov_use_assets,
                                                                Wact_last.reindex(cov_use_assets))
                                te_alt = compute_te_from_active(cov_matrix, cov_use_assets,
                                                                Wact_alt.reindex(cov_use_assets))

                                cov_np = cov_matrix.reindex(index=cov_use_assets, columns=cov_use_assets).fillna(
                                    0.0).values
                                w_cur = (Wbmk_last.reindex(cov_use_assets).fillna(0.0) + Wact_last.reindex(
                                    cov_use_assets).fillna(0.0)).values
                                w_alt = (Wbmk_last.reindex(cov_use_assets).fillna(0.0) + Wact_alt.reindex(
                                    cov_use_assets).fillna(0.0)).values
                                vol_cur = float(np.sqrt(w_cur @ cov_np @ w_cur))
                                vol_alt = float(np.sqrt(w_alt @ cov_np @ w_alt))

                            # ë©”íŠ¸ë¦­ í‘œì‹œ
                            st.markdown("---")
                            st.subheader("ğŸ“Š ë¦¬ìŠ¤í¬ ì§€í‘œ ë³€í™”")
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("í˜„ì¬ TE(ì—°ìœ¨)", f"{(te_cur * 10000 if pd.notna(te_cur) else 0):.3f}bp")
                            with col2:
                                te_delta = ((te_alt - te_cur) * 10000 if (pd.notna(te_alt) and pd.notna(te_cur)) else 0)
                                st.metric("ëŒ€ì•ˆ TE(ì—°ìœ¨)", f"{(te_alt * 10000 if pd.notna(te_alt) else 0):.3f}bp",
                                          delta=f"{te_delta:+.3f}bp")
                            with col3:
                                vol_delta = (
                                    (vol_alt - vol_cur) * 10000 if (pd.notna(vol_alt) and pd.notna(vol_cur)) else 0)
                                st.metric("í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„± ë³€í™”", f"{(vol_alt * 10000 if pd.notna(vol_alt) else 0):.3f}bp",
                                          delta=f"{vol_delta:+.3f}bp")

                            st.markdown("---")

                            # Active Weight ë³€í™” ì‹œê°í™”
                            st.subheader("ğŸ“Š ìì‚°ë³„ Active Weight ë³€í™”")
                            diff = (Wact_alt - Wact_last).sort_values(key=lambda s: s.abs(), ascending=False)

                            # ë³€ê²½ì´ ìˆëŠ” ìì‚°ë§Œ í•„í„°ë§
                            diff_changed = diff[np.abs(diff * 10000) > 1e-6]

                            if len(diff_changed) == 0:
                                st.info("ìì‚°ë³„ Active Weight ë³€ê²½ì´ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                # Slider ì˜¤ë¥˜ ì™„ì „ í•´ê²°
                                max_assets_to_display = len(diff_changed)

                                if max_assets_to_display <= 1:
                                    n_display = max_assets_to_display
                                else:
                                    min_display_assets = min(5, max_assets_to_display)
                                    max_display_assets = min(30, max_assets_to_display)

                                    if min_display_assets >= max_display_assets:
                                        n_display = max_display_assets
                                    else:
                                        default_display_assets = min(15, max_assets_to_display)
                                        n_display = st.slider(
                                            "í‘œì‹œ ìì‚° ìˆ˜",
                                            min_value=min_display_assets,
                                            max_value=max_display_assets,
                                            value=default_display_assets,
                                            key="n_display_constraint"
                                        )

                                show_assets = diff_changed.head(n_display).index.tolist()

                                fig = make_subplots(
                                    rows=2, cols=1,
                                    subplot_titles=("Active Weight ë¹„êµ (bp)", "Active Weight ë³€í™”ëŸ‰ (bp)"),
                                    vertical_spacing=0.15,
                                    row_heights=[0.6, 0.4]
                                )

                                fig.add_trace(
                                    go.Bar(
                                        name="í˜„ì¬",
                                        x=show_assets,
                                        y=(Wact_last.reindex(show_assets) * 10000).values,
                                        marker_color='lightblue',
                                        hovertemplate="%{y:.3f}bp<extra></extra>"
                                    ),
                                    row=1, col=1
                                )
                                fig.add_trace(
                                    go.Bar(
                                        name="ëŒ€ì•ˆ(ì œì•½ Cap)",
                                        x=show_assets,
                                        y=(Wact_alt.reindex(show_assets) * 10000).values,
                                        marker_color='lightcoral',
                                        hovertemplate="%{y:.3f}bp<extra></extra>"
                                    ),
                                    row=1, col=1
                                )

                                changes = (diff.reindex(show_assets) * 10000).values
                                colors = ['green' if c > 0 else 'red' for c in changes]
                                fig.add_trace(
                                    go.Bar(
                                        name="ë³€í™”ëŸ‰",
                                        x=show_assets,
                                        y=changes,
                                        marker_color=colors,
                                        showlegend=False,
                                        hovertemplate="%{y:.3f}bp<extra></extra>"
                                    ),
                                    row=2, col=1
                                )

                                fig.update_xaxes(title_text="", row=1, col=1)
                                fig.update_xaxes(title_text="ìì‚°", row=2, col=1)
                                fig.update_yaxes(title_text="Active Weight (bp)", row=1, col=1, tickformat=".3f")
                                fig.update_yaxes(title_text="ë³€í™”ëŸ‰ (bp)", row=2, col=1, tickformat=".3f")
                                fig.update_layout(barmode='group', height=700, hovermode='x unified')

                                # í°íŠ¸ í¬ê¸° ì ìš©
                                fig = apply_chart_font_settings(fig)

                                st.plotly_chart(fig, use_container_width=True)

                            st.markdown("---")

                            # Pairë³„ ì œì•½ ìƒì„¸ í…Œì´ë¸”
                            st.subheader("ğŸ¯ Pairë³„ ë¦¬ìŠ¤í¬ ì œì•½ ìƒì„¸")

                            bind = (np.abs(x_cur) > np.abs(x_cap) + 1e-9)

                            constraint_col_name = {
                                "3Y_MDD": "MDD_%",
                                "-3STD": "-3STD_%",
                                "-2STD": "-2STD_%",
                                "-1STD": "-1STD_%"
                            }[constraint_method]

                            bind_df = pd.DataFrame({
                                "Pair_ID": pair_ids,
                                "Pair": [f"{p[0]} vs {p[1]}" for p in pairs],
                                "Long_Asset": [p[0] for p in pairs],
                                "Short_Asset": [p[1] for p in pairs],
                                "Signal": signals,
                                constraint_col_name: (constraint_values * 100).round(2),
                                "Max_Loss_bp": max_loss_per_pair.round(3),
                                "Per_Leg_Cap_bp": (cap_arr * 10000).round(3),
                                "Current_Position_bp": (x_cur * 10000).round(3),
                                "Capped_Position_bp": (x_cap * 10000).round(3),
                                "Position_Change_bp": ((x_cap - x_cur) * 10000).round(3),
                                "Actual_Loss_bp": (np.abs(x_cap) * np.abs(constraint_values) * 10000).round(3),
                                "Binding": bind,
                                "Status": ["âš ï¸ ì œì•½ ì ìš©" if b else "âœ… OK" for b in bind]
                            })

                            def highlight_binding(row):
                                if row['Binding']:
                                    return ['background-color: #ffe6e6'] * len(row)
                                return [''] * len(row)

                            styled_df = bind_df.style.apply(highlight_binding, axis=1).format({
                                constraint_col_name: '{:.2f}',
                                'Max_Loss_bp': '{:.3f}',
                                'Per_Leg_Cap_bp': '{:.3f}',
                                'Current_Position_bp': '{:.3f}',
                                'Capped_Position_bp': '{:.3f}',
                                'Position_Change_bp': '{:+.3f}',
                                'Actual_Loss_bp': '{:.3f}'
                            })

                            st.dataframe(styled_df, use_container_width=True)

                            # ìš”ì•½ í†µê³„
                            st.markdown("---")
                            st.subheader("ğŸ“Š ìš”ì•½ í†µê³„")

                            summary_col1, summary_col2, summary_col3, summary_col4 = st.columns(4)

                            with summary_col1:
                                st.metric("ì´ Pair ìˆ˜", len(pairs))
                            with summary_col2:
                                n_binding = bind.sum()
                                st.metric(
                                    "ì œì•½ ì ìš©",
                                    f"{n_binding}ê°œ",
                                    delta=f"{n_binding / len(pairs) * 100:.1f}%" if len(pairs) > 0 else "0%"
                                )
                            with summary_col3:
                                avg_loss = bind_df['Actual_Loss_bp'].mean()
                                max_loss_avg = max_loss_per_pair.mean()
                                st.metric(
                                    "í‰ê·  ì‹¤ì œ ì†ì‹¤",
                                    f"{avg_loss:.3f}bp",
                                    delta=f"í—ˆìš©ì¹˜: {max_loss_avg:.3f}bp"
                                )
                            with summary_col4:
                                avg_constraint = np.abs(constraint_values).mean() * 100
                                st.metric(f"í‰ê·  {constraint_col_name.replace('_%', '')}", f"{avg_constraint:.2f}%")

                            # Position Cap ë¹„êµ ì°¨íŠ¸
                            st.markdown("---")
                            st.subheader("ğŸ¯ í¬ì§€ì…˜ í¬ê¸° ë¹„êµ: Current vs Capped")

                            fig_pos = go.Figure()

                            fig_pos.add_trace(go.Bar(
                                name='í˜„ì¬ í¬ì§€ì…˜',
                                x=bind_df['Pair'],
                                y=bind_df['Current_Position_bp'],
                                marker_color='lightblue',
                                hovertemplate='í˜„ì¬: %{y:.3f}bp<extra></extra>'
                            ))

                            fig_pos.add_trace(go.Bar(
                                name='Capped í¬ì§€ì…˜',
                                x=bind_df['Pair'],
                                y=bind_df['Capped_Position_bp'],
                                marker_color='orange',
                                hovertemplate='Capped: %{y:.3f}bp<extra></extra>'
                            ))

                            fig_pos.update_layout(
                                title='í¬ì§€ì…˜ í¬ê¸° ë¹„êµ (Per Leg, bp)',
                                xaxis_title='Pair',
                                yaxis_title='í¬ì§€ì…˜ í¬ê¸° (bp)',
                                yaxis_tickformat=".3f",
                                height=450,
                                barmode='group',
                                hovermode='x unified'
                            )

                            # í°íŠ¸ í¬ê¸° ì ìš©
                            fig_pos = apply_chart_font_settings(fig_pos)

                            st.plotly_chart(fig_pos, use_container_width=True)

                            # ìµœëŒ€ ì†ì‹¤ vs ì‹¤ì œ ì†ì‹¤ ë¹„êµ
                            st.subheader("ğŸ’° ìµœëŒ€ í—ˆìš© ì†ì‹¤ vs ì‹¤ì œ ì†ì‹¤")

                            fig_loss = go.Figure()

                            fig_loss.add_trace(go.Bar(
                                name='ìµœëŒ€ í—ˆìš© ì†ì‹¤',
                                x=bind_df['Pair'],
                                y=bind_df['Max_Loss_bp'],
                                marker_color='lightgreen',
                                hovertemplate='í—ˆìš©: %{y:.3f}bp<extra></extra>'
                            ))

                            fig_loss.add_trace(go.Bar(
                                name='ì‹¤ì œ ì†ì‹¤ (Capped)',
                                x=bind_df['Pair'],
                                y=bind_df['Actual_Loss_bp'],
                                marker_color='lightcoral',
                                hovertemplate='ì‹¤ì œ: %{y:.3f}bp<extra></extra>'
                            ))

                            fig_loss.update_layout(
                                title='Pairë³„ ìµœëŒ€ í—ˆìš© ì†ì‹¤ vs ì‹¤ì œ ì†ì‹¤ (bp)',
                                xaxis_title='Pair',
                                yaxis_title='ì†ì‹¤ (bp)',
                                yaxis_tickformat=".3f",
                                height=400,
                                barmode='group',
                                hovermode='x unified'
                            )

                            # í°íŠ¸ í¬ê¸° ì ìš©
                            fig_loss = apply_chart_font_settings(fig_loss)

                            st.plotly_chart(fig_loss, use_container_width=True)

                            # ì œì•½ ë°©ë²• ë¹„êµ
                            st.markdown("---")
                            st.subheader("ğŸ”„ ë‹¤ë¥¸ ì œì•½ ë°©ë²•ê³¼ ë¹„êµ")

                            comparison_methods = ["3Y_MDD", "-3STD", "-2STD", "-1STD"]
                            comparison_data = []

                            with st.spinner("ë‹¤ë¥¸ ì œì•½ ë°©ë²• ê³„ì‚° ì¤‘..."):
                                for method in comparison_methods:
                                    if method == constraint_method:
                                        # í˜„ì¬ ë°©ë²•ì€ ì´ë¯¸ ê³„ì‚°ë¨
                                        comparison_data.append({
                                            'Method': method,
                                            'Avg_Position_bp': (x_cap * 10000).mean(),
                                            'Total_TE_bp': te_alt * 10000 if pd.notna(te_alt) else 0,
                                            'Avg_Loss_bp': bind_df['Actual_Loss_bp'].mean()
                                        })
                                    else:
                                        # ë‹¤ë¥¸ ë°©ë²• ê³„ì‚°
                                        constraint_vals_comp, cap_arr_comp = risk_calc.calculate_position_caps(
                                            pairs, signals, method
                                        )
                                        x_comp = np.sign(signals) * cap_arr_comp
                                        Wact_comp = pd.Series(B @ x_comp, index=assets_list)

                                        if not cov_matrix.empty:
                                            te_comp = compute_te_from_active(cov_matrix, cov_use_assets,
                                                                             Wact_comp.reindex(cov_use_assets))
                                        else:
                                            te_comp = np.nan

                                        avg_loss_comp = (np.abs(x_comp) * np.abs(constraint_vals_comp) * 10000).mean()

                                        comparison_data.append({
                                            'Method': method,
                                            'Avg_Position_bp': (x_comp * 10000).mean(),
                                            'Total_TE_bp': te_comp * 10000 if pd.notna(te_comp) else 0,
                                            'Avg_Loss_bp': avg_loss_comp
                                        })

                            comparison_df = pd.DataFrame(comparison_data)

                            # ë¹„êµ ì°¨íŠ¸
                            fig_comp = make_subplots(
                                rows=1, cols=3,
                                subplot_titles=("í‰ê·  í¬ì§€ì…˜", "ì˜ˆìƒ TE", "í‰ê·  ì†ì‹¤"),
                                specs=[[{"type": "bar"}, {"type": "bar"}, {"type": "bar"}]]
                            )

                            colors_comp = ['green' if m == constraint_method else 'lightgray' for m in
                                           comparison_df['Method']]

                            fig_comp.add_trace(
                                go.Bar(
                                    x=comparison_df['Method'],
                                    y=comparison_df['Avg_Position_bp'],
                                    marker_color=colors_comp,
                                    showlegend=False,
                                    hovertemplate="%{y:.3f}bp<extra></extra>"
                                ),
                                row=1, col=1
                            )

                            fig_comp.add_trace(
                                go.Bar(
                                    x=comparison_df['Method'],
                                    y=comparison_df['Total_TE_bp'],
                                    marker_color=colors_comp,
                                    showlegend=False,
                                    hovertemplate="%{y:.3f}bp<extra></extra>"
                                ),
                                row=1, col=2
                            )

                            fig_comp.add_trace(
                                go.Bar(
                                    x=comparison_df['Method'],
                                    y=comparison_df['Avg_Loss_bp'],
                                    marker_color=colors_comp,
                                    showlegend=False,
                                    hovertemplate="%{y:.3f}bp<extra></extra>"
                                ),
                                row=1, col=3
                            )

                            fig_comp.update_yaxes(title_text="bp", tickformat=".3f", row=1, col=1)
                            fig_comp.update_yaxes(title_text="bp", tickformat=".3f", row=1, col=2)
                            fig_comp.update_yaxes(title_text="bp", tickformat=".3f", row=1, col=3)

                            fig_comp.update_layout(height=400, title_text="ë¦¬ìŠ¤í¬ ì œì•½ ë°©ë²• ë¹„êµ")

                            # í°íŠ¸ í¬ê¸° ì ìš©
                            fig_comp = apply_chart_font_settings(fig_comp)

                            st.plotly_chart(fig_comp, use_container_width=True)

                            # ë¹„êµ í…Œì´ë¸”
                            comparison_display = comparison_df.copy()
                            comparison_display['Avg_Position_bp'] = comparison_display['Avg_Position_bp'].apply(
                                lambda x: f"{x:.3f}")
                            comparison_display['Total_TE_bp'] = comparison_display['Total_TE_bp'].apply(
                                lambda x: f"{x:.3f}")
                            comparison_display['Avg_Loss_bp'] = comparison_display['Avg_Loss_bp'].apply(
                                lambda x: f"{x:.3f}")

                            # í˜„ì¬ ë°©ë²• í•˜ì´ë¼ì´íŠ¸
                            def highlight_current_method(row):
                                if row['Method'] == constraint_method:
                                    return ['background-color: #e7f3ff'] * len(row)
                                return [''] * len(row)

                            styled_comp_df = comparison_display.style.apply(highlight_current_method, axis=1)
                            st.dataframe(styled_comp_df, use_container_width=True)

                            # CSV ë‹¤ìš´ë¡œë“œ
                            st.markdown("---")
                            st.subheader("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")

                            col_d1, col_d2, col_d3 = st.columns(3)

                            with col_d1:
                                csv_pair = bind_df.to_csv(index=False).encode('utf-8-sig')
                                st.download_button(
                                    label="ğŸ“¥ Pair ì œì•½ ìƒì„¸ ë‹¤ìš´ë¡œë“œ",
                                    data=csv_pair,
                                    file_name=f"constraint_analysis_{constraint_method}_{default_max_loss_bp:.3f}bp.csv",
                                    mime="text/csv",
                                    key="download_pair_constraints_detail"
                                )

                            with col_d2:
                                weight_change_df = pd.DataFrame({
                                    'Asset': assets_list,
                                    'Current_Active_bp': (Wact_last.reindex(assets_list) * 10000).values,
                                    'Alternative_Active_bp': (Wact_alt.reindex(assets_list) * 10000).values,
                                    'Change_bp': ((Wact_alt.reindex(assets_list) - Wact_last.reindex(
                                        assets_list)) * 10000).values
                                }).sort_values('Change_bp', key=lambda x: x.abs(), ascending=False)

                                # ì†Œìˆ˜ì  3ìë¦¬ í¬ë§·
                                for col in ['Current_Active_bp', 'Alternative_Active_bp', 'Change_bp']:
                                    weight_change_df[col] = weight_change_df[col].apply(lambda x: f"{x:.3f}")

                                csv_weight = weight_change_df.to_csv(index=False).encode('utf-8-sig')
                                st.download_button(
                                    label="ğŸ“¥ Active Weight ë³€í™” ë‹¤ìš´ë¡œë“œ",
                                    data=csv_weight,
                                    file_name=f"active_weight_changes_{constraint_method}_{default_max_loss_bp:.3f}bp.csv",
                                    mime="text/csv",
                                    key="download_weight_changes_constraint"
                                )

                            with col_d3:
                                csv_comp = comparison_df.to_csv(index=False).encode('utf-8-sig')
                                st.download_button(
                                    label="ğŸ“¥ ì œì•½ ë°©ë²• ë¹„êµ ë‹¤ìš´ë¡œë“œ",
                                    data=csv_comp,
                                    file_name=f"constraint_method_comparison_{lookback_years}y.csv",
                                    mime="text/csv",
                                    key="download_comparison"
                                )

    # =========================================================================
    # Tab 11: ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ (Enhanced with Risk Simulation)
    # =========================================================================
    with tabs[11]:
        st.header("ğŸ“Š ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ë¶„ì„ & ë¦¬ìŠ¤í¬ ì‹œë®¬ë ˆì´ì…˜")
        st.markdown("""
        ì—…ë¡œë“œëœ ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„±ê³¼ë¥¼ ë¶„ì„í•˜ê³ , í¬ì§€ì…˜ í¬ê¸° ë³€ê²½ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ ë³€í™”ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.

        **ìƒˆë¡œìš´ ê¸°ëŠ¥:**
        1. ğŸ“Š **í¬ì§€ì…˜ íƒ€ì… ë° í¬ê¸° ì¡°ì • â†’ ë¦¬ìŠ¤í¬ ë³€í™”**: ê° í˜ì–´ì˜ í¬ì§€ì…˜ íƒ€ì…ê³¼ í¬ê¸°ë¥¼ ë³€ê²½í–ˆì„ ë•Œ í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ë¦¬ìŠ¤í¬ê°€ ì–¼ë§ˆë‚˜ ë³€í•˜ëŠ”ì§€ í™•ì¸
        2. ğŸ¯ **ëª©í‘œ ë¦¬ìŠ¤í¬ â†’ í¬ì§€ì…˜ ì—­ì‚°**: ì›í•˜ëŠ” ë¦¬ìŠ¤í¬ ë³€í™”ëŸ‰ì„ ì…ë ¥í•˜ë©´ í•´ë‹¹ í˜ì–´ì˜ í¬ì§€ì…˜ í¬ê¸°ë¥¼ ìë™ ê³„ì‚°
        3. ğŸ“ˆ **ì†ìµ ë¶„í¬ ê·¸ë˜í”„**: -3Ïƒ ~ +3Ïƒ ì‹œë‚˜ë¦¬ì˜¤ë³„ P&L ë¶„í¬ ì‹œê°í™” (í˜„ì¬ + ì¡°ì • í¬ì§€ì…˜ ë¹„êµ)

        **í¬ì§€ì…˜ íƒ€ì… (ê° ìì‚°ë³„ Long/Short ì„ íƒ ê°€ëŠ¥):**
        - âš–ï¸ **Pair (L/S)**: Long ìì‚° ë§¤ìˆ˜ + Short ìì‚° ë§¤ë„ ë™ì‹œ í¬ì§€ì…˜
        - ğŸ“ˆ **Long: [ìì‚°ëª…]**: í•´ë‹¹ ìì‚°ë§Œ ë‹¨ë… ë§¤ìˆ˜ (Long/Short ì–‘ìª½ ìì‚° ëª¨ë‘ ì„ íƒ ê°€ëŠ¥)
        - ğŸ“‰ **Short: [ìì‚°ëª…]**: í•´ë‹¹ ìì‚°ë§Œ ë‹¨ë… ë§¤ë„ (Long/Short ì–‘ìª½ ìì‚° ëª¨ë‘ ì„ íƒ ê°€ëŠ¥)
        """)

        # ===== íŒŒì¼ ë¡œë“œ =====
        try:
            import os

            # ê¸°ë³¸ ë””ë ‰í† ë¦¬
            base_dir = data_dir  # Streamlit Cloud compatible

            # ìˆ˜ìµë¥  ë°ì´í„°
            actual_returns_df = pd.read_csv(
                os.path.join(base_dir, 'actual_portfolio_returns.csv'),
                parse_dates=['Date'],
                index_col='Date'
            )

            # í¬ì§€ì…˜ ë°ì´í„°
            actual_positions_df = pd.read_csv(
                os.path.join(base_dir, 'actual_portfolio_positions.csv'),
                parse_dates=['Date']
            )

            # ìš”ì•½ ë°ì´í„°
            actual_summary_df = pd.read_csv(
                os.path.join(base_dir, 'actual_portfolio_summary.csv')
            )

            # ===== Inception ë‚ ì§œ ê²°ì • (í¬ì§€ì…˜ ì§„ì…ì¼ ê¸°ì¤€) =====
            # ENTRY ì´ë²¤íŠ¸ê°€ ìˆëŠ” ë‚ ì§œë“¤ ì°¾ê¸°
            entry_dates = actual_positions_df[
                actual_positions_df['Event'].str.contains('ENTRY', case=False, na=False)
            ]['Date']

            if not entry_dates.empty:
                inception_date = entry_dates.min()
                st.info(f"ğŸ“… **Inception Date**: {inception_date.strftime('%Y-%m-%d')} (ì²« í¬ì§€ì…˜ ì§„ì…ì¼)")
            else:
                # ENTRY ì´ë²¤íŠ¸ê°€ ì—†ìœ¼ë©´ í¬ì§€ì…˜ ë°ì´í„°ì˜ ê°€ì¥ ë¹ ë¥¸ ë‚ ì§œ ì‚¬ìš©
                inception_date = actual_positions_df['Date'].min()
                st.info(f"ğŸ“… **Inception Date**: {inception_date.strftime('%Y-%m-%d')} (í¬ì§€ì…˜ ë°ì´í„° ì‹œì‘ì¼)")

            # Inception ë‚ ì§œ ì´í›„ ë°ì´í„°ë§Œ í•„í„°ë§
            actual_returns_df = actual_returns_df[actual_returns_df.index >= inception_date]

            st.success(
                f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(actual_returns_df)}ì¼, "
                f"{actual_returns_df.index.min().date()} ~ {actual_returns_df.index.max().date()}"
            )

        except FileNotFoundError as e:
            st.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            st.info(
                "ğŸ“ ë‹¤ìŒ íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì„¸ìš”:\n- actual_portfolio_returns.csv\n- actual_portfolio_positions.csv\n- actual_portfolio_summary.csv")
            st.stop()
        except Exception as e:
            st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()

        # ===== ê¸°ê°„ ì„ íƒ UI =====
        st.markdown("---")
        st.subheader("ğŸ“… ë¶„ì„ ê¸°ê°„ ì„¤ì •")

        col_period1, col_period2, col_period3 = st.columns([1, 1, 1])

        with col_period1:
            # ë¹ ë¥¸ ì„ íƒ
            quick_period = st.selectbox(
                "ë¹ ë¥¸ ê¸°ê°„ ì„ íƒ",
                ["ì „ì²´ ê¸°ê°„", "ìµœê·¼ 1ê°œì›”", "ìµœê·¼ 3ê°œì›”", "ìµœê·¼ 6ê°œì›”", "ìµœê·¼ 1ë…„", "ì‚¬ìš©ì ì§€ì •"],
                key="quick_period_selector"
            )

        # ê¸°ê°„ ê³„ì‚°
        data_end_date = actual_returns_df.index.max()
        data_start_date = actual_returns_df.index.min()

        if quick_period == "ì „ì²´ ê¸°ê°„":
            selected_start = data_start_date
            selected_end = data_end_date
            manual_selection = False
        elif quick_period == "ìµœê·¼ 1ê°œì›”":
            selected_start = max(data_start_date, data_end_date - pd.Timedelta(days=30))
            selected_end = data_end_date
            manual_selection = False
        elif quick_period == "ìµœê·¼ 3ê°œì›”":
            selected_start = max(data_start_date, data_end_date - pd.Timedelta(days=90))
            selected_end = data_end_date
            manual_selection = False
        elif quick_period == "ìµœê·¼ 6ê°œì›”":
            selected_start = max(data_start_date, data_end_date - pd.Timedelta(days=180))
            selected_end = data_end_date
            manual_selection = False
        elif quick_period == "ìµœê·¼ 1ë…„":
            selected_start = max(data_start_date, data_end_date - pd.Timedelta(days=365))
            selected_end = data_end_date
            manual_selection = False
        else:  # ì‚¬ìš©ì ì§€ì •
            manual_selection = True
            with col_period2:
                selected_start = st.date_input(
                    "ì‹œì‘ì¼",
                    value=data_start_date.date(),
                    min_value=data_start_date.date(),
                    max_value=data_end_date.date(),
                    key="custom_start_date"
                )
                selected_start = pd.Timestamp(selected_start)

            with col_period3:
                selected_end = st.date_input(
                    "ì¢…ë£Œì¼",
                    value=data_end_date.date(),
                    min_value=data_start_date.date(),
                    max_value=data_end_date.date(),
                    key="custom_end_date"
                )
                selected_end = pd.Timestamp(selected_end)

        # ì„ íƒëœ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§
        filtered_returns = actual_returns_df[
            (actual_returns_df.index >= selected_start) &
            (actual_returns_df.index <= selected_end)
            ].copy()

        if filtered_returns.empty:
            st.warning("âš ï¸ ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        # ê¸°ê°„ ì •ë³´ í‘œì‹œ
        n_trading_days = len(filtered_returns)
        st.caption(
            f"ğŸ“Š ì„ íƒ ê¸°ê°„: **{selected_start.strftime('%Y-%m-%d')}** ~ **{selected_end.strftime('%Y-%m-%d')}** "
            f"({n_trading_days}ì¼)"
        )

        # ===== ê¸°ê°„ ì •ì˜ (ì„ íƒëœ ë°ì´í„° ê¸°ì¤€) =====
        periods_config = {
            '1D': 1,
            '1W': 5,
            '2W': 10,
            '1M': 21,
            '3M': 63,
            '6M': 126,
            '12M': 252,
            'Inception': len(filtered_returns)
        }

        # ===== ê¸°ê°„ë³„ ì„±ê³¼ ê³„ì‚° í•¨ìˆ˜ =====
        def calculate_period_metrics(returns_series, period_days):
            """ê¸°ê°„ë³„ ì„±ê³¼ ì§€í‘œ ê³„ì‚°"""
            if len(returns_series) < period_days:
                period_returns = returns_series
            else:
                period_returns = returns_series.tail(period_days)

            if len(period_returns) == 0:
                return {
                    'cumulative_return': 0.0,
                    'annualized_return': 0.0,
                    'annualized_volatility': 0.0,
                    'sharpe_ratio': 0.0,
                    'max_drawdown': 0.0,
                    'n_days': 0
                }

            # ëˆ„ì  ìˆ˜ìµë¥ 
            cum_ret = (1 + period_returns).prod() - 1

            # ê±°ë˜ì¼ ìˆ˜
            n_days = len(period_returns)

            # ì—°ìœ¨í™” ìˆ˜ìµë¥ 
            if n_days > 0:
                ann_ret = (1 + cum_ret) ** (252 / n_days) - 1
            else:
                ann_ret = 0.0

            # ì—°ìœ¨í™” ë³€ë™ì„±
            ann_vol = period_returns.std() * np.sqrt(252)

            # Sharpe Ratio
            if ann_vol > 0:
                sharpe = ann_ret / ann_vol
            else:
                sharpe = 0.0

            # MDD ê³„ì‚°
            cum_series = (1 + period_returns).cumprod()
            running_max = cum_series.expanding().max()
            drawdown = (cum_series - running_max) / running_max
            mdd = drawdown.min()

            return {
                'cumulative_return': cum_ret,
                'annualized_return': ann_ret,
                'annualized_volatility': ann_vol,
                'sharpe_ratio': sharpe,
                'max_drawdown': mdd,
                'n_days': n_days
            }

        # ===== ëˆ„ì  ìˆ˜ìµë¥  ê·¸ë˜í”„ =====
        st.markdown("---")
        st.subheader("ğŸ“ˆ ëˆ„ì  ìˆ˜ìµë¥  ì¶”ì´")

        cum_returns = (1 + filtered_returns['Actual_Portfolio_Return']).cumprod() - 1

        fig_cum = go.Figure()

        fig_cum.add_trace(go.Scatter(
            x=cum_returns.index,
            y=cum_returns.values * 10000,  # bp ë‹¨ìœ„
            mode='lines',
            name='ëˆ„ì  ìˆ˜ìµë¥ ',
            line=dict(color='#1f77b4', width=2.5),
            fill='tozeroy',
            fillcolor='rgba(31, 119, 180, 0.1)',
            hovertemplate='%{x|%Y-%m-%d}<br>%{y:.3f}bp<extra></extra>'
        ))

        fig_cum.update_layout(
            title=f"ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ëˆ„ì  ìˆ˜ìµë¥  (bp) - {selected_start.strftime('%Y-%m-%d')} ~ {selected_end.strftime('%Y-%m-%d')}",
            xaxis_title="ë‚ ì§œ",
            yaxis_title="ëˆ„ì  ìˆ˜ìµë¥  (bp)",
            height=500,
            hovermode='x unified'
        )

        fig_cum.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
        fig_cum = apply_chart_font_settings(fig_cum)

        st.plotly_chart(fig_cum, use_container_width=True)

        # ===== ê¸°ê°„ë³„ ì„±ê³¼ í…Œì´ë¸” =====
        st.markdown("---")
        st.subheader("ğŸ“Š ê¸°ê°„ë³„ ì„±ê³¼ ì§€í‘œ")

        # ì„±ê³¼ ê³„ì‚°
        performance_data = []

        for period_name, period_days in periods_config.items():
            metrics = calculate_period_metrics(
                filtered_returns['Actual_Portfolio_Return'],
                period_days
            )

            performance_data.append({
                'ê¸°ê°„': period_name,
                'ê±°ë˜ì¼': f"{metrics['n_days']}ì¼",
                'ëˆ„ì  ìˆ˜ìµë¥  (bp)': f"{metrics['cumulative_return'] * 10000:.3f}",
                'ì—°ìœ¨í™” ìˆ˜ìµë¥  (bp)': f"{metrics['annualized_return'] * 10000:.3f}",
                'ì—°ìœ¨í™” ë³€ë™ì„± (bp)': f"{metrics['annualized_volatility'] * 10000:.3f}",
                'Sharpe Ratio': f"{metrics['sharpe_ratio']:.3f}",
                'MDD (%)': f"{metrics['max_drawdown'] * 100:.2f}"
            })

        performance_df = pd.DataFrame(performance_data)

        # ìŠ¤íƒ€ì¼ë§
        def highlight_inception(row):
            if row['ê¸°ê°„'] == 'Inception':
                return ['background-color: #e7f3ff; font-weight: bold'] * len(row)
            return [''] * len(row)

        styled_performance = performance_df.style.apply(highlight_inception, axis=1)

        st.dataframe(styled_performance, use_container_width=True)

        st.caption(f"ğŸ’¡ Inception = ì„ íƒëœ ì „ì²´ ê¸°ê°„ ({n_trading_days}ì¼)")

        # ===== ìš”ì•½ í†µê³„ (ì„ íƒ ê¸°ê°„ ê¸°ì¤€) =====
        st.markdown("---")
        st.subheader("ğŸ“‹ ì„ íƒ ê¸°ê°„ ìš”ì•½ í†µê³„")

        # ì„ íƒ ê¸°ê°„ì˜ í†µê³„ ê³„ì‚°
        selected_metrics = calculate_period_metrics(
            filtered_returns['Actual_Portfolio_Return'],
            len(filtered_returns)
        )

        col1, col2, col3, col4, col5 = st.columns(5)

        with col1:
            st.metric("ëˆ„ì  ìˆ˜ìµë¥ ", f"{selected_metrics['cumulative_return'] * 10000:.3f}bp")

        with col2:
            st.metric("ì—°ìœ¨í™” ìˆ˜ìµë¥ ", f"{selected_metrics['annualized_return'] * 10000:.3f}bp")

        with col3:
            st.metric("ì—°ìœ¨í™” ë³€ë™ì„±", f"{selected_metrics['annualized_volatility'] * 10000:.3f}bp")

        with col4:
            st.metric("Sharpe Ratio", f"{selected_metrics['sharpe_ratio']:.3f}")

        with col5:
            st.metric("Max Drawdown", f"{selected_metrics['max_drawdown'] * 100:.2f}%")

        st.caption(
            f"ğŸ“… ë¶„ì„ ê¸°ê°„: {selected_start.strftime('%Y-%m-%d')} ~ {selected_end.strftime('%Y-%m-%d')} ({selected_metrics['n_days']}ì¼)")

        # ===== ì „ì²´ ê¸°ê°„ ìš”ì•½ (ì°¸ê³ ìš©) =====
        with st.expander("ğŸ“Š ì „ì²´ ê¸°ê°„ ìš”ì•½ í†µê³„ (ì°¸ê³ )", expanded=False):
            summary_dict = dict(zip(actual_summary_df['Metric'], actual_summary_df['Value']))

            col1, col2, col3, col4, col5 = st.columns(5)

            with col1:
                cum_ret_summary = float(summary_dict.get('Cumulative_Return', 0))
                st.metric("ëˆ„ì  ìˆ˜ìµë¥ ", f"{cum_ret_summary * 10000:.3f}bp")

            with col2:
                ann_ret_summary = float(summary_dict.get('Annualized_Return', 0))
                st.metric("ì—°ìœ¨í™” ìˆ˜ìµë¥ ", f"{ann_ret_summary * 10000:.3f}bp")

            with col3:
                vol_summary = float(summary_dict.get('Volatility', 0))
                st.metric("ì—°ìœ¨í™” ë³€ë™ì„±", f"{vol_summary * 10000:.3f}bp")

            with col4:
                mdd_summary = float(summary_dict.get('Max_Drawdown', 0))
                st.metric("Max Drawdown", f"{mdd_summary * 100:.2f}%")

            with col5:
                trading_days = int(summary_dict.get('Trading_Days', 0))
                st.metric("ì´ ê±°ë˜ì¼", f"{trading_days}ì¼")

            start_date = summary_dict.get('Start_Date', 'N/A')
            end_date = summary_dict.get('End_Date', 'N/A')
            st.caption(f"ğŸ“… ì „ì²´ ê¸°ê°„: {start_date} ~ {end_date}")

        # ===== Drawdown ì°¨íŠ¸ =====
        st.markdown("---")
        st.subheader("ğŸ“‰ Drawdown ì¶”ì´")

        cum_series = (1 + filtered_returns['Actual_Portfolio_Return']).cumprod()
        running_max = cum_series.expanding().max()
        drawdown = (cum_series - running_max) / running_max

        fig_dd = go.Figure()

        fig_dd.add_trace(go.Scatter(
            x=drawdown.index,
            y=drawdown.values * 100,  # % ë‹¨ìœ„
            mode='lines',
            name='Drawdown',
            line=dict(color='#d62728', width=2),
            fill='tozeroy',
            fillcolor='rgba(214, 39, 40, 0.1)',
            hovertemplate='%{x|%Y-%m-%d}<br>%{y:.2f}%<extra></extra>'
        ))

        # MDD í‘œì‹œ
        mdd_value = drawdown.min()
        mdd_date = drawdown.idxmin()

        fig_dd.add_trace(go.Scatter(
            x=[mdd_date],
            y=[mdd_value * 100],
            mode='markers+text',
            marker=dict(color='red', size=12, symbol='x'),
            text=[f'MDD: {mdd_value * 100:.2f}%'],
            textposition='top center',
            name='Max Drawdown',
            showlegend=True,
            hovertemplate=f'MDD: {mdd_value * 100:.2f}%<br>{mdd_date.strftime("%Y-%m-%d")}<extra></extra>'
        ))

        fig_dd.update_layout(
            title=f"Drawdown (%) - {selected_start.strftime('%Y-%m-%d')} ~ {selected_end.strftime('%Y-%m-%d')}",
            xaxis_title="ë‚ ì§œ",
            yaxis_title="Drawdown (%)",
            height=400,
            hovermode='x unified'
        )

        fig_dd.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
        fig_dd = apply_chart_font_settings(fig_dd)

        st.plotly_chart(fig_dd, use_container_width=True)

        # ===== ì¼ë³„ ìˆ˜ìµë¥  ë¶„í¬ =====
        st.markdown("---")
        st.subheader("ğŸ“Š ì¼ë³„ ìˆ˜ìµë¥  ë¶„í¬")

        col_dist1, col_dist2 = st.columns(2)

        with col_dist1:
            # íˆìŠ¤í† ê·¸ë¨
            fig_hist = go.Figure()

            fig_hist.add_trace(go.Histogram(
                x=filtered_returns['Actual_Portfolio_Return'] * 10000,
                nbinsx=50,
                name='ì¼ë³„ ìˆ˜ìµë¥ ',
                marker_color='#1f77b4',
                opacity=0.7
            ))

            # í‰ê· ì„ 
            mean_ret = filtered_returns['Actual_Portfolio_Return'].mean() * 10000
            fig_hist.add_vline(
                x=mean_ret,
                line_dash="dash",
                line_color="red",
                line_width=2,
                annotation_text=f"í‰ê· : {mean_ret:.3f}bp"
            )

            fig_hist.update_layout(
                title="ì¼ë³„ ìˆ˜ìµë¥  ë¶„í¬ (bp)",
                xaxis_title="ì¼ë³„ ìˆ˜ìµë¥  (bp)",
                yaxis_title="ë¹ˆë„",
                height=400,
                showlegend=False
            )

            fig_hist = apply_chart_font_settings(fig_hist)
            st.plotly_chart(fig_hist, use_container_width=True)

        with col_dist2:
            # í†µê³„ ìš”ì•½
            st.markdown("#### ğŸ“ˆ ë¶„í¬ í†µê³„")

            returns_bp = filtered_returns['Actual_Portfolio_Return'] * 10000

            stats_col1, stats_col2 = st.columns(2)

            with stats_col1:
                st.metric("í‰ê· ", f"{returns_bp.mean():.3f}bp")
                st.metric("ì¤‘ì•™ê°’", f"{returns_bp.median():.3f}bp")
                st.metric("í‘œì¤€í¸ì°¨", f"{returns_bp.std():.3f}bp")

            with stats_col2:
                st.metric("ìµœëŒ€ê°’", f"{returns_bp.max():.3f}bp")
                st.metric("ìµœì†Œê°’", f"{returns_bp.min():.3f}bp")

                # ì–‘ìˆ˜/ìŒìˆ˜ ë¹„ìœ¨
                positive_days = (returns_bp > 0).sum()
                total_days = len(returns_bp)
                win_rate = (positive_days / total_days * 100) if total_days > 0 else 0
                st.metric("ì–‘ìˆ˜ ë¹„ìœ¨", f"{win_rate:.1f}%")

        # ===== ì›”ë³„ ìˆ˜ìµë¥  íˆíŠ¸ë§µ =====
        st.markdown("---")
        st.subheader("ğŸ—“ï¸ ì›”ë³„ ìˆ˜ìµë¥  íˆíŠ¸ë§µ")

        # ì›”ë³„ ìˆ˜ìµë¥  ê³„ì‚°
        monthly_returns = filtered_returns['Actual_Portfolio_Return'].resample('M').apply(
            lambda x: (1 + x).prod() - 1
        )

        if len(monthly_returns) > 0:
            # ì—°ë„ì™€ ì›”ë¡œ ë¶„ë¦¬
            monthly_returns_df = pd.DataFrame({
                'Year': monthly_returns.index.year,
                'Month': monthly_returns.index.month,
                'Return': monthly_returns.values * 10000  # bp ë‹¨ìœ„
            })

            # í”¼ë²— í…Œì´ë¸” ìƒì„±
            pivot_monthly = monthly_returns_df.pivot(
                index='Year',
                columns='Month',
                values='Return'
            )

            # ì›” ì´ë¦„ìœ¼ë¡œ ë³€ê²½
            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
            pivot_monthly.columns = [month_names[i - 1] for i in pivot_monthly.columns]

            fig_heatmap = go.Figure(data=go.Heatmap(
                z=pivot_monthly.values,
                x=pivot_monthly.columns,
                y=pivot_monthly.index,
                colorscale='RdYlGn',
                zmid=0,
                text=pivot_monthly.values,
                texttemplate='%{text:.2f}',
                textfont={"size": 20},
                colorbar=dict(title="bp")
            ))

            fig_heatmap.update_layout(
                title=f"ì›”ë³„ ìˆ˜ìµë¥  (bp) - {selected_start.strftime('%Y-%m-%d')} ~ {selected_end.strftime('%Y-%m-%d')}",
                xaxis_title="ì›”",
                yaxis_title="ì—°ë„",
                height=max(300, len(pivot_monthly) * 40)  # ë™ì  ë†’ì´
            )

            fig_heatmap = apply_chart_font_settings(fig_heatmap)
            st.plotly_chart(fig_heatmap, use_container_width=True)
        else:
            st.info("ì„ íƒí•œ ê¸°ê°„ì— ì›”ë³„ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # ===== í¬ì§€ì…˜ ì •ë³´ =====
        if not actual_positions_df.empty:
            st.markdown("---")
            st.subheader("ğŸ“‹ ìµœê·¼ í¬ì§€ì…˜ ì •ë³´")

            # ì„ íƒ ê¸°ê°„ ë‚´ì˜ í¬ì§€ì…˜ë§Œ í•„í„°ë§
            period_positions = actual_positions_df[
                (actual_positions_df['Date'] >= selected_start) &
                (actual_positions_df['Date'] <= selected_end)
                ].copy()

            if not period_positions.empty:
                # ìµœê·¼ ë‚ ì§œ
                latest_date = period_positions['Date'].max()
                latest_positions = period_positions[
                    period_positions['Date'] == latest_date
                    ].copy()

                if not latest_positions.empty:
                    st.markdown(f"**ğŸ“… ê¸°ì¤€ì¼: {latest_date.strftime('%Y-%m-%d')}**")

                    # ìš”ì•½ í†µê³„
                    col_p1, col_p2, col_p3, col_p4 = st.columns(4)

                    with col_p1:
                        n_pairs = len(latest_positions)
                        st.metric("í™œì„± Pair", f"{n_pairs}ê°œ")

                    with col_p2:
                        total_pnl_bp = latest_positions['Position_PnL_bp'].sum()
                        st.metric("ë‹¹ì¼ ì´ P&L", f"{total_pnl_bp:.3f}bp")

                    with col_p3:
                        avg_size = latest_positions['Size'].mean()
                        st.metric("í‰ê·  í¬ì§€ì…˜", f"{avg_size:.4f}")

                    with col_p4:
                        n_cash_pairs = latest_positions['Is_Cash_Pair'].sum()
                        st.metric("Cash Pair", f"{n_cash_pairs}ê°œ")

                    # ìƒì„¸ í…Œì´ë¸”
                    with st.expander("ğŸ“Š í¬ì§€ì…˜ ìƒì„¸ ì •ë³´", expanded=False):
                        display_positions = latest_positions[[
                            'Pair_ID', 'Pair', 'Size', 'Direction',
                            'Spread_Return_%', 'Position_PnL_bp'
                        ]].copy()

                        # í¬ë§·íŒ…
                        display_positions['Spread_Return_%'] = display_positions['Spread_Return_%'].apply(
                            lambda x: f"{x:.2f}%"
                        )
                        display_positions['Position_PnL_bp'] = display_positions['Position_PnL_bp'].apply(
                            lambda x: f"{x:.3f}"
                        )
                        display_positions['Size'] = display_positions['Size'].apply(
                            lambda x: f"{x:.4f}"
                        )

                        st.dataframe(display_positions, use_container_width=True)

                    # ê¸°ê°„ ë‚´ í¬ì§€ì…˜ ì§„ì… ì´ë ¥
                    st.markdown("#### ğŸ“ í¬ì§€ì…˜ ì§„ì… ì´ë ¥")

                    entry_positions = period_positions[
                        period_positions['Event'].str.contains('ENTRY', case=False, na=False)
                    ].copy()

                    if not entry_positions.empty:
                        st.info(f"ğŸ’¡ ì„ íƒ ê¸°ê°„ ë‚´ {len(entry_positions)}ê±´ì˜ í¬ì§€ì…˜ ì§„ì…")

                        # ì§„ì… ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
                        entry_by_date = entry_positions.groupby('Date').agg({
                            'Pair_ID': 'count',
                            'Pair': lambda x: ', '.join(x.unique())
                        }).reset_index()
                        entry_by_date.columns = ['ì§„ì…ì¼', 'Pair ìˆ˜', 'Pair ëª©ë¡']
                        entry_by_date['ì§„ì…ì¼'] = entry_by_date['ì§„ì…ì¼'].dt.strftime('%Y-%m-%d')

                        st.dataframe(entry_by_date, use_container_width=True)
            else:
                st.info("ì„ íƒí•œ ê¸°ê°„ì— í¬ì§€ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # =========================================================================
        # ìƒˆë¡œìš´ ì„¹ì…˜: í¬ì§€ì…˜ë³„ ìƒì„¸ í†µê³„ (Position Statistics)
        # =========================================================================
        st.markdown("---")
        st.subheader("ğŸ“Š í¬ì§€ì…˜ë³„ ìƒì„¸ í†µê³„")

        try:
            # í¬ì§€ì…˜ í†µê³„ íŒŒì¼ ë¡œë“œ
            position_stats_path = os.path.join(base_dir, 'actual_portfolio_position_statistics.csv')
            if os.path.exists(position_stats_path):
                position_stats_df = pd.read_csv(position_stats_path)

                if not position_stats_df.empty:
                    st.success(f"âœ… {len(position_stats_df)}ê°œ í¬ì§€ì…˜ í†µê³„ ë¡œë“œ ì™„ë£Œ")

                    # í¬ì§€ì…˜ íƒ€ì…ë³„ í•„í„°
                    col_filter1, col_filter2 = st.columns(2)
                    with col_filter1:
                        pos_types = ['ì „ì²´'] + list(position_stats_df['Position_Type'].unique())
                        selected_pos_type = st.selectbox("í¬ì§€ì…˜ íƒ€ì…", pos_types, key="pos_type_filter")

                    with col_filter2:
                        status_options = ['ì „ì²´'] + list(position_stats_df['Status'].unique())
                        selected_status = st.selectbox("ìƒíƒœ", status_options, key="status_filter")

                    # í•„í„°ë§
                    filtered_stats = position_stats_df.copy()
                    if selected_pos_type != 'ì „ì²´':
                        filtered_stats = filtered_stats[filtered_stats['Position_Type'] == selected_pos_type]
                    if selected_status != 'ì „ì²´':
                        filtered_stats = filtered_stats[filtered_stats['Status'] == selected_status]

                    # Sizeë¥¼ bpë¡œ ë³€í™˜ (ì†Œìˆ˜ â†’ bp)
                    if 'Size' in filtered_stats.columns:
                        filtered_stats['Size_bp'] = filtered_stats['Size'] * 10000

                    # TE (bp) ê³„ì‚° - ê³µë¶„ì‚° í–‰ë ¬ ê¸°ë°˜ Marginal Contribution to TE
                    # filtered_stats ìì²´ì˜ Long_Asset, Short_Asset, Size ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°
                    total_te_bp = 0.0
                    filtered_stats['TE_bp'] = 0.0
                    filtered_stats['TE_Contribution_Pct'] = 0.0

                    try:
                        # ê³µë¶„ì‚° í–‰ë ¬ ê¸°ë°˜ TE ê³„ì‚° ì‹œë„
                        # filtered_statsì—ì„œ Long_Asset, Short_Asset, Size ì •ë³´ë¥¼ ì§ì ‘ ì‚¬ìš©
                        has_asset_info = ('Long_Asset' in filtered_stats.columns and
                                          'Short_Asset' in filtered_stats.columns and
                                          'Size' in filtered_stats.columns)

                        if not returns_by_asset.empty and not w_opt_daily.empty and not w_bmk_daily.empty and has_asset_info:
                            asof = min(w_opt_daily.index.max(), w_bmk_daily.index.max())
                            Wopt_last = w_opt_daily.loc[asof].fillna(0.0)

                            cols = [c for c in returns_by_asset.columns if c in Wopt_last.index]
                            R = returns_by_asset[cols]
                            R_dec = _pc_ensure_decimal_returns(R)
                            C = _pc_build_recent_cov_constant_corr(R_dec, window=63, rho=0.25)

                            # í˜„ì¬ í¬ì§€ì…˜ì˜ active weights ê³„ì‚° - filtered_stats (position_stats_df) ì‚¬ìš©
                            # Open ìƒíƒœì¸ í¬ì§€ì…˜ë§Œ ì‚¬ìš© (Status == 'Open')
                            open_positions = filtered_stats[filtered_stats['Status'] == 'Open'].copy()

                            # Open í¬ì§€ì…˜ì´ ì—†ìœ¼ë©´ ì „ì²´ í¬ì§€ì…˜ ì‚¬ìš© (íˆìŠ¤í† ë¦¬ ë¶„ì„ìš©)
                            if open_positions.empty:
                                open_positions = filtered_stats.copy()

                            w_active = pd.Series(0.0, index=cols)

                            for _, row in open_positions.iterrows():
                                long_asset = str(row.get('Long_Asset', ''))
                                short_asset = str(row.get('Short_Asset', ''))
                                # SizeëŠ” ì†Œìˆ˜ í˜•íƒœ
                                size_decimal = float(row.get('Size', 0.0))
                                pos_bp = abs(size_decimal)  # ì†Œìˆ˜ í˜•íƒœ

                                # Position_Typeì— ë”°ë¼ ì²˜ë¦¬
                                pos_type = str(row.get('Position_Type', 'Pair'))

                                if pos_type == 'Single':
                                    # ë‹¨ì¼ í¬ì§€ì…˜: Long_Asset ë˜ëŠ” Short_Asset ì¤‘ ìœ íš¨í•œ ê²ƒë§Œ
                                    if long_asset and long_asset in w_active.index and long_asset != 'Cash':
                                        if size_decimal >= 0:
                                            w_active[long_asset] += pos_bp
                                        else:
                                            w_active[long_asset] -= pos_bp
                                    elif short_asset and short_asset in w_active.index and short_asset != 'Cash':
                                        if size_decimal >= 0:
                                            w_active[short_asset] -= pos_bp
                                        else:
                                            w_active[short_asset] += pos_bp
                                else:
                                    # Pair í¬ì§€ì…˜: Long ë§¤ìˆ˜ + Short ë§¤ë„
                                    if long_asset and long_asset in w_active.index:
                                        w_active[long_asset] += pos_bp
                                    if short_asset and short_asset in w_active.index and short_asset != 'Cash':
                                        w_active[short_asset] -= pos_bp

                            # í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ TE ê³„ì‚°
                            total_te_bp = _pc_te_bp_from_cov(w_active.values, C, 252)

                            # Marginal Contribution to TE ê³„ì‚°
                            # MCTE_i = (C @ w)_i / TE
                            # í¬ì§€ì…˜ë³„ TE ê¸°ì—¬ = |w_i| * MCTE_i
                            if total_te_bp > 0:
                                C_np = C.values if hasattr(C, 'values') else C
                                w_np = w_active.values
                                Cw = C_np @ w_np  # ê³µë¶„ì‚° í–‰ë ¬ * ê°€ì¤‘ì¹˜
                                portfolio_var = w_np @ Cw
                                te_annual = np.sqrt(portfolio_var * 252)

                                if te_annual > 0:
                                    mcte = Cw * np.sqrt(252) / te_annual  # Marginal contribution

                                    # Pair_IDë³„ TE ê¸°ì—¬ë„ ê³„ì‚° (filtered_stats ê¸°ë°˜)
                                    pair_te_contrib = {}
                                    for _, fs_row in filtered_stats.iterrows():
                                        pair_id = fs_row.get('Pair_ID', '')
                                        long_asset = str(fs_row.get('Long_Asset', ''))
                                        short_asset = str(fs_row.get('Short_Asset', ''))
                                        size_decimal = float(fs_row.get('Size', 0.0))
                                        pos_bp = abs(size_decimal)  # ì†Œìˆ˜ í˜•íƒœ
                                        pos_type = str(fs_row.get('Position_Type', 'Pair'))

                                        te_contrib = 0.0
                                        if pos_type == 'Single':
                                            # ë‹¨ì¼ í¬ì§€ì…˜
                                            if long_asset in cols:
                                                long_idx = cols.index(long_asset)
                                                te_contrib += pos_bp * abs(mcte[long_idx]) * 10000
                                            elif short_asset in cols and short_asset != 'Cash':
                                                short_idx = cols.index(short_asset)
                                                te_contrib += pos_bp * abs(mcte[short_idx]) * 10000
                                        else:
                                            # Pair í¬ì§€ì…˜
                                            if long_asset in cols:
                                                long_idx = cols.index(long_asset)
                                                te_contrib += pos_bp * abs(mcte[long_idx]) * 10000
                                            if short_asset in cols and short_asset != 'Cash':
                                                short_idx = cols.index(short_asset)
                                                te_contrib += pos_bp * abs(mcte[short_idx]) * 10000

                                        pair_te_contrib[pair_id] = te_contrib

                                    # filtered_statsì— TE ê¸°ì—¬ë„ ë§¤í•‘
                                    for idx, row in filtered_stats.iterrows():
                                        pair_id = row.get('Pair_ID', '')
                                        filtered_stats.at[idx, 'TE_bp'] = pair_te_contrib.get(pair_id, 0.0)

                                    # TE ê¸°ì—¬ë„ ë¹„ìœ¨ ê³„ì‚°
                                    total_te_contrib = filtered_stats['TE_bp'].sum()
                                    if total_te_contrib > 0:
                                        filtered_stats['TE_Contribution_Pct'] = (filtered_stats['TE_bp'] / total_te_contrib) * 100
                                        # ì´ TEì™€ ì¼ì¹˜í•˜ë„ë¡ ìŠ¤ì¼€ì¼ ì¡°ì •
                                        scale_factor = total_te_bp / total_te_contrib if total_te_contrib > 0 else 1.0
                                        filtered_stats['TE_bp'] = filtered_stats['TE_bp'] * scale_factor

                            # session stateì— ì €ì¥ (ë¦¬ìŠ¤í¬ ì‹œë®¬ë ˆì´ì…˜ ì„¹ì…˜ì—ì„œë„ ì‚¬ìš©)
                            st.session_state['current_portfolio_te_bp'] = total_te_bp
                            st.session_state['cov_matrix'] = C
                            st.session_state['asset_cols'] = cols

                    except Exception as e:
                        st.warning(f"TE ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        total_te_bp = 0.0

                    # ìš”ì•½ ì§€í‘œ
                    col_s1, col_s2, col_s3, col_s4, col_s5, col_s6 = st.columns(6)

                    with col_s1:
                        total_return_bp = filtered_stats['Total_Return_bp'].sum()
                        st.metric("ì´ ìˆ˜ìµë¥ ", f"{total_return_bp:.2f}bp")

                    with col_s2:
                        avg_sharpe = filtered_stats['Sharpe_Ratio'].mean()
                        st.metric("í‰ê·  Sharpe", f"{avg_sharpe:.2f}")

                    with col_s3:
                        avg_win_rate = filtered_stats['Win_Rate_%'].mean()
                        st.metric("í‰ê·  Win Rate", f"{avg_win_rate:.1f}%")

                    with col_s4:
                        st.metric("ì´ TE", f"{total_te_bp:.2f}bp")

                    with col_s5:
                        avg_holding = filtered_stats['Holding_Days'].mean()
                        st.metric("í‰ê·  ë³´ìœ ì¼", f"{avg_holding:.0f}ì¼")

                    with col_s6:
                        n_positions = len(filtered_stats)
                        st.metric("í¬ì§€ì…˜ ìˆ˜", f"{n_positions}ê°œ")

                    # ìƒì„¸ í…Œì´ë¸”
                    with st.expander("ğŸ“‹ í¬ì§€ì…˜ë³„ ìƒì„¸ í†µê³„ í…Œì´ë¸”", expanded=True):
                        # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ (Size_bp, TE_bpì™€ TE_Contribution_Pct ì¶”ê°€)
                        display_cols = [
                            'Pair_ID', 'Pair', 'Position_Type', 'Direction', 'Size_bp',
                            'Entry_Date', 'Exit_Date', 'Status', 'Holding_Days',
                            'Total_Return_bp', 'Avg_Daily_Return_bp', 'Annualized_Volatility',
                            'Sharpe_Ratio', 'Max_Drawdown', 'TE_bp', 'TE_Contribution_Pct',
                            'Win_Rate_%', 'Best_Day_bp', 'Worst_Day_bp'
                        ]
                        available_cols = [c for c in display_cols if c in filtered_stats.columns]

                        display_df = filtered_stats[available_cols].copy()

                        # í¬íŠ¸í´ë¦¬ì˜¤ ì´í•© í–‰ ì¶”ê°€
                        total_row = pd.DataFrame([{
                            'Pair_ID': 'í•©ê³„',
                            'Pair': 'í¬íŠ¸í´ë¦¬ì˜¤ ì´í•©',
                            'Position_Type': '-',
                            'Direction': '-',
                            'Size_bp': filtered_stats['Size_bp'].sum() if 'Size_bp' in filtered_stats.columns else 0,
                            'Entry_Date': '-',
                            'Exit_Date': '-',
                            'Status': '-',
                            'Holding_Days': filtered_stats['Holding_Days'].mean() if 'Holding_Days' in filtered_stats.columns else 0,
                            'Total_Return_bp': filtered_stats['Total_Return_bp'].sum() if 'Total_Return_bp' in filtered_stats.columns else 0,
                            'Avg_Daily_Return_bp': filtered_stats['Avg_Daily_Return_bp'].mean() if 'Avg_Daily_Return_bp' in filtered_stats.columns else 0,
                            'Annualized_Volatility': None,  # í•©ê³„ì—ì„œëŠ” í‘œì‹œ ì•ˆí•¨
                            'Sharpe_Ratio': filtered_stats['Sharpe_Ratio'].mean() if 'Sharpe_Ratio' in filtered_stats.columns else 0,
                            'Max_Drawdown': filtered_stats['Max_Drawdown'].sum() if 'Max_Drawdown' in filtered_stats.columns else 0,
                            'TE_bp': total_te_bp,
                            'TE_Contribution_Pct': 100.0,  # í•©ê³„ = 100%
                            'Win_Rate_%': filtered_stats['Win_Rate_%'].mean() if 'Win_Rate_%' in filtered_stats.columns else 0,
                            'Best_Day_bp': filtered_stats['Best_Day_bp'].max() if 'Best_Day_bp' in filtered_stats.columns else 0,
                            'Worst_Day_bp': filtered_stats['Worst_Day_bp'].min() if 'Worst_Day_bp' in filtered_stats.columns else 0,
                        }])

                        display_df = pd.concat([display_df, total_row], ignore_index=True)

                        # í¬ë§·íŒ…
                        format_cols = {
                            'Size_bp': lambda x: f"{x:.2f}" if isinstance(x, (int, float)) else x,
                            'Total_Return_bp': lambda x: f"{x:.2f}" if isinstance(x, (int, float)) else x,
                            'Avg_Daily_Return_bp': lambda x: f"{x:.3f}" if isinstance(x, (int, float)) else x,
                            'Annualized_Volatility': lambda x: f"{x:.2%}" if pd.notna(x) and isinstance(x, (int, float)) else "-",
                            'Sharpe_Ratio': lambda x: f"{x:.2f}" if isinstance(x, (int, float)) else x,
                            'Max_Drawdown': lambda x: f"{x:.4f}" if isinstance(x, (int, float)) else x,
                            'TE_bp': lambda x: f"{x:.2f}" if isinstance(x, (int, float)) else x,
                            'TE_Contribution_Pct': lambda x: f"{x:.1f}%" if isinstance(x, (int, float)) else x,
                            'Win_Rate_%': lambda x: f"{x:.1f}%" if isinstance(x, (int, float)) else x,
                            'Best_Day_bp': lambda x: f"{x:.2f}" if isinstance(x, (int, float)) else x,
                            'Worst_Day_bp': lambda x: f"{x:.2f}" if isinstance(x, (int, float)) else x,
                        }

                        for col, fmt in format_cols.items():
                            if col in display_df.columns:
                                display_df[col] = display_df[col].apply(fmt)

                        # ì»¬ëŸ¼ëª… í•œê¸€í™”
                        col_names = {
                            'Pair_ID': 'Pair ID',
                            'Pair': 'í˜ì–´/ìì‚°',
                            'Position_Type': 'ìœ í˜•',
                            'Direction': 'ë°©í–¥',
                            'Size_bp': 'ì‚¬ì´ì¦ˆ(bp)',
                            'Entry_Date': 'ì§„ì…ì¼',
                            'Exit_Date': 'ì²­ì‚°ì¼',
                            'Status': 'ìƒíƒœ',
                            'Holding_Days': 'ë³´ìœ ì¼',
                            'Total_Return_bp': 'ì´ìˆ˜ìµ(bp)',
                            'Avg_Daily_Return_bp': 'ì¼í‰ê· (bp)',
                            'Annualized_Volatility': 'ì—°ë³€ë™ì„±',
                            'Sharpe_Ratio': 'Sharpe',
                            'Max_Drawdown': 'MDD',
                            'TE_bp': 'TE(bp)',
                            'TE_Contribution_Pct': 'TEê¸°ì—¬(%)',
                            'Win_Rate_%': 'Win Rate',
                            'Best_Day_bp': 'ìµœê³ ì¼(bp)',
                            'Worst_Day_bp': 'ìµœì €ì¼(bp)',
                        }
                        display_df.rename(columns=col_names, inplace=True)

                        # ë§ˆì§€ë§‰ í–‰(ì´í•©) ìŠ¤íƒ€ì¼ ê°•ì¡°ë¥¼ ìœ„í•´ í‘œì‹œ
                        st.dataframe(display_df, use_container_width=True, hide_index=True)

                    # ìˆ˜ìµ ê¸°ì—¬ë„ ì°¨íŠ¸
                    st.markdown("#### ğŸ“ˆ í¬ì§€ì…˜ë³„ ìˆ˜ìµ ê¸°ì—¬ë„")

                    chart_df = filtered_stats[['Pair', 'Total_Return_bp']].copy()
                    chart_df = chart_df.sort_values('Total_Return_bp', ascending=True)

                    fig_contrib = go.Figure()
                    colors = ['#EF553B' if x < 0 else '#00CC96' for x in chart_df['Total_Return_bp']]

                    fig_contrib.add_trace(go.Bar(
                        y=chart_df['Pair'],
                        x=chart_df['Total_Return_bp'],
                        orientation='h',
                        marker_color=colors,
                        text=[f"{x:.2f}bp" for x in chart_df['Total_Return_bp']],
                        textposition='outside'
                    ))

                    fig_contrib.update_layout(
                        title="í¬ì§€ì…˜ë³„ ì´ ìˆ˜ìµ ê¸°ì—¬ë„ (bp)",
                        xaxis_title="ìˆ˜ìµë¥  (bp)",
                        yaxis_title="",
                        height=max(400, len(chart_df) * 30),
                        showlegend=False
                    )

                    st.plotly_chart(fig_contrib, use_container_width=True)

                    # TE ê¸°ì—¬ë„ íŒŒì´ ì°¨íŠ¸ (ìƒˆ TE_Contribution_Pct ì‚¬ìš©)
                    if 'TE_Contribution_Pct' in filtered_stats.columns and filtered_stats['TE_Contribution_Pct'].sum() > 0:
                        st.markdown("#### ğŸ¯ TE ê¸°ì—¬ë„ ë¶„í¬")

                        # ì´í•© í–‰ ì œì™¸ (filtered_statsì—ëŠ” ì•„ì§ ì¶”ê°€ ì•ˆë¨)
                        te_df = filtered_stats[filtered_stats['TE_Contribution_Pct'] > 0][['Pair', 'TE_bp', 'TE_Contribution_Pct']].copy()
                        if not te_df.empty:
                            fig_te = go.Figure(data=[go.Pie(
                                labels=te_df['Pair'],
                                values=te_df['TE_Contribution_Pct'],
                                hole=0.4,
                                textinfo='label+percent',
                                textposition='outside',
                                hovertemplate="<b>%{label}</b><br>TE: %{customdata:.2f}bp<br>ê¸°ì—¬ë„: %{percent}<extra></extra>",
                                customdata=te_df['TE_bp']
                            )])

                            fig_te.update_layout(
                                title=f"í¬ì§€ì…˜ë³„ TE ê¸°ì—¬ë„ (ì´ TE: {total_te_bp:.2f}bp)",
                                height=450
                            )

                            st.plotly_chart(fig_te, use_container_width=True)

                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    csv_stats = filtered_stats.to_csv(index=False).encode('utf-8-sig')
                    st.download_button(
                        label="ğŸ“¥ í¬ì§€ì…˜ í†µê³„ ë‹¤ìš´ë¡œë“œ (CSV)",
                        data=csv_stats,
                        file_name=f"position_statistics_{selected_start.strftime('%Y%m%d')}_{selected_end.strftime('%Y%m%d')}.csv",
                        mime="text/csv",
                        key="download_position_stats"
                    )

                else:
                    st.info("í¬ì§€ì…˜ í†µê³„ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ğŸ“ actual_portfolio_position_statistics.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. itaa_v5.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ìƒì„±í•´ì£¼ì„¸ìš”.")

        except Exception as e:
            st.error(f"í¬ì§€ì…˜ í†µê³„ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

        # =========================================================================
        # ìƒˆë¡œìš´ ì„¹ì…˜: ë¦¬ìŠ¤í¬ ì‹œë®¬ë ˆì´ì…˜ & P&L ë¶„í¬
        # =========================================================================
        st.markdown("---")
        st.subheader("ğŸ”¬ ë¦¬ìŠ¤í¬ ì‹œë®¬ë ˆì´ì…˜ & í¬ì§€ì…˜ ì¡°ì •")

        # ===== ì‹¤ì œ í¬ì§€ì…˜ ë°ì´í„°ì—ì„œ ìµœì‹  í¬ì§€ì…˜ ì¶”ì¶œ =====
        try:
            # ìµœì‹  ë‚ ì§œì˜ í¬ì§€ì…˜ ì¶”ì¶œ
            latest_date = actual_positions_df['Date'].max()
            latest_positions = actual_positions_df[actual_positions_df['Date'] == latest_date].copy()

            if not latest_positions.empty:
                # ì‹¤ì œ í¬ì§€ì…˜ ë°ì´í„°ë¥¼ common_positions í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                actual_common_positions = []

                for idx, row in latest_positions.iterrows():
                    pair_id = row.get('Pair_ID', f'P{idx:03d}')
                    pair_name = row.get('Pair', 'Unknown')

                    # Long/Short ìì‚° ì¶”ì¶œ: ì»¬ëŸ¼ ê°’ ìš°ì„ , ì—†ìœ¼ë©´ Pair ë¬¸ìì—´ íŒŒì‹±
                    long_asset = row.get('Long_Asset', None)
                    short_asset = row.get('Short_Asset', None)
                    long_asset = long_asset if isinstance(long_asset, str) and long_asset.strip() else None
                    short_asset = short_asset if isinstance(short_asset, str) and short_asset.strip() else None

                    if not long_asset:
                        if 'vs' in pair_name:
                            parts = pair_name.split(' vs ')
                            long_asset = parts[0].strip() if len(parts) > 0 else 'Unknown'
                            short_asset = parts[1].strip() if len(parts) > 1 else 'Unknown'
                        else:
                            long_asset = pair_name
                            short_asset = short_asset or 'Cash'
                    else:
                        # Long/Short ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ Cash ì²˜ë¦¬ë§Œ ë³´ì™„
                        if not short_asset:
                            short_asset = 'Cash'

                    # ì‹¤ì œ í¬ì§€ì…˜ í¬ê¸° (Size ë˜ëŠ” Position_PnL_bp ë“±ì—ì„œ ì—­ì‚°)
                    size = row.get('Size', 0.0)  # ì‹¤ì œ í¬ì§€ì…˜ í¬ê¸°
                    signal = 2 if size > 0 else (-2 if size < 0 else 0)  # í¬ê¸° ê¸°ë°˜ ì‹ í˜¸ ì¶”ì •

                    # Cash pair íŒë‹¨
                    is_cash = 'cash' in short_asset.lower() or 'tbill' in short_asset.lower()
                    leg_factor = 1 if is_cash else 2

                    # Sizeë¥¼ bpë¡œ ë³€í™˜ (Sizeê°€ ì†Œìˆ˜ í˜•íƒœë¼ê³  ê°€ì •)
                    per_leg_bp = abs(size) * 10000  # ì†Œìˆ˜ â†’ bp

                    actual_common_positions.append({
                        'Pair_ID': pair_id,
                        'Pair': pair_name,
                        'Long_Asset': long_asset,
                        'Short_Asset': short_asset,
                        'Signal': signal,
                        'Is_Cash_Pair': is_cash,
                        'Leg_Factor': leg_factor,
                        'Risk_Unit_3M_%': 5.0,  # ê¸°ë³¸ê°’ (ì‹¤ì œ ê³„ì‚° í•„ìš” ì‹œ ì¶”ê°€)
                        'Max_Loss_bp': 0.10,
                        'Per_Leg_Position_bp': per_leg_bp,
                        'Total_Notional_bp': per_leg_bp * leg_factor,
                        'Constraint_Method': 'Actual'
                    })

                common_positions = pd.DataFrame(actual_common_positions)

                st.info(f"ğŸ“… **ìµœê·¼ í¬ì§€ì…˜ ë‚ ì§œ**: {latest_date.strftime('%Y-%m-%d')} ({len(common_positions)}ê°œ í˜ì–´)")

            else:
                st.warning("ì‹¤ì œ í¬ì§€ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                common_positions = pd.DataFrame()

        except Exception as e:
            st.error(f"ì‹¤ì œ í¬ì§€ì…˜ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # Fallback: Session stateì˜ common_positions ì‚¬ìš©
            if 'common_positions' in st.session_state and st.session_state.common_positions is not None:
                common_positions = st.session_state.common_positions
                st.warning("âš ï¸ ì‹¤ì œ í¬ì§€ì…˜ ë¡œë“œ ì‹¤íŒ¨. Asset View íƒ­ì˜ ì´ë¡ ì  í¬ì§€ì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                common_positions = pd.DataFrame()

        if not common_positions.empty:
            # ===== í˜„ì¬ í¬ì§€ì…˜ ì •ë³´ í…Œì´ë¸” =====
            st.markdown("### ğŸ“‹ í˜„ì¬ í¬ì§€ì…˜ í˜„í™©")

            # í˜„ì¬ í¬ì§€ì…˜ í…Œì´ë¸” ìƒì„±
            current_pos_display = common_positions[[
                'Pair_ID', 'Pair', 'Long_Asset', 'Short_Asset', 'Signal',
                'Leg_Factor', 'Per_Leg_Position_bp', 'Total_Notional_bp',
                'Risk_Unit_3M_%', 'Max_Loss_bp'
            ]].copy()

            # ì»¬ëŸ¼ëª… í•œê¸€í™”
            current_pos_display.columns = [
                'Pair ID', 'í˜ì–´', 'Long ìì‚°', 'Short ìì‚°', 'Signal',
                'Leg Factor', 'ë ˆê·¸ë‹¹ í¬ì§€ì…˜ (bp)', 'ì´ ëª…ëª© (bp)',
                'Risk Unit 3M (%)', 'ìµœëŒ€ì†ì‹¤ (bp)'
            ]

            # ìˆ«ì í¬ë§·íŒ…
            current_pos_display['ë ˆê·¸ë‹¹ í¬ì§€ì…˜ (bp)'] = current_pos_display['ë ˆê·¸ë‹¹ í¬ì§€ì…˜ (bp)'].apply(lambda x: f"{x:.3f}")
            current_pos_display['ì´ ëª…ëª© (bp)'] = current_pos_display['ì´ ëª…ëª© (bp)'].apply(lambda x: f"{x:.3f}")
            current_pos_display['Risk Unit 3M (%)'] = current_pos_display['Risk Unit 3M (%)'].apply(lambda x: f"{x:.2f}")
            current_pos_display['ìµœëŒ€ì†ì‹¤ (bp)'] = current_pos_display['ìµœëŒ€ì†ì‹¤ (bp)'].apply(lambda x: f"{x:.2f}")

            st.dataframe(current_pos_display, use_container_width=True, hide_index=True)

            # ìš”ì•½ í†µê³„
            col_sum1, col_sum2, col_sum3, col_sum4 = st.columns(4)
            with col_sum1:
                total_notional = common_positions['Total_Notional_bp'].abs().sum()
                st.metric("ì´ ëª…ëª© í¬ì§€ì…˜", f"{total_notional:.2f}bp")
            with col_sum2:
                avg_position = common_positions['Per_Leg_Position_bp'].abs().mean()
                st.metric("í‰ê·  ë ˆê·¸ë‹¹ í¬ì§€ì…˜", f"{avg_position:.3f}bp")
            with col_sum3:
                n_pairs = len(common_positions)
                st.metric("í™œì„± í˜ì–´ ìˆ˜", f"{n_pairs}ê°œ")
            with col_sum4:
                avg_signal = common_positions['Signal'].abs().mean()
                st.metric("í‰ê·  Signal ê°•ë„", f"{avg_signal:.1f}")

            st.markdown("---")

            # ===== 1. í¬ì§€ì…˜ í¬ê¸° ì¡°ì • UI =====
            st.markdown("### ğŸ“Š 1. í¬ì§€ì…˜ í¬ê¸° ì¡°ì • â†’ ë¦¬ìŠ¤í¬ ë³€í™”")
            st.caption("ê¸°ì¡´ í¬ì§€ì…˜ ë³€ê²½ ë° ìœ ë‹ˆë²„ìŠ¤ ë‚´ ëª¨ë“  ìì‚°ì˜ Long/Short ì¶”ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

            # Session state ì´ˆê¸°í™”
            if 'adjusted_positions_tab11' not in st.session_state:
                st.session_state.adjusted_positions_tab11 = {}
            if 'position_types_tab11' not in st.session_state:
                st.session_state.position_types_tab11 = {}
            if 'new_positions_tab11' not in st.session_state:
                st.session_state.new_positions_tab11 = []

            # ì¡°ì •ëœ í¬ì§€ì…˜ ì €ì¥
            adjusted_sizes = {}
            position_types = {}

            # ===== ê¸°ì¡´ í¬ì§€ì…˜ ì¡°ì • =====
            st.markdown("#### ğŸšï¸ ê¸°ì¡´ í¬ì§€ì…˜ ì¡°ì •")
            st.caption("ğŸ’¡ í¬ì§€ì…˜ íƒ€ì…ê³¼ í¬ê¸°ë¥¼ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            for idx, row in common_positions.iterrows():
                pair_id = row['Pair_ID']
                pair_name = row['Pair']
                current_size = float(row['Per_Leg_Position_bp'])
                signal = float(row['Signal'])
                long_asset = row['Long_Asset']
                short_asset = row['Short_Asset']

                # ìŠ¬ë¼ì´ë” ë²”ìœ„ ì„¤ì • (í˜„ì¬ í¬ê¸°ì˜ Â±200%)
                abs_current = abs(current_size)
                max_size = max(abs_current * 3, 5.0)  # ìµœì†Œ 5bp

                with st.expander(f"**{pair_name}** (Signal: {signal:.0f})", expanded=(idx < 3)):
                    col1, col2, col3 = st.columns([2, 2, 1])

                    with col1:
                        # í¬ì§€ì…˜ íƒ€ì… ì„ íƒ - 5ê°€ì§€ ì˜µì…˜
                        pos_type_options = [
                            "Pair (L/S)",
                            f"Long: {long_asset}",
                            f"Long: {short_asset}",
                            f"Short: {long_asset}",
                            f"Short: {short_asset}"
                        ]
                        pos_type = st.selectbox(
                            "í¬ì§€ì…˜ íƒ€ì…",
                            pos_type_options,
                            index=0,
                            key=f"pos_type_{pair_id}_tab11",
                            help="Pair: Long/Short ë™ì‹œ í¬ì§€ì…˜\nê°œë³„ ìì‚°ë³„ Long ë˜ëŠ” Short ì„ íƒ ê°€ëŠ¥"
                        )

                        # í¬ì§€ì…˜ íƒ€ì… ë¶„ë¥˜ (ìì‚°ëª…ê³¼ ë°©í–¥ ì €ì¥)
                        if pos_type == "Pair (L/S)":
                            position_types[pair_id] = {'type': 'pair', 'asset': None, 'direction': None}
                        elif pos_type == f"Long: {long_asset}":
                            position_types[pair_id] = {'type': 'single', 'asset': long_asset, 'direction': 'long'}
                        elif pos_type == f"Long: {short_asset}":
                            position_types[pair_id] = {'type': 'single', 'asset': short_asset, 'direction': 'long'}
                        elif pos_type == f"Short: {long_asset}":
                            position_types[pair_id] = {'type': 'single', 'asset': long_asset, 'direction': 'short'}
                        elif pos_type == f"Short: {short_asset}":
                            position_types[pair_id] = {'type': 'single', 'asset': short_asset, 'direction': 'short'}

                    with col2:
                        # í¬ì§€ì…˜ í¬ê¸° ì…ë ¥
                        new_size = st.number_input(
                            f"í¬ì§€ì…˜ (bp)",
                            min_value=-max_size,
                            max_value=max_size,
                            value=float(current_size),
                            step=0.01,
                            key=f"pos_size_{pair_id}_tab11",
                            label_visibility="collapsed"
                        )
                        adjusted_sizes[pair_id] = new_size

                    with col3:
                        change_pct = ((new_size - current_size) / current_size * 100) if current_size != 0 else 0
                        if abs(change_pct) > 0.1:
                            color = "ğŸŸ¢" if change_pct > 0 else "ğŸ”´"
                            st.markdown(f"{color} {change_pct:+.1f}%")
                        else:
                            st.markdown("â–")

                    # í¬ì§€ì…˜ íƒ€ì…ë³„ ì„¤ëª…
                    pos_info = position_types[pair_id]
                    if pos_info['type'] == 'pair':
                        st.info(f"âš–ï¸ **Pair**: {long_asset} ë§¤ìˆ˜ + {short_asset} ë§¤ë„ ê° {abs(new_size):.2f}bp")
                    else:
                        asset_name = pos_info['asset']
                        direction = pos_info['direction']
                        if direction == 'long':
                            st.info(f"ğŸ“ˆ **Long**: {asset_name} {abs(new_size):.2f}bp ë§¤ìˆ˜")
                        else:
                            st.info(f"ğŸ“‰ **Short**: {asset_name} {abs(new_size):.2f}bp ë§¤ë„")

            # ===== ìƒˆ í¬ì§€ì…˜ ì¶”ê°€ UI =====
            st.markdown("---")
            st.markdown("#### â• ìƒˆ í¬ì§€ì…˜ ì¶”ê°€")
            st.caption("ìœ ë‹ˆë²„ìŠ¤ ë‚´ ëª¨ë“  ìì‚°ì˜ Long ë˜ëŠ” Short í¬ì§€ì…˜ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            # ìœ ë‹ˆë²„ìŠ¤ ë‚´ ëª¨ë“  ìì‚° ë¦¬ìŠ¤íŠ¸ ìƒì„±
            if not returns_by_asset.empty:
                all_assets = sorted(returns_by_asset.columns.tolist())

                col_add1, col_add2, col_add3, col_add4 = st.columns([2, 1, 1, 1])

                with col_add1:
                    selected_asset = st.selectbox(
                        "ìì‚° ì„ íƒ",
                        all_assets,
                        key="new_asset_select_tab11"
                    )

                with col_add2:
                    new_direction = st.selectbox(
                        "ë°©í–¥",
                        ["Long", "Short"],
                        key="new_direction_tab11"
                    )

                with col_add3:
                    new_position_size = st.number_input(
                        "í¬ì§€ì…˜ í¬ê¸° (bp)",
                        min_value=0.0,
                        max_value=100.0,
                        value=1.0,
                        step=0.1,
                        key="new_position_size_tab11"
                    )

                with col_add4:
                    if st.button("â• ì¶”ê°€", key="add_position_btn_tab11"):
                        new_pos = {
                            'id': f"NEW_{len(st.session_state.new_positions_tab11):03d}",
                            'asset': selected_asset,
                            'direction': new_direction.lower(),
                            'size_bp': new_position_size
                        }
                        st.session_state.new_positions_tab11.append(new_pos)
                        st.success(f"âœ… {new_direction}: {selected_asset} ({new_position_size:.2f}bp) ì¶”ê°€ë¨")

                # ì¶”ê°€ëœ ìƒˆ í¬ì§€ì…˜ í‘œì‹œ
                if st.session_state.new_positions_tab11:
                    st.markdown("**ì¶”ê°€ëœ í¬ì§€ì…˜:**")
                    for i, pos in enumerate(st.session_state.new_positions_tab11):
                        col_p1, col_p2 = st.columns([4, 1])
                        with col_p1:
                            icon = "ğŸ“ˆ" if pos['direction'] == 'long' else "ğŸ“‰"
                            st.markdown(f"{icon} **{pos['direction'].capitalize()}: {pos['asset']}** - {pos['size_bp']:.2f}bp")
                        with col_p2:
                            if st.button("âŒ", key=f"remove_new_pos_{i}_tab11"):
                                st.session_state.new_positions_tab11.pop(i)
                                st.rerun()

            # Session state ì €ì¥
            st.session_state.adjusted_positions_tab11 = adjusted_sizes
            st.session_state.position_types_tab11 = position_types

            # ===== ë¦¬ìŠ¤í¬ ë³€í™” ê³„ì‚° ë° í‘œì‹œ =====
            st.markdown("---")
            st.markdown("#### ğŸ“ˆ ì˜ˆìƒ ë¦¬ìŠ¤í¬ ë³€í™” (TE ê¸°ì¤€)")

            # ë¦¬ìŠ¤í¬ ê³„ì‚°ì„ ìœ„í•œ ì¤€ë¹„
            if not returns_by_asset.empty and not w_opt_daily.empty and not w_bmk_daily.empty:
                # ìµœì‹  ê°€ì¤‘ì¹˜
                asof = min(w_opt_daily.index.max(), w_bmk_daily.index.max())
                Wopt_last = w_opt_daily.loc[asof].fillna(0.0)
                Wbmk_last = w_bmk_daily.loc[asof].fillna(0.0)

                # ê³µë¶„ì‚° í–‰ë ¬
                cols = [c for c in returns_by_asset.columns if c in Wopt_last.index]
                R = returns_by_asset[cols]
                R_dec = _pc_ensure_decimal_returns(R)
                C = _pc_build_recent_cov_constant_corr(R_dec, window=63, rho=0.25)

                w_b = Wbmk_last.reindex(cols).fillna(0.0)

                # í˜„ì¬ í¬ì§€ì…˜ì˜ active weights ê³„ì‚°
                w_active_current = pd.Series(0.0, index=cols)
                for i, row in enumerate(common_positions.itertuples()):
                    long_asset = str(row.Long_Asset)
                    short_asset = str(row.Short_Asset)
                    pos_bp = row.Per_Leg_Position_bp / 10000.0  # bp â†’ ì†Œìˆ˜

                    # Pair ê¸°ì¤€ (í˜„ì¬ í¬ì§€ì…˜ì€ í•­ìƒ Pairë¡œ ê³„ì‚°)
                    if long_asset in w_active_current.index:
                        w_active_current[long_asset] += pos_bp
                    if short_asset in w_active_current.index:
                        w_active_current[short_asset] -= pos_bp

                # í˜„ì¬ TE ê³„ì‚°
                current_te_bp = _pc_te_bp_from_cov(w_active_current.values, C, 252)

                # ì¡°ì •ëœ í¬ì§€ì…˜ì˜ active weights ê³„ì‚°
                w_active_adj = pd.Series(0.0, index=cols)

                # 1) ê¸°ì¡´ í¬ì§€ì…˜ (ì¡°ì • ë°˜ì˜)
                for i, row in enumerate(common_positions.itertuples()):
                    pid = row.Pair_ID
                    long_asset = str(row.Long_Asset)
                    short_asset = str(row.Short_Asset)

                    if pid in adjusted_sizes:
                        pos_bp = adjusted_sizes[pid] / 10000.0  # bp â†’ ì†Œìˆ˜
                    else:
                        pos_bp = row.Per_Leg_Position_bp / 10000.0

                    # í¬ì§€ì…˜ íƒ€ì…ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì ìš©
                    pos_info = position_types.get(pid, {'type': 'pair', 'asset': None, 'direction': None})

                    if pos_info['type'] == 'single':
                        # ë‹¨ì¼ ìì‚° í¬ì§€ì…˜
                        target_asset = pos_info['asset']
                        direction = pos_info['direction']
                        if target_asset in w_active_adj.index:
                            if direction == 'long':
                                w_active_adj[target_asset] += pos_bp
                            else:  # short
                                w_active_adj[target_asset] -= pos_bp
                    else:
                        # Pair: Long ë§¤ìˆ˜ + Short ë§¤ë„
                        if long_asset in w_active_adj.index:
                            w_active_adj[long_asset] += pos_bp
                        if short_asset in w_active_adj.index:
                            w_active_adj[short_asset] -= pos_bp

                # 2) ìƒˆ í¬ì§€ì…˜ ì¶”ê°€
                for new_pos in st.session_state.new_positions_tab11:
                    asset = new_pos['asset']
                    direction = new_pos['direction']
                    size_bp = new_pos['size_bp'] / 10000.0  # bp â†’ ì†Œìˆ˜

                    if asset in w_active_adj.index:
                        if direction == 'long':
                            w_active_adj[asset] += size_bp
                        else:  # short
                            w_active_adj[asset] -= size_bp

                # ì¡°ì • í›„ TE ê³„ì‚°
                adj_te_bp = _pc_te_bp_from_cov(w_active_adj.values, C, 252)

                # ë©”íŠ¸ë¦­ í‘œì‹œ
                col_te1, col_te2, col_te3 = st.columns(3)

                with col_te1:
                    st.metric("í˜„ì¬ TE", f"{current_te_bp:.2f}bp")

                with col_te2:
                    delta_te = adj_te_bp - current_te_bp
                    st.metric("ì¡°ì • í›„ TE", f"{adj_te_bp:.2f}bp", delta=f"{delta_te:+.2f}bp")

                with col_te3:
                    te_change_pct = (delta_te/current_te_bp*100) if current_te_bp > 0 else 0
                    st.metric("TE ë³€í™”ìœ¨", f"{te_change_pct:.1f}%")

                # í˜„ì¬ TEë¥¼ session stateì— ì €ì¥ (í¬ì§€ì…˜ë³„ ìƒì„¸ í†µê³„ì—ì„œ ì‚¬ìš©)
                st.session_state['current_portfolio_te_bp'] = current_te_bp
            else:
                st.warning("ë¦¬ìŠ¤í¬ ê³„ì‚°ì— í•„ìš”í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                current_te_bp = 0.0
                st.session_state['current_portfolio_te_bp'] = 0.0

            # ===== 2. ëª©í‘œ ë¦¬ìŠ¤í¬ â†’ í¬ì§€ì…˜ ì—­ì‚° =====
            st.markdown("---")
            st.markdown("### ğŸ¯ 2. ëª©í‘œ ë¦¬ìŠ¤í¬ ë³€í™” â†’ í¬ì§€ì…˜ í¬ê¸° ì—­ì‚°")
            st.caption("ì›í•˜ëŠ” ë¦¬ìŠ¤í¬ ë³€í™”ëŸ‰ì„ ì…ë ¥í•˜ë©´ ì„ íƒí•œ í˜ì–´ì˜ í¬ì§€ì…˜ í¬ê¸°ë¥¼ ìë™ ê³„ì‚°í•©ë‹ˆë‹¤.")

            col_target1, col_target2 = st.columns(2)

            with col_target1:
                # í˜ì–´ ì„ íƒ
                pair_options = common_positions['Pair'].tolist()
                selected_pair_for_calc = st.selectbox(
                    "ì¡°ì •í•  í˜ì–´ ì„ íƒ",
                    pair_options,
                    key="selected_pair_risk_calc"
                )

                # ì„ íƒëœ í˜ì–´ì˜ í˜„ì¬ ì •ë³´
                selected_row = common_positions[common_positions['Pair'] == selected_pair_for_calc].iloc[0]
                current_pos_bp_calc = float(selected_row['Per_Leg_Position_bp'])
                risk_unit = float(selected_row['Risk_Unit_3M_%']) / 100.0
                leg_factor_calc = int(selected_row['Leg_Factor'])

                st.info(f"í˜„ì¬ í¬ì§€ì…˜: {current_pos_bp_calc:.3f}bp | Risk Unit: {risk_unit*100:.2f}%")

            with col_target2:
                # ëª©í‘œ ë¦¬ìŠ¤í¬ ë³€í™” ì…ë ¥
                target_risk_change = st.number_input(
                    "ëª©í‘œ ë¦¬ìŠ¤í¬ ë³€í™”ëŸ‰ (bp)",
                    min_value=-10.0,
                    max_value=10.0,
                    value=0.0,
                    step=0.01,
                    key="target_risk_change"
                )

                if target_risk_change != 0 and risk_unit > 0:
                    # í¬ì§€ì…˜ ë³€í™”ëŸ‰ ê³„ì‚°
                    # Risk = Position Ã— Risk_Unit Ã— Leg_Factor
                    # Î”Risk = Î”Position Ã— Risk_Unit Ã— Leg_Factor
                    # Î”Position = Î”Risk / (Risk_Unit Ã— Leg_Factor)

                    delta_pos_bp = target_risk_change / (risk_unit * leg_factor_calc)
                    new_pos_bp_calc = current_pos_bp_calc + delta_pos_bp

                    st.success(f"ğŸ“Œ ê³„ì‚°ëœ í¬ì§€ì…˜ ë³€í™”:")
                    st.markdown(f"- **í¬ì§€ì…˜ ë³€í™”ëŸ‰**: {delta_pos_bp:+.3f}bp")
                    st.markdown(f"- **ìƒˆ í¬ì§€ì…˜ í¬ê¸°**: {new_pos_bp_calc:.3f}bp")
                    st.markdown(f"- **ë³€í™”ìœ¨**: {(delta_pos_bp/current_pos_bp_calc*100) if current_pos_bp_calc != 0 else 0:+.1f}%")
                elif risk_unit == 0:
                    st.warning("Risk Unitì´ 0ì…ë‹ˆë‹¤. ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # ===== 3. ì†ìµ ë¶„í¬ ê·¸ë˜í”„ (std ì‹œë‚˜ë¦¬ì˜¤) =====
            st.markdown("---")
            st.markdown("### ğŸ“ˆ 3. ì†ìµ ë¶„í¬ ê·¸ë˜í”„ (-3Ïƒ ~ +3Ïƒ)")
            st.caption("í˜„ì¬ í¬ì§€ì…˜ê³¼ ì¡°ì •ëœ í¬ì§€ì…˜ì˜ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜ˆìƒ ì†ìµì„ ë¹„êµí•©ë‹ˆë‹¤.")

            st.markdown("""
            **ê³„ì‚° ê¸°ì¤€:**
            - **ê¸°ì¤€ ìˆ˜ìµë¥ **: ê° ìì‚°/í˜ì–´ì˜ 3ê°œì›” ë¡¤ë§ ìˆ˜ìµë¥  ë¶„í¬ (mean Â± nÃ—std)
            - **í˜„ì¬ P&L**: (í˜„ì¬ í¬ì§€ì…˜ bp) Ã— (ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ìµë¥ ) Ã— (Pairì˜ leg_factor)
            - **ì¡°ì • P&L**: (ì¡°ì • í¬ì§€ì…˜ bp) Ã— (ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ìµë¥ ) Ã— (í¬ì§€ì…˜ íƒ€ì…ë³„ leg_factor)
              - Pair: leg_factor (2 ë˜ëŠ” 1)
              - ë‹¨ì¼ ìì‚° Long/Short: 1
            - **ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ P&L**: ê° í˜ì–´ë³„ P&Lì˜ ë‹¨ìˆœ í•©ê³„ (ìƒê´€ê´€ê³„ ë¯¸ë°˜ì˜)
            """)

            # ê° í˜ì–´ë³„ 3M ë¡¤ë§ ë¦¬í„´ í†µê³„ ê³„ì‚°
            scenario_data = []
            std_levels = [-3, -2, -1, 0, 1, 2, 3]

            for idx, row in common_positions.iterrows():
                pair_id = row['Pair_ID']
                long_asset = row['Long_Asset']
                short_asset = row['Short_Asset']
                signal = float(row['Signal'])
                current_pos = float(row['Per_Leg_Position_bp']) / 10000.0  # bp â†’ ì†Œìˆ˜
                adj_pos = adjusted_sizes.get(pair_id, row['Per_Leg_Position_bp']) / 10000.0
                leg_factor = int(row['Leg_Factor'])

                # í¬ì§€ì…˜ íƒ€ì… ê°€ì ¸ì˜¤ê¸°
                pos_info = position_types.get(pair_id, {'type': 'pair', 'asset': None, 'direction': None})

                # í¬ì§€ì…˜ íƒ€ì…ì— ë”°ë¥¸ ìˆ˜ìµë¥  ê³„ì‚°
                if pos_info['type'] == 'single':
                    # ë‹¨ì¼ ìì‚° í¬ì§€ì…˜
                    target_asset = pos_info['asset']
                    direction = pos_info['direction']

                    if target_asset in returns_by_asset.columns:
                        asset_returns = returns_by_asset[target_asset].dropna()
                        # Shortì¸ ê²½ìš° ìŒìˆ˜ë¡œ ë³€í™˜ (ë§¤ë„ í¬ì§€ì…˜ì˜ ìˆ˜ìµ)
                        if direction == 'short':
                            asset_returns = -asset_returns
                        rolling_3m = asset_returns.rolling(window=63).sum().dropna()
                        if not rolling_3m.empty and len(rolling_3m) >= 20:
                            mean_ret = rolling_3m.mean()
                            std_ret = rolling_3m.std()
                            effective_leg_factor = 1  # ë‹¨ì¼ ìì‚° = 1 leg
                            pos_type_label = f"{direction.capitalize()}: {target_asset}"
                        else:
                            continue
                    else:
                        continue
                else:
                    # Pair: ê¸°ì¡´ ë°©ì‹ (Long - Short)
                    pair_3m_returns = calculate_pair_3m_rolling_returns(
                        returns_by_asset, long_asset, short_asset, signal,
                        lookback_years=3, rolling_window=63
                    )

                    if not pair_3m_returns.empty and len(pair_3m_returns) >= 20:
                        mean_ret = pair_3m_returns.mean()
                        std_ret = pair_3m_returns.std()
                        effective_leg_factor = leg_factor
                        pos_type_label = 'Pair'
                    else:
                        continue

                for std_level in std_levels:
                    scenario_return = mean_ret + std_level * std_ret

                    # í˜„ì¬ í¬ì§€ì…˜ ì†ìµ (ê¸°ì¡´: Pair ê¸°ì¤€ leg_factor ì‚¬ìš©)
                    current_pnl = current_pos * scenario_return * leg_factor * 10000  # bp
                    # ì¡°ì • í¬ì§€ì…˜ ì†ìµ (í¬ì§€ì…˜ íƒ€ì…ì— ë”°ë¥¸ effective_leg_factor ì‚¬ìš©)
                    adj_pnl = adj_pos * scenario_return * effective_leg_factor * 10000  # bp

                    scenario_data.append({
                        'Pair': row['Pair'],
                        'Position_Type': pos_type_label,
                        'Scenario': f"{std_level}Ïƒ" if std_level != 0 else "Mean",
                        'Std_Level': std_level,
                        'Current_PnL_bp': current_pnl,
                        'Adjusted_PnL_bp': adj_pnl,
                        'Delta_PnL_bp': adj_pnl - current_pnl
                    })

            # ìƒˆ í¬ì§€ì…˜ì˜ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ë„ ì¶”ê°€
            new_position_scenario_data = []
            for new_pos in st.session_state.new_positions_tab11:
                asset = new_pos['asset']
                direction = new_pos['direction']
                size_bp = new_pos['size_bp'] / 10000.0  # bp â†’ ì†Œìˆ˜

                if asset in returns_by_asset.columns:
                    asset_returns = returns_by_asset[asset].dropna()
                    if direction == 'short':
                        asset_returns = -asset_returns
                    rolling_3m = asset_returns.rolling(window=63).sum().dropna()
                    if not rolling_3m.empty and len(rolling_3m) >= 20:
                        mean_ret = rolling_3m.mean()
                        std_ret = rolling_3m.std()

                        for std_level in std_levels:
                            scenario_return = mean_ret + std_level * std_ret
                            new_pnl = size_bp * scenario_return * 10000  # bp

                            new_position_scenario_data.append({
                                'Pair': f"[NEW] {direction.capitalize()}: {asset}",
                                'Position_Type': f"{direction.capitalize()}: {asset}",
                                'Scenario': f"{std_level}Ïƒ" if std_level != 0 else "Mean",
                                'Std_Level': std_level,
                                'Current_PnL_bp': 0.0,  # ìƒˆ í¬ì§€ì…˜ì€ í˜„ì¬ 0
                                'Adjusted_PnL_bp': new_pnl,
                                'Delta_PnL_bp': new_pnl,
                                'Is_New': True
                            })

            # ê¸°ì¡´ ë°ì´í„°ì— Is_New í”Œë˜ê·¸ ì¶”ê°€
            for item in scenario_data:
                item['Is_New'] = False

            # í•©ì¹˜ê¸°
            all_scenario_data = scenario_data + new_position_scenario_data

            if all_scenario_data:
                scenario_df = pd.DataFrame(all_scenario_data)

                # í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ì†ìµ í•©ê³„
                portfolio_pnl = scenario_df.groupby('Scenario').agg({
                    'Current_PnL_bp': 'sum',
                    'Adjusted_PnL_bp': 'sum',
                    'Std_Level': 'first'
                }).reset_index().sort_values('Std_Level')

                # ìƒˆ í¬ì§€ì…˜ë§Œì˜ ê¸°ì—¬ë„ ê³„ì‚°
                new_pos_pnl = scenario_df[scenario_df['Is_New'] == True].groupby('Scenario').agg({
                    'Adjusted_PnL_bp': 'sum',
                    'Std_Level': 'first'
                }).reset_index().sort_values('Std_Level')
                new_pos_pnl.rename(columns={'Adjusted_PnL_bp': 'New_Position_PnL_bp'}, inplace=True)

                # ë³‘í•©
                if not new_pos_pnl.empty:
                    portfolio_pnl = portfolio_pnl.merge(new_pos_pnl[['Scenario', 'New_Position_PnL_bp']], on='Scenario', how='left')
                    portfolio_pnl['New_Position_PnL_bp'] = portfolio_pnl['New_Position_PnL_bp'].fillna(0)
                else:
                    portfolio_pnl['New_Position_PnL_bp'] = 0

                # ê·¸ë˜í”„ 1: ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ì†ìµ ë¶„í¬
                fig_pnl = go.Figure()

                # í˜„ì¬ AP í¬ì§€ì…˜ P&L (ê¸°ì¡´)
                fig_pnl.add_trace(go.Bar(
                    name='ê¸°ì¡´ AP í¬ì§€ì…˜',
                    x=portfolio_pnl['Scenario'],
                    y=portfolio_pnl['Current_PnL_bp'],
                    marker_color='rgba(55, 128, 191, 0.8)',
                    text=portfolio_pnl['Current_PnL_bp'].apply(lambda x: f"{x:.2f}"),
                    textposition='outside'
                ))

                # ì¡°ì • í›„ ì „ì²´ P&L
                fig_pnl.add_trace(go.Bar(
                    name='ì¡°ì • í›„ ì „ì²´',
                    x=portfolio_pnl['Scenario'],
                    y=portfolio_pnl['Adjusted_PnL_bp'],
                    marker_color='rgba(219, 64, 82, 0.8)',
                    text=portfolio_pnl['Adjusted_PnL_bp'].apply(lambda x: f"{x:.2f}"),
                    textposition='outside'
                ))

                fig_pnl.update_layout(
                    title="ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ì†ìµ ë¶„í¬: ê¸°ì¡´ AP vs ì¡°ì • í›„",
                    xaxis_title="ì‹œë‚˜ë¦¬ì˜¤ (Ïƒ)",
                    yaxis_title="ì˜ˆìƒ ì†ìµ (bp)",
                    barmode='group',
                    height=500,
                    showlegend=True,
                    legend=dict(x=0.02, y=0.98)
                )

                fig_pnl.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
                fig_pnl = apply_chart_font_settings(fig_pnl)

                st.plotly_chart(fig_pnl, use_container_width=True)

                # ìƒˆ í¬ì§€ì…˜ì´ ìˆìœ¼ë©´ ì˜í–¥ ë¶„ì„ ê·¸ë˜í”„ ì¶”ê°€
                if st.session_state.new_positions_tab11 and portfolio_pnl['New_Position_PnL_bp'].abs().sum() > 0:
                    st.markdown("#### ğŸ†• ìƒˆ í¬ì§€ì…˜ ì¶”ê°€ ì˜í–¥ ë¶„ì„")

                    # ìŠ¤íƒ ë°” ì°¨íŠ¸: ê¸°ì¡´ AP + ìƒˆ í¬ì§€ì…˜ = ì¡°ì • í›„
                    fig_stack = go.Figure()

                    # ê¸°ì¡´ AP ì¡°ì • (ìƒˆ í¬ì§€ì…˜ ì œì™¸)
                    existing_adjusted = portfolio_pnl['Adjusted_PnL_bp'] - portfolio_pnl['New_Position_PnL_bp']

                    fig_stack.add_trace(go.Bar(
                        name='ê¸°ì¡´ AP (ì¡°ì •)',
                        x=portfolio_pnl['Scenario'],
                        y=existing_adjusted,
                        marker_color='rgba(55, 128, 191, 0.8)',
                    ))

                    fig_stack.add_trace(go.Bar(
                        name='ìƒˆ í¬ì§€ì…˜ ê¸°ì—¬',
                        x=portfolio_pnl['Scenario'],
                        y=portfolio_pnl['New_Position_PnL_bp'],
                        marker_color='rgba(0, 204, 150, 0.8)',
                    ))

                    fig_stack.update_layout(
                        title="ì†ìµ êµ¬ì„±: ê¸°ì¡´ AP ì¡°ì • + ìƒˆ í¬ì§€ì…˜ ì¶”ê°€",
                        xaxis_title="ì‹œë‚˜ë¦¬ì˜¤ (Ïƒ)",
                        yaxis_title="ì˜ˆìƒ ì†ìµ (bp)",
                        barmode='stack',
                        height=450,
                        showlegend=True,
                        legend=dict(x=0.02, y=0.98)
                    )

                    fig_stack.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1)
                    fig_stack = apply_chart_font_settings(fig_stack)

                    st.plotly_chart(fig_stack, use_container_width=True)

                # ì‹œë‚˜ë¦¬ì˜¤ë³„ ìƒì„¸ í…Œì´ë¸”
                with st.expander("ğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì†ìµ ìƒì„¸ í…Œì´ë¸”", expanded=False):
                    pnl_table = portfolio_pnl.copy()
                    pnl_table['ë³€í™”ëŸ‰ (bp)'] = pnl_table['Adjusted_PnL_bp'] - pnl_table['Current_PnL_bp']

                    display_pnl = pnl_table[['Scenario', 'Current_PnL_bp', 'Adjusted_PnL_bp', 'New_Position_PnL_bp', 'ë³€í™”ëŸ‰ (bp)']].copy()
                    display_pnl.columns = ['ì‹œë‚˜ë¦¬ì˜¤', 'ê¸°ì¡´ AP (bp)', 'ì¡°ì • í›„ (bp)', 'ìƒˆ í¬ì§€ì…˜ (bp)', 'ë³€í™”ëŸ‰ (bp)']

                    # í¬ë§·íŒ…
                    for col in ['ê¸°ì¡´ AP (bp)', 'ì¡°ì • í›„ (bp)', 'ìƒˆ í¬ì§€ì…˜ (bp)', 'ë³€í™”ëŸ‰ (bp)']:
                        display_pnl[col] = display_pnl[col].apply(lambda x: f"{x:+.2f}" if x != 0 else "0.00")

                    st.dataframe(display_pnl, use_container_width=True, hide_index=True)

                # ===== í¬ì§€ì…˜ ì •ë³´ ë° ë¦¬ìŠ¤í¬ ë¹„êµ í…Œì´ë¸” =====
                st.markdown("---")
                st.markdown("#### ğŸ“Š í¬ì§€ì…˜ ì •ë³´ ë° ë¦¬ìŠ¤í¬ ë¹„êµ")

                # í¬ì§€ì…˜ ë¹„êµ ë°ì´í„° ìƒì„±
                position_comparison = []

                # ê¸°ì¡´ í¬ì§€ì…˜
                for idx, row in common_positions.iterrows():
                    pair_id = row['Pair_ID']
                    pair_name = row['Pair']
                    long_asset = row['Long_Asset']
                    short_asset = row['Short_Asset']
                    signal = float(row['Signal'])
                    leg_factor = int(row['Leg_Factor'])

                    # í˜„ì¬ í¬ì§€ì…˜
                    current_pos_bp = float(row['Per_Leg_Position_bp'])
                    current_notional_bp = current_pos_bp * leg_factor

                    # ì¡°ì • í¬ì§€ì…˜
                    adj_pos_bp = adjusted_sizes.get(pair_id, current_pos_bp)
                    pos_info = position_types.get(pair_id, {'type': 'pair', 'asset': None, 'direction': None})

                    # í¬ì§€ì…˜ íƒ€ì…ì— ë”°ë¥¸ effective leg factor
                    if pos_info['type'] == 'single':
                        effective_leg_factor = 1
                        pos_type_str = f"{pos_info['direction'].capitalize()}: {pos_info['asset']}"
                    else:
                        effective_leg_factor = leg_factor
                        pos_type_str = "Pair"

                    adj_notional_bp = adj_pos_bp * effective_leg_factor

                    # Risk Unit
                    risk_unit = float(row['Risk_Unit_3M_%'])

                    # ì˜ˆìƒ ë¦¬ìŠ¤í¬ (bp) - ê·¼ì‚¬ì¹˜
                    # current_pos_bpëŠ” ì´ë¯¸ bp ë‹¨ìœ„ì´ë¯€ë¡œ * 10000 ë¶ˆí•„ìš”
                    current_risk_bp = abs(current_pos_bp) * (risk_unit / 100.0) * leg_factor
                    adj_risk_bp = abs(adj_pos_bp) * (risk_unit / 100.0) * effective_leg_factor

                    position_comparison.append({
                        'Pair': pair_name,
                        'Signal': signal,
                        'í¬ì§€ì…˜ íƒ€ì…': pos_type_str,
                        'í˜„ì¬ ë ˆê·¸ë‹¹ (bp)': current_pos_bp,
                        'ì¡°ì • ë ˆê·¸ë‹¹ (bp)': adj_pos_bp,
                        'í˜„ì¬ ì´ëª…ëª© (bp)': current_notional_bp,
                        'ì¡°ì • ì´ëª…ëª© (bp)': adj_notional_bp,
                        'Risk Unit (%)': risk_unit,
                        'í˜„ì¬ ë¦¬ìŠ¤í¬ (bp)': current_risk_bp,
                        'ì¡°ì • ë¦¬ìŠ¤í¬ (bp)': adj_risk_bp,
                        'ë¦¬ìŠ¤í¬ ë³€í™” (bp)': adj_risk_bp - current_risk_bp
                    })

                # ìƒˆ í¬ì§€ì…˜ ì¶”ê°€
                for new_pos in st.session_state.new_positions_tab11:
                    asset = new_pos['asset']
                    direction = new_pos['direction']
                    size_bp = new_pos['size_bp']
                    pos_type_str = f"{direction.capitalize()}: {asset}"

                    # ìƒˆ í¬ì§€ì…˜ì€ í˜„ì¬ 0, ì¡°ì •ì—ë§Œ ë°˜ì˜
                    position_comparison.append({
                        'Pair': f"[NEW] {asset}",
                        'Signal': 0.0,
                        'í¬ì§€ì…˜ íƒ€ì…': pos_type_str,
                        'í˜„ì¬ ë ˆê·¸ë‹¹ (bp)': 0.0,
                        'ì¡°ì • ë ˆê·¸ë‹¹ (bp)': size_bp,
                        'í˜„ì¬ ì´ëª…ëª© (bp)': 0.0,
                        'ì¡°ì • ì´ëª…ëª© (bp)': size_bp,
                        'Risk Unit (%)': 5.0,  # ê¸°ë³¸ê°’
                        'í˜„ì¬ ë¦¬ìŠ¤í¬ (bp)': 0.0,
                        'ì¡°ì • ë¦¬ìŠ¤í¬ (bp)': size_bp * 0.05,  # ê·¼ì‚¬ì¹˜
                        'ë¦¬ìŠ¤í¬ ë³€í™” (bp)': size_bp * 0.05
                    })

                position_comp_df = pd.DataFrame(position_comparison)

                # í¬ë§·íŒ… í•¨ìˆ˜
                def format_position_table(df):
                    return df.style.format({
                        'Signal': '{:.0f}',
                        'í˜„ì¬ ë ˆê·¸ë‹¹ (bp)': '{:.3f}',
                        'ì¡°ì • ë ˆê·¸ë‹¹ (bp)': '{:.3f}',
                        'í˜„ì¬ ì´ëª…ëª© (bp)': '{:.2f}',
                        'ì¡°ì • ì´ëª…ëª© (bp)': '{:.2f}',
                        'Risk Unit (%)': '{:.2f}',
                        'í˜„ì¬ ë¦¬ìŠ¤í¬ (bp)': '{:.2f}',
                        'ì¡°ì • ë¦¬ìŠ¤í¬ (bp)': '{:.2f}',
                        'ë¦¬ìŠ¤í¬ ë³€í™” (bp)': '{:+.2f}'
                    }).background_gradient(
                        subset=['ë¦¬ìŠ¤í¬ ë³€í™” (bp)'],
                        cmap='RdYlGn_r',
                        vmin=-position_comp_df['ë¦¬ìŠ¤í¬ ë³€í™” (bp)'].abs().max(),
                        vmax=position_comp_df['ë¦¬ìŠ¤í¬ ë³€í™” (bp)'].abs().max()
                    )

                st.dataframe(format_position_table(position_comp_df), use_container_width=True, hide_index=True)

                # ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ìš”ì•½
                st.markdown("##### ğŸ’¼ ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ìš”ì•½")
                col_sum1, col_sum2, col_sum3, col_sum4 = st.columns(4)

                total_current_notional = position_comp_df['í˜„ì¬ ì´ëª…ëª© (bp)'].abs().sum()
                total_adj_notional = position_comp_df['ì¡°ì • ì´ëª…ëª© (bp)'].abs().sum()

                # TE ê³„ì‚° (ê³µë¶„ì‚° í–‰ë ¬ ì‚¬ìš©)
                try:
                    if not returns_by_asset.empty and not w_opt_daily.empty and not w_bmk_daily.empty:
                        # ìµœì‹  ê°€ì¤‘ì¹˜
                        asof = min(w_opt_daily.index.max(), w_bmk_daily.index.max())
                        Wopt_last = w_opt_daily.loc[asof].fillna(0.0)
                        Wbmk_last = w_bmk_daily.loc[asof].fillna(0.0)

                        # ê³µë¶„ì‚° í–‰ë ¬
                        cols = [c for c in returns_by_asset.columns if c in Wopt_last.index]
                        R = returns_by_asset[cols]
                        R_dec = _pc_ensure_decimal_returns(R)
                        C = _pc_build_recent_cov_constant_corr(R_dec, window=63, rho=0.25)

                        w_b = Wbmk_last.reindex(cols).fillna(0.0)

                        # í˜„ì¬ active weights ê³„ì‚°
                        w_active_current = pd.Series(0.0, index=cols)
                        for i, row in enumerate(common_positions.itertuples()):
                            pid = row.Pair_ID
                            long_asset = str(row.Long_Asset)
                            short_asset = str(row.Short_Asset)
                            pos_bp = row.Per_Leg_Position_bp / 10000.0  # bp â†’ ì†Œìˆ˜

                            # Pair ê¸°ì¤€
                            if long_asset in w_active_current.index:
                                w_active_current[long_asset] += pos_bp
                            if short_asset in w_active_current.index:
                                w_active_current[short_asset] -= pos_bp

                        # ì¡°ì • active weights ê³„ì‚°
                        w_active_adj = pd.Series(0.0, index=cols)

                        # ê¸°ì¡´ í¬ì§€ì…˜ ë°˜ì˜
                        for i, row in enumerate(common_positions.itertuples()):
                            pid = row.Pair_ID
                            long_asset = str(row.Long_Asset)
                            short_asset = str(row.Short_Asset)

                            if pid in adjusted_sizes:
                                pos_bp = adjusted_sizes[pid] / 10000.0  # bp â†’ ì†Œìˆ˜
                            else:
                                pos_bp = row.Per_Leg_Position_bp / 10000.0

                            pos_info = position_types.get(pid, {'type': 'pair', 'asset': None, 'direction': None})

                            if pos_info['type'] == 'single':
                                target_asset = pos_info['asset']
                                direction = pos_info['direction']
                                if target_asset in w_active_adj.index:
                                    if direction == 'long':
                                        w_active_adj[target_asset] += pos_bp
                                    else:
                                        w_active_adj[target_asset] -= pos_bp
                            else:
                                if long_asset in w_active_adj.index:
                                    w_active_adj[long_asset] += pos_bp
                                if short_asset in w_active_adj.index:
                                    w_active_adj[short_asset] -= pos_bp

                        # ìƒˆ í¬ì§€ì…˜ ë°˜ì˜
                        for new_pos in st.session_state.new_positions_tab11:
                            asset = new_pos['asset']
                            direction = new_pos['direction']
                            size_bp = new_pos['size_bp'] / 10000.0  # bp â†’ ì†Œìˆ˜

                            if asset in w_active_adj.index:
                                if direction == 'long':
                                    w_active_adj[asset] += size_bp
                                else:  # short
                                    w_active_adj[asset] -= size_bp

                        # TE ê³„ì‚°
                        te_bp_here = _pc_te_bp_from_cov(w_active_current.values, C, 252)
                        adj_te_bp_here = _pc_te_bp_from_cov(w_active_adj.values, C, 252)
                    else:
                        # ê³µë¶„ì‚° ë°ì´í„° ì—†ìœ¼ë©´ ê·¼ì‚¬ì¹˜ ì‚¬ìš©
                        te_bp_here = position_comp_df['í˜„ì¬ ë¦¬ìŠ¤í¬ (bp)'].sum()
                        adj_te_bp_here = position_comp_df['ì¡°ì • ë¦¬ìŠ¤í¬ (bp)'].sum()
                except Exception as e:
                    st.warning(f"TE ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
                    te_bp_here = position_comp_df['í˜„ì¬ ë¦¬ìŠ¤í¬ (bp)'].sum()
                    adj_te_bp_here = position_comp_df['ì¡°ì • ë¦¬ìŠ¤í¬ (bp)'].sum()

                with col_sum1:
                    st.metric(
                        "í˜„ì¬ ì´ ëª…ëª©",
                        f"{total_current_notional:.2f}bp"
                    )
                with col_sum2:
                    st.metric(
                        "ì¡°ì • í›„ ì´ ëª…ëª©",
                        f"{total_adj_notional:.2f}bp",
                        delta=f"{total_adj_notional - total_current_notional:+.2f}bp"
                    )
                with col_sum3:
                    st.metric(
                        "í˜„ì¬ TE",
                        f"{te_bp_here:.2f}bp"
                    )
                with col_sum4:
                    st.metric(
                        "ì¡°ì • í›„ TE",
                        f"{adj_te_bp_here:.2f}bp",
                        delta=f"{adj_te_bp_here - te_bp_here:+.2f}bp"
                    )

                st.markdown("---")

                # í˜ì–´ë³„ ìƒì„¸ í…Œì´ë¸”
                with st.expander("ğŸ“‹ í˜ì–´ë³„ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„¸", expanded=False):
                    # í¬ì§€ì…˜ íƒ€ì… ìš”ì•½
                    if 'Position_Type' in scenario_df.columns:
                        type_summary = scenario_df.groupby('Pair')['Position_Type'].first().reset_index()
                        st.markdown("**í¬ì§€ì…˜ íƒ€ì… í˜„í™©**")
                        type_counts = type_summary['Position_Type'].value_counts()
                        type_info = ", ".join([f"{t}: {c}ê°œ" for t, c in type_counts.items()])
                        st.caption(f"ğŸ’¡ {type_info}")

                        # í¬ì§€ì…˜ íƒ€ì…ë³„ ìƒ‰ìƒ í‘œì‹œ
                        for _, type_row in type_summary.iterrows():
                            if type_row['Position_Type'] == 'Long Only':
                                icon = "ğŸ“ˆ"
                            elif type_row['Position_Type'] == 'Short Only':
                                icon = "ğŸ“‰"
                            else:
                                icon = "âš–ï¸"

                    # í”¼ë²— í…Œì´ë¸” ìƒì„±
                    pivot_current = scenario_df.pivot(
                        index='Pair', columns='Scenario', values='Current_PnL_bp'
                    )
                    pivot_adjusted = scenario_df.pivot(
                        index='Pair', columns='Scenario', values='Adjusted_PnL_bp'
                    )

                    st.markdown("**í˜„ì¬ í¬ì§€ì…˜ ì†ìµ (bp)** - Pair ê¸°ì¤€")
                    st.dataframe(
                        pivot_current.style.format("{:.2f}").background_gradient(cmap='RdYlGn', axis=1),
                        use_container_width=True
                    )

                    st.markdown("**ì¡°ì • í¬ì§€ì…˜ ì†ìµ (bp)** - ì„ íƒí•œ í¬ì§€ì…˜ íƒ€ì… ê¸°ì¤€")
                    st.dataframe(
                        pivot_adjusted.style.format("{:.2f}").background_gradient(cmap='RdYlGn', axis=1),
                        use_container_width=True
                    )

                # ë¦¬ìŠ¤í¬ ìš”ì•½ í†µê³„
                st.markdown("#### ğŸ“Š ë¦¬ìŠ¤í¬ ìš”ì•½")
                col_s1, col_s2, col_s3, col_s4 = st.columns(4)

                current_worst = portfolio_pnl[portfolio_pnl['Std_Level'] == -3]['Current_PnL_bp'].values[0]
                adjusted_worst = portfolio_pnl[portfolio_pnl['Std_Level'] == -3]['Adjusted_PnL_bp'].values[0]
                current_best = portfolio_pnl[portfolio_pnl['Std_Level'] == 3]['Current_PnL_bp'].values[0]
                adjusted_best = portfolio_pnl[portfolio_pnl['Std_Level'] == 3]['Adjusted_PnL_bp'].values[0]

                with col_s1:
                    st.metric(
                        "í˜„ì¬ ìµœì•… (-3Ïƒ)",
                        f"{current_worst:.2f}bp"
                    )

                with col_s2:
                    st.metric(
                        "ì¡°ì • í›„ ìµœì•… (-3Ïƒ)",
                        f"{adjusted_worst:.2f}bp",
                        delta=f"{adjusted_worst - current_worst:+.2f}bp"
                    )

                with col_s3:
                    st.metric(
                        "í˜„ì¬ ìµœì„  (+3Ïƒ)",
                        f"{current_best:.2f}bp"
                    )

                with col_s4:
                    st.metric(
                        "ì¡°ì • í›„ ìµœì„  (+3Ïƒ)",
                        f"{adjusted_best:.2f}bp",
                        delta=f"{adjusted_best - current_best:+.2f}bp"
                    )
            else:
                st.warning("ì‹œë‚˜ë¦¬ì˜¤ ì†ìµ ê³„ì‚°ì— í•„ìš”í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        else:
            st.info("í¬ì§€ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. actual_portfolio_positions.csv íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

        # ===== ë°ì´í„° ë‹¤ìš´ë¡œë“œ =====
        st.markdown("---")
        st.subheader("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")

        col_d1, col_d2, col_d3 = st.columns(3)

        with col_d1:
            # ì„±ê³¼ í…Œì´ë¸” ë‹¤ìš´ë¡œë“œ
            csv_performance = performance_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ê¸°ê°„ë³„ ì„±ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                data=csv_performance,
                file_name=f"performance_by_period_{selected_start.strftime('%Y%m%d')}_{selected_end.strftime('%Y%m%d')}.csv",
                mime="text/csv",
                key="download_performance"
            )

        with col_d2:
            # ì¼ë³„ ìˆ˜ìµë¥  ë‹¤ìš´ë¡œë“œ (ì„ íƒ ê¸°ê°„)
            csv_returns = filtered_returns.to_csv().encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ì¼ë³„ ìˆ˜ìµë¥  ë‹¤ìš´ë¡œë“œ (CSV)",
                data=csv_returns,
                file_name=f"daily_returns_{selected_start.strftime('%Y%m%d')}_{selected_end.strftime('%Y%m%d')}.csv",
                mime="text/csv",
                key="download_returns"
            )

        with col_d3:
            # ì›”ë³„ ìˆ˜ìµë¥  ë‹¤ìš´ë¡œë“œ
            if len(monthly_returns) > 0:
                csv_monthly = monthly_returns_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ì›”ë³„ ìˆ˜ìµë¥  ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv_monthly,
                    file_name=f"monthly_returns_{selected_start.strftime('%Y%m%d')}_{selected_end.strftime('%Y%m%d')}.csv",
                    mime="text/csv",
                    key="download_monthly"
                )

        st.success(f"âœ… ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ë¶„ì„ ì™„ë£Œ ({selected_start.strftime('%Y-%m-%d')} ~ {selected_end.strftime('%Y-%m-%d')})")


if __name__ == "__main__":
    main()
